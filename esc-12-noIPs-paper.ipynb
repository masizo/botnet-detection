{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupiter's Notebook for Scenario 12\n",
    "Requieres: [CategoryEncoders](http://contrib.scikit-learn.org/category_encoders/), [imbalanced-learn](https://imbalanced-learn.org/stable/), [XGBoost](https://pypi.org/project/xgboost/), and [dill](https://pypi.org/project/dill/)<br>\n",
    "`pip install category_encoders`<br>\n",
    "`pip install imbalanced-learn`<br>\n",
    "`pip install xgboost`<br>\n",
    "`pip install dill`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To identify class 0 and 1, respectively\n",
    "target_names = ['class 0', 'class 1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "df=pd.read_csv('esc-12-Mixed-traffic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No trunkated \n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209211, 52)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataset dimensions, number of sessions and features\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 208576, 1: 635})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#counting classes\n",
    "collections.Counter(df.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proto                 0\n",
      "ts                    0\n",
      "srcIP                 0\n",
      "srcPrt                0\n",
      "dstIP                 0\n",
      "dstPrt                0\n",
      "flowduration          0\n",
      "total_fpackets        0\n",
      "total_bpackets        0\n",
      "total_fpktl           0\n",
      "total_bpktl           0\n",
      "min_fpktl             0\n",
      "min_bpktl             0\n",
      "max_fpktl             0\n",
      "max_bpktl             0\n",
      "mean_fpktl            0\n",
      "mean_bpktl            0\n",
      "std_fpktl             0\n",
      "std_bpktl             0\n",
      "total_fipt            0\n",
      "total_bipt            0\n",
      "min_fipt              0\n",
      "min_bipt              0\n",
      "max_fipt              0\n",
      "max_bipt              0\n",
      "mean_fipt             0\n",
      "mean_bipt             0\n",
      "std_fipt              0\n",
      "std_bipt              0\n",
      "fpsh_cnt              0\n",
      "bpsh_cnt              0\n",
      "furg_cnt              0\n",
      "burg_cnt              0\n",
      "total_fhlen           0\n",
      "total_bhlen           0\n",
      "fPktsPerSecond        0\n",
      "bPktsPerSecond        0\n",
      "flowPktsPerSecond     0\n",
      "flowBytesPerSecond    0\n",
      "mean_flowpktl         0\n",
      "std_flowpktl          0\n",
      "mean_flowipt          0\n",
      "std_flowipt           0\n",
      "flow_fin              0\n",
      "flow_syn              0\n",
      "flow_rst              0\n",
      "flow_ack              0\n",
      "flow_urg              0\n",
      "flow_cwr              0\n",
      "flow_ece              0\n",
      "downUpRatio           0\n",
      "label                 0\n",
      "dtype: int64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#check the number of null values\n",
    "print(df.isnull().sum())\n",
    "print(df.isnull().values.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping Rows with NA inplace\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proto                      2\n",
      "ts                    209211\n",
      "srcIP                   8550\n",
      "srcPrt                 47861\n",
      "dstIP                   7035\n",
      "dstPrt                   443\n",
      "flowduration          136048\n",
      "total_fpackets           605\n",
      "total_bpackets           750\n",
      "total_fpktl             7232\n",
      "total_bpktl            13095\n",
      "min_fpktl                139\n",
      "min_bpktl                493\n",
      "max_fpktl               1093\n",
      "max_bpktl                840\n",
      "mean_fpktl             12024\n",
      "mean_bpktl             14820\n",
      "std_fpktl              18604\n",
      "std_bpktl              17453\n",
      "total_fipt             60103\n",
      "total_bipt             45622\n",
      "min_fipt               35382\n",
      "min_bipt               16905\n",
      "max_fipt               58481\n",
      "max_bipt               43265\n",
      "mean_fipt              57557\n",
      "mean_bipt              44741\n",
      "std_fipt               48421\n",
      "std_bipt               40535\n",
      "fpsh_cnt                 200\n",
      "bpsh_cnt                 302\n",
      "furg_cnt                   1\n",
      "burg_cnt                   1\n",
      "total_fhlen             2734\n",
      "total_bhlen             3586\n",
      "fPktsPerSecond        120511\n",
      "bPktsPerSecond        116705\n",
      "flowPktsPerSecond     123137\n",
      "flowBytesPerSecond    165775\n",
      "mean_flowpktl          20801\n",
      "std_flowpktl           28221\n",
      "mean_flowipt          132030\n",
      "std_flowipt            60380\n",
      "flow_fin                  17\n",
      "flow_syn                  11\n",
      "flow_rst                  18\n",
      "flow_ack                 939\n",
      "flow_urg                   1\n",
      "flow_cwr                   2\n",
      "flow_ece                   1\n",
      "downUpRatio            30274\n",
      "label                      2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#sumarize the number of unique values for each column \n",
    "print(df.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete time stamp (ts), srcIP and dstIP features\n",
    "# Models do not learn with IP addresses\n",
    "df.drop(['ts','srcIP','dstIP'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(209211, 49)\n"
     ]
    }
   ],
   "source": [
    "#Dataset dimensions, number of sessions and features\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(209211, 49)\n",
      "(207157, 49)\n"
     ]
    }
   ],
   "source": [
    "#Delete Rows That Contain Duplicate Data\n",
    "print(df.shape)\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proto</th>\n",
       "      <th>srcPrt</th>\n",
       "      <th>dstPrt</th>\n",
       "      <th>flowduration</th>\n",
       "      <th>total_fpackets</th>\n",
       "      <th>total_bpackets</th>\n",
       "      <th>total_fpktl</th>\n",
       "      <th>total_bpktl</th>\n",
       "      <th>min_fpktl</th>\n",
       "      <th>min_bpktl</th>\n",
       "      <th>max_fpktl</th>\n",
       "      <th>max_bpktl</th>\n",
       "      <th>mean_fpktl</th>\n",
       "      <th>mean_bpktl</th>\n",
       "      <th>std_fpktl</th>\n",
       "      <th>std_bpktl</th>\n",
       "      <th>total_fipt</th>\n",
       "      <th>total_bipt</th>\n",
       "      <th>min_fipt</th>\n",
       "      <th>min_bipt</th>\n",
       "      <th>max_fipt</th>\n",
       "      <th>max_bipt</th>\n",
       "      <th>mean_fipt</th>\n",
       "      <th>mean_bipt</th>\n",
       "      <th>std_fipt</th>\n",
       "      <th>std_bipt</th>\n",
       "      <th>fpsh_cnt</th>\n",
       "      <th>bpsh_cnt</th>\n",
       "      <th>furg_cnt</th>\n",
       "      <th>burg_cnt</th>\n",
       "      <th>total_fhlen</th>\n",
       "      <th>total_bhlen</th>\n",
       "      <th>fPktsPerSecond</th>\n",
       "      <th>bPktsPerSecond</th>\n",
       "      <th>flowPktsPerSecond</th>\n",
       "      <th>flowBytesPerSecond</th>\n",
       "      <th>mean_flowpktl</th>\n",
       "      <th>std_flowpktl</th>\n",
       "      <th>mean_flowipt</th>\n",
       "      <th>std_flowipt</th>\n",
       "      <th>flow_fin</th>\n",
       "      <th>flow_syn</th>\n",
       "      <th>flow_rst</th>\n",
       "      <th>flow_ack</th>\n",
       "      <th>flow_urg</th>\n",
       "      <th>flow_cwr</th>\n",
       "      <th>flow_ece</th>\n",
       "      <th>downUpRatio</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCP</td>\n",
       "      <td>64790</td>\n",
       "      <td>80</td>\n",
       "      <td>1.170896</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>901</td>\n",
       "      <td>5488</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>365</td>\n",
       "      <td>1434</td>\n",
       "      <td>100.111115</td>\n",
       "      <td>686.000000</td>\n",
       "      <td>99.368564</td>\n",
       "      <td>681.547818</td>\n",
       "      <td>1.170896</td>\n",
       "      <td>1.106900</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.891553</td>\n",
       "      <td>0.956194</td>\n",
       "      <td>0.146362</td>\n",
       "      <td>0.158129</td>\n",
       "      <td>0.303141</td>\n",
       "      <td>0.353125</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>296</td>\n",
       "      <td>268</td>\n",
       "      <td>7.686422</td>\n",
       "      <td>6.832376</td>\n",
       "      <td>14.518798</td>\n",
       "      <td>5.456506e+03</td>\n",
       "      <td>375.823529</td>\n",
       "      <td>546.830444</td>\n",
       "      <td>0.074453</td>\n",
       "      <td>0.220053</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.091010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCP</td>\n",
       "      <td>54669</td>\n",
       "      <td>22</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCP</td>\n",
       "      <td>54670</td>\n",
       "      <td>22</td>\n",
       "      <td>56.932455</td>\n",
       "      <td>6365</td>\n",
       "      <td>3398</td>\n",
       "      <td>3875053</td>\n",
       "      <td>245052</td>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>1434</td>\n",
       "      <td>1082</td>\n",
       "      <td>608.806458</td>\n",
       "      <td>72.116539</td>\n",
       "      <td>436.618751</td>\n",
       "      <td>103.965048</td>\n",
       "      <td>56.932455</td>\n",
       "      <td>36.944291</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>20.092236</td>\n",
       "      <td>0.215406</td>\n",
       "      <td>0.008946</td>\n",
       "      <td>0.010876</td>\n",
       "      <td>0.252046</td>\n",
       "      <td>0.015706</td>\n",
       "      <td>6359</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>127312</td>\n",
       "      <td>69544</td>\n",
       "      <td>111.799149</td>\n",
       "      <td>59.684761</td>\n",
       "      <td>171.483917</td>\n",
       "      <td>7.236830e+04</td>\n",
       "      <td>422.012189</td>\n",
       "      <td>439.778320</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.203547</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9762</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.063238</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCP</td>\n",
       "      <td>11969</td>\n",
       "      <td>80</td>\n",
       "      <td>3.509542</td>\n",
       "      <td>132</td>\n",
       "      <td>301</td>\n",
       "      <td>8497</td>\n",
       "      <td>423475</td>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>631</td>\n",
       "      <td>1434</td>\n",
       "      <td>64.371216</td>\n",
       "      <td>1406.893677</td>\n",
       "      <td>49.697929</td>\n",
       "      <td>134.995907</td>\n",
       "      <td>3.509542</td>\n",
       "      <td>3.506052</td>\n",
       "      <td>0.003537</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.194394</td>\n",
       "      <td>0.195942</td>\n",
       "      <td>0.026790</td>\n",
       "      <td>0.011687</td>\n",
       "      <td>0.033722</td>\n",
       "      <td>0.026183</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2652</td>\n",
       "      <td>6032</td>\n",
       "      <td>37.611744</td>\n",
       "      <td>85.766174</td>\n",
       "      <td>123.377922</td>\n",
       "      <td>1.230850e+05</td>\n",
       "      <td>997.625866</td>\n",
       "      <td>629.475708</td>\n",
       "      <td>0.008146</td>\n",
       "      <td>0.022240</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>432</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49.838177</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TCP</td>\n",
       "      <td>11970</td>\n",
       "      <td>80</td>\n",
       "      <td>8.681771</td>\n",
       "      <td>53</td>\n",
       "      <td>92</td>\n",
       "      <td>6684</td>\n",
       "      <td>105846</td>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>462</td>\n",
       "      <td>1434</td>\n",
       "      <td>126.113205</td>\n",
       "      <td>1150.500000</td>\n",
       "      <td>147.291656</td>\n",
       "      <td>492.381999</td>\n",
       "      <td>8.681771</td>\n",
       "      <td>8.470597</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>4.977212</td>\n",
       "      <td>5.003184</td>\n",
       "      <td>0.166957</td>\n",
       "      <td>0.093083</td>\n",
       "      <td>0.687755</td>\n",
       "      <td>0.532268</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1072</td>\n",
       "      <td>1852</td>\n",
       "      <td>6.104745</td>\n",
       "      <td>10.596916</td>\n",
       "      <td>16.701662</td>\n",
       "      <td>1.296164e+04</td>\n",
       "      <td>776.068966</td>\n",
       "      <td>637.257019</td>\n",
       "      <td>0.093644</td>\n",
       "      <td>0.575285</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.835727</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209206</th>\n",
       "      <td>UDP</td>\n",
       "      <td>54791</td>\n",
       "      <td>53</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209207</th>\n",
       "      <td>UDP</td>\n",
       "      <td>27719</td>\n",
       "      <td>53</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>173</td>\n",
       "      <td>81</td>\n",
       "      <td>173</td>\n",
       "      <td>81</td>\n",
       "      <td>173</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>139</td>\n",
       "      <td>2505.557861</td>\n",
       "      <td>2505.557861</td>\n",
       "      <td>5011.115723</td>\n",
       "      <td>6.364117e+05</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>65.053825</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.135803</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209208</th>\n",
       "      <td>UDP</td>\n",
       "      <td>28931</td>\n",
       "      <td>53</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>144</td>\n",
       "      <td>85</td>\n",
       "      <td>144</td>\n",
       "      <td>85</td>\n",
       "      <td>144</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>110</td>\n",
       "      <td>4899.887695</td>\n",
       "      <td>4899.887695</td>\n",
       "      <td>9799.775391</td>\n",
       "      <td>1.122074e+06</td>\n",
       "      <td>114.500000</td>\n",
       "      <td>41.719299</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.694118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209209</th>\n",
       "      <td>UDP</td>\n",
       "      <td>40314</td>\n",
       "      <td>53</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>177</td>\n",
       "      <td>85</td>\n",
       "      <td>177</td>\n",
       "      <td>85</td>\n",
       "      <td>177</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>143</td>\n",
       "      <td>4132.319336</td>\n",
       "      <td>4132.319336</td>\n",
       "      <td>8264.638672</td>\n",
       "      <td>1.082668e+06</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>65.053825</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.082353</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209210</th>\n",
       "      <td>UDP</td>\n",
       "      <td>54794</td>\n",
       "      <td>53</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207157 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       proto  srcPrt  dstPrt  flowduration  total_fpackets  total_bpackets  \\\n",
       "0        TCP   64790      80      1.170896               9               8   \n",
       "1        TCP   54669      22      0.000000               1               0   \n",
       "2        TCP   54670      22     56.932455            6365            3398   \n",
       "3        TCP   11969      80      3.509542             132             301   \n",
       "4        TCP   11970      80      8.681771              53              92   \n",
       "...      ...     ...     ...           ...             ...             ...   \n",
       "209206   UDP   54791      53      0.000000               1               0   \n",
       "209207   UDP   27719      53      0.000399               1               1   \n",
       "209208   UDP   28931      53      0.000204               1               1   \n",
       "209209   UDP   40314      53      0.000242               1               1   \n",
       "209210   UDP   54794      53      0.000000               1               0   \n",
       "\n",
       "        total_fpktl  total_bpktl  min_fpktl  min_bpktl  max_fpktl  max_bpktl  \\\n",
       "0               901         5488         66         66        365       1434   \n",
       "1                60            0         60          0         60          0   \n",
       "2           3875053       245052         60         54       1434       1082   \n",
       "3              8497       423475         60         54        631       1434   \n",
       "4              6684       105846         60         54        462       1434   \n",
       "...             ...          ...        ...        ...        ...        ...   \n",
       "209206           76            0         76          0         76          0   \n",
       "209207           81          173         81        173         81        173   \n",
       "209208           85          144         85        144         85        144   \n",
       "209209           85          177         85        177         85        177   \n",
       "209210           70            0         70          0         70          0   \n",
       "\n",
       "        mean_fpktl   mean_bpktl   std_fpktl   std_bpktl  total_fipt  \\\n",
       "0       100.111115   686.000000   99.368564  681.547818    1.170896   \n",
       "1        60.000000     0.000000    0.000000    0.000000    0.000000   \n",
       "2       608.806458    72.116539  436.618751  103.965048   56.932455   \n",
       "3        64.371216  1406.893677   49.697929  134.995907    3.509542   \n",
       "4       126.113205  1150.500000  147.291656  492.381999    8.681771   \n",
       "...            ...          ...         ...         ...         ...   \n",
       "209206   76.000000     0.000000    0.000000    0.000000    0.000000   \n",
       "209207   81.000000   173.000000    0.000000    0.000000    0.000000   \n",
       "209208   85.000000   144.000000    0.000000    0.000000    0.000000   \n",
       "209209   85.000000   177.000000    0.000000    0.000000    0.000000   \n",
       "209210   70.000000     0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "        total_bipt  min_fipt  min_bipt   max_fipt  max_bipt  mean_fipt  \\\n",
       "0         1.106900  0.000017  0.000009   0.891553  0.956194   0.146362   \n",
       "1         0.000000  0.000000  0.000000   0.000000  0.000000   0.000000   \n",
       "2        36.944291  0.000011  0.000005  20.092236  0.215406   0.008946   \n",
       "3         3.506052  0.003537  0.000006   0.194394  0.195942   0.026790   \n",
       "4         8.470597  0.003008  0.000005   4.977212  5.003184   0.166957   \n",
       "...            ...       ...       ...        ...       ...        ...   \n",
       "209206    0.000000  0.000000  0.000000   0.000000  0.000000   0.000000   \n",
       "209207    0.000000  0.000000  0.000000   0.000000  0.000000   0.000000   \n",
       "209208    0.000000  0.000000  0.000000   0.000000  0.000000   0.000000   \n",
       "209209    0.000000  0.000000  0.000000   0.000000  0.000000   0.000000   \n",
       "209210    0.000000  0.000000  0.000000   0.000000  0.000000   0.000000   \n",
       "\n",
       "        mean_bipt  std_fipt  std_bipt  fpsh_cnt  bpsh_cnt  furg_cnt  burg_cnt  \\\n",
       "0        0.158129  0.303141  0.353125         1         2         0         0   \n",
       "1        0.000000  0.000000  0.000000         0         0         0         0   \n",
       "2        0.010876  0.252046  0.015706      6359       138         0         0   \n",
       "3        0.011687  0.033722  0.026183         1         2         0         0   \n",
       "4        0.093083  0.687755  0.532268         9        29         0         0   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "209206   0.000000  0.000000  0.000000         0         0         0         0   \n",
       "209207   0.000000  0.000000  0.000000         0         0         0         0   \n",
       "209208   0.000000  0.000000  0.000000         0         0         0         0   \n",
       "209209   0.000000  0.000000  0.000000         0         0         0         0   \n",
       "209210   0.000000  0.000000  0.000000         0         0         0         0   \n",
       "\n",
       "        total_fhlen  total_bhlen  fPktsPerSecond  bPktsPerSecond  \\\n",
       "0               296          268        7.686422        6.832376   \n",
       "1                20            0        0.000000        0.000000   \n",
       "2            127312        69544      111.799149       59.684761   \n",
       "3              2652         6032       37.611744       85.766174   \n",
       "4              1072         1852        6.104745       10.596916   \n",
       "...             ...          ...             ...             ...   \n",
       "209206           42            0        0.000000        0.000000   \n",
       "209207           47          139     2505.557861     2505.557861   \n",
       "209208           51          110     4899.887695     4899.887695   \n",
       "209209           51          143     4132.319336     4132.319336   \n",
       "209210           36            0        0.000000        0.000000   \n",
       "\n",
       "        flowPktsPerSecond  flowBytesPerSecond  mean_flowpktl  std_flowpktl  \\\n",
       "0               14.518798        5.456506e+03     375.823529    546.830444   \n",
       "1                0.000000        0.000000e+00      60.000000      0.000000   \n",
       "2              171.483917        7.236830e+04     422.012189    439.778320   \n",
       "3              123.377922        1.230850e+05     997.625866    629.475708   \n",
       "4               16.701662        1.296164e+04     776.068966    637.257019   \n",
       "...                   ...                 ...            ...           ...   \n",
       "209206           0.000000        0.000000e+00      76.000000      0.000000   \n",
       "209207        5011.115723        6.364117e+05     127.000000     65.053825   \n",
       "209208        9799.775391        1.122074e+06     114.500000     41.719299   \n",
       "209209        8264.638672        1.082668e+06     131.000000     65.053825   \n",
       "209210           0.000000        0.000000e+00      70.000000      0.000000   \n",
       "\n",
       "        mean_flowipt  std_flowipt  flow_fin  flow_syn  flow_rst  flow_ack  \\\n",
       "0           0.074453     0.220053         2         2         0        16   \n",
       "1           0.000000     0.000000         0         0         1         1   \n",
       "2           0.005859     0.203547         0         2         1      9762   \n",
       "3           0.008146     0.022240         0         2         1       432   \n",
       "4           0.093644     0.575285         1         2         1       144   \n",
       "...              ...          ...       ...       ...       ...       ...   \n",
       "209206      0.000000     0.000000         0         0         0         0   \n",
       "209207      0.000399     0.000000         0         0         0         0   \n",
       "209208      0.000204     0.000000         0         0         0         0   \n",
       "209209      0.000242     0.000000         0         0         0         0   \n",
       "209210      0.000000     0.000000         0         0         0         0   \n",
       "\n",
       "        flow_urg  flow_cwr  flow_ece  downUpRatio  label  \n",
       "0              0         0         0     6.091010      0  \n",
       "1              0         0         0     0.000000      0  \n",
       "2              0         0         0     0.063238      0  \n",
       "3              0         0         0    49.838177      0  \n",
       "4              0         0         0    15.835727      0  \n",
       "...          ...       ...       ...          ...    ...  \n",
       "209206         0         0         0     0.000000      0  \n",
       "209207         0         0         0     2.135803      0  \n",
       "209208         0         0         0     1.694118      0  \n",
       "209209         0         0         0     2.082353      0  \n",
       "209210         0         0         0     0.000000      0  \n",
       "\n",
       "[207157 rows x 49 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Class 0 : 206526 of 207157 (99.7%)\n",
      "> Class 1 : 631 of 207157 (0.3%)\n"
     ]
    }
   ],
   "source": [
    "#check % class distribution \n",
    "y=df['label'].values #convert to nparray\n",
    "\n",
    "classes=np.unique(y)\n",
    "total=len(y)\n",
    "\n",
    "for c in classes:\n",
    "    n_examples=len(y[y==c])\n",
    "    percent = n_examples/total*100\n",
    "    print('> Class %d : %d of %d (%.1f%%)' % (c, n_examples,total,percent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(df.drop(columns=['label']), df['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((165725, 48), (41432, 48))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Original dataset dimensions\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding of categorical variables\n",
    "[Target encoding](https://contrib.scikit-learn.org/category_encoders/targetencoder.html) for categorical features will be used to encode three nominal categorical variables: protocol, source and destination ports. This method is supervised and requires training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load library for target encoder \n",
    "from category_encoders import TargetEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "proto                  object\n",
       "srcPrt                  int64\n",
       "dstPrt                  int64\n",
       "flowduration          float64\n",
       "total_fpackets          int64\n",
       "total_bpackets          int64\n",
       "total_fpktl             int64\n",
       "total_bpktl             int64\n",
       "min_fpktl               int64\n",
       "min_bpktl               int64\n",
       "max_fpktl               int64\n",
       "max_bpktl               int64\n",
       "mean_fpktl            float64\n",
       "mean_bpktl            float64\n",
       "std_fpktl             float64\n",
       "std_bpktl             float64\n",
       "total_fipt            float64\n",
       "total_bipt            float64\n",
       "min_fipt              float64\n",
       "min_bipt              float64\n",
       "max_fipt              float64\n",
       "max_bipt              float64\n",
       "mean_fipt             float64\n",
       "mean_bipt             float64\n",
       "std_fipt              float64\n",
       "std_bipt              float64\n",
       "fpsh_cnt                int64\n",
       "bpsh_cnt                int64\n",
       "furg_cnt                int64\n",
       "burg_cnt                int64\n",
       "total_fhlen             int64\n",
       "total_bhlen             int64\n",
       "fPktsPerSecond        float64\n",
       "bPktsPerSecond        float64\n",
       "flowPktsPerSecond     float64\n",
       "flowBytesPerSecond    float64\n",
       "mean_flowpktl         float64\n",
       "std_flowpktl          float64\n",
       "mean_flowipt          float64\n",
       "std_flowipt           float64\n",
       "flow_fin                int64\n",
       "flow_syn                int64\n",
       "flow_rst                int64\n",
       "flow_ack                int64\n",
       "flow_urg                int64\n",
       "flow_cwr                int64\n",
       "flow_ece                int64\n",
       "downUpRatio           float64\n",
       "label                   int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check data types for each feature\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the three categorical variables to be coded\n",
    "enc = TargetEncoder(cols=['proto','srcPrt','dstPrt'])\n",
    "# fit on the trainning dataset\n",
    "enc.fit_transform(X_train, y_train)\n",
    "# Coding categorical variables of the trainning dataset\n",
    "training_numeric_dataset=enc.transform(X_train)\n",
    "# Coding categorical variables of the test dataset\n",
    "testing_numeric_dataset = enc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proto</th>\n",
       "      <th>srcPrt</th>\n",
       "      <th>dstPrt</th>\n",
       "      <th>flowduration</th>\n",
       "      <th>total_fpackets</th>\n",
       "      <th>total_bpackets</th>\n",
       "      <th>total_fpktl</th>\n",
       "      <th>total_bpktl</th>\n",
       "      <th>min_fpktl</th>\n",
       "      <th>min_bpktl</th>\n",
       "      <th>max_fpktl</th>\n",
       "      <th>max_bpktl</th>\n",
       "      <th>mean_fpktl</th>\n",
       "      <th>mean_bpktl</th>\n",
       "      <th>std_fpktl</th>\n",
       "      <th>std_bpktl</th>\n",
       "      <th>total_fipt</th>\n",
       "      <th>total_bipt</th>\n",
       "      <th>min_fipt</th>\n",
       "      <th>min_bipt</th>\n",
       "      <th>max_fipt</th>\n",
       "      <th>max_bipt</th>\n",
       "      <th>mean_fipt</th>\n",
       "      <th>mean_bipt</th>\n",
       "      <th>std_fipt</th>\n",
       "      <th>std_bipt</th>\n",
       "      <th>fpsh_cnt</th>\n",
       "      <th>bpsh_cnt</th>\n",
       "      <th>furg_cnt</th>\n",
       "      <th>burg_cnt</th>\n",
       "      <th>total_fhlen</th>\n",
       "      <th>total_bhlen</th>\n",
       "      <th>fPktsPerSecond</th>\n",
       "      <th>bPktsPerSecond</th>\n",
       "      <th>flowPktsPerSecond</th>\n",
       "      <th>flowBytesPerSecond</th>\n",
       "      <th>mean_flowpktl</th>\n",
       "      <th>std_flowpktl</th>\n",
       "      <th>mean_flowipt</th>\n",
       "      <th>std_flowipt</th>\n",
       "      <th>flow_fin</th>\n",
       "      <th>flow_syn</th>\n",
       "      <th>flow_rst</th>\n",
       "      <th>flow_ack</th>\n",
       "      <th>flow_urg</th>\n",
       "      <th>flow_cwr</th>\n",
       "      <th>flow_ece</th>\n",
       "      <th>downUpRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8772</th>\n",
       "      <td>0.004343</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>9.552330</td>\n",
       "      <td>134</td>\n",
       "      <td>226</td>\n",
       "      <td>9169</td>\n",
       "      <td>314991</td>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>400</td>\n",
       "      <td>1434</td>\n",
       "      <td>68.425377</td>\n",
       "      <td>1393.765503</td>\n",
       "      <td>41.308371</td>\n",
       "      <td>219.532662</td>\n",
       "      <td>9.552326</td>\n",
       "      <td>9.552312</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>4.853084</td>\n",
       "      <td>4.904044</td>\n",
       "      <td>0.071822</td>\n",
       "      <td>0.042455</td>\n",
       "      <td>0.479779</td>\n",
       "      <td>0.380285</td>\n",
       "      <td>2</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3352</td>\n",
       "      <td>4528</td>\n",
       "      <td>14.027991</td>\n",
       "      <td>23.659149</td>\n",
       "      <td>37.687141</td>\n",
       "      <td>3.393518e+04</td>\n",
       "      <td>900.444444</td>\n",
       "      <td>665.156799</td>\n",
       "      <td>0.040129</td>\n",
       "      <td>0.387836</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>359</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.353909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54525</th>\n",
       "      <td>0.002892</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>144</td>\n",
       "      <td>85</td>\n",
       "      <td>144</td>\n",
       "      <td>85</td>\n",
       "      <td>144</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>110</td>\n",
       "      <td>5714.310547</td>\n",
       "      <td>5714.310547</td>\n",
       "      <td>11428.621094</td>\n",
       "      <td>1.308577e+06</td>\n",
       "      <td>114.500000</td>\n",
       "      <td>41.719299</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.694118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84875</th>\n",
       "      <td>0.002892</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.938860</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>1.065122</td>\n",
       "      <td>1.065122</td>\n",
       "      <td>2.130243</td>\n",
       "      <td>1.491170e+02</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.938860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133388</th>\n",
       "      <td>0.002892</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.184145</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>5.430504</td>\n",
       "      <td>5.430504</td>\n",
       "      <td>10.861008</td>\n",
       "      <td>7.494095e+02</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.184145</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119845</th>\n",
       "      <td>0.002892</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>4.785918</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>203</td>\n",
       "      <td>297</td>\n",
       "      <td>98</td>\n",
       "      <td>145</td>\n",
       "      <td>105</td>\n",
       "      <td>152</td>\n",
       "      <td>101.500000</td>\n",
       "      <td>148.500000</td>\n",
       "      <td>4.949747</td>\n",
       "      <td>4.949747</td>\n",
       "      <td>4.698249</td>\n",
       "      <td>4.697643</td>\n",
       "      <td>4.698249</td>\n",
       "      <td>4.697643</td>\n",
       "      <td>4.698249</td>\n",
       "      <td>4.697643</td>\n",
       "      <td>4.698249</td>\n",
       "      <td>4.697643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>229</td>\n",
       "      <td>0.417893</td>\n",
       "      <td>0.417893</td>\n",
       "      <td>0.835785</td>\n",
       "      <td>1.044732e+02</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>27.434771</td>\n",
       "      <td>1.624731</td>\n",
       "      <td>2.661745</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.463054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121012</th>\n",
       "      <td>0.002892</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.382068</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>2.617336</td>\n",
       "      <td>2.617336</td>\n",
       "      <td>5.234672</td>\n",
       "      <td>3.716617e+02</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.382068</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104650</th>\n",
       "      <td>0.002892</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.072581</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>440</td>\n",
       "      <td>84</td>\n",
       "      <td>440</td>\n",
       "      <td>84</td>\n",
       "      <td>440</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>406</td>\n",
       "      <td>13.777700</td>\n",
       "      <td>13.777700</td>\n",
       "      <td>27.555401</td>\n",
       "      <td>7.219515e+03</td>\n",
       "      <td>262.000000</td>\n",
       "      <td>251.730011</td>\n",
       "      <td>0.072581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.238095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133210</th>\n",
       "      <td>0.002892</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.459518</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>2.176193</td>\n",
       "      <td>2.176193</td>\n",
       "      <td>4.352387</td>\n",
       "      <td>3.351338e+02</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.459518</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148286</th>\n",
       "      <td>0.002892</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>46.688585</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>610</td>\n",
       "      <td>1985</td>\n",
       "      <td>85</td>\n",
       "      <td>397</td>\n",
       "      <td>97</td>\n",
       "      <td>397</td>\n",
       "      <td>87.142860</td>\n",
       "      <td>397.000000</td>\n",
       "      <td>4.488079</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46.688584</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>40.573093</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>7.781431</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>16.249685</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>372</td>\n",
       "      <td>1815</td>\n",
       "      <td>0.149930</td>\n",
       "      <td>0.107093</td>\n",
       "      <td>0.257022</td>\n",
       "      <td>5.558104e+01</td>\n",
       "      <td>216.250000</td>\n",
       "      <td>159.588745</td>\n",
       "      <td>4.252745</td>\n",
       "      <td>12.184536</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.254098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123116</th>\n",
       "      <td>0.002892</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.655589</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>7.778175</td>\n",
       "      <td>7.778175</td>\n",
       "      <td>0.327531</td>\n",
       "      <td>0.328248</td>\n",
       "      <td>0.327531</td>\n",
       "      <td>0.328248</td>\n",
       "      <td>0.327531</td>\n",
       "      <td>0.328248</td>\n",
       "      <td>0.327531</td>\n",
       "      <td>0.328248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>3.050691</td>\n",
       "      <td>3.050691</td>\n",
       "      <td>6.101383</td>\n",
       "      <td>5.338710e+02</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>6.350853</td>\n",
       "      <td>0.327643</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165725 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           proto    srcPrt    dstPrt  flowduration  total_fpackets  \\\n",
       "8772    0.004343  0.000056  0.004387      9.552330             134   \n",
       "54525   0.002892  0.000831  0.000042      0.000175               1   \n",
       "84875   0.002892  0.000147  0.000042      0.938860               1   \n",
       "133388  0.002892  0.000368  0.000042      0.184145               1   \n",
       "119845  0.002892  0.000000  0.000042      4.785918               2   \n",
       "...          ...       ...       ...           ...             ...   \n",
       "121012  0.002892  0.000003  0.000042      0.382068               1   \n",
       "104650  0.002892  0.000056  0.000042      0.072581               1   \n",
       "133210  0.002892  0.000831  0.000042      0.459518               1   \n",
       "148286  0.002892  0.000000  0.000042     46.688585               7   \n",
       "123116  0.002892  0.000000  0.000042      0.655589               2   \n",
       "\n",
       "        total_bpackets  total_fpktl  total_bpktl  min_fpktl  min_bpktl  \\\n",
       "8772               226         9169       314991         60         54   \n",
       "54525                1           85          144         85        144   \n",
       "84875                1           70           70         70         70   \n",
       "133388               1           69           69         69         69   \n",
       "119845               2          203          297         98        145   \n",
       "...                ...          ...          ...        ...        ...   \n",
       "121012               1           71           71         71         71   \n",
       "104650               1           84          440         84        440   \n",
       "133210               1           77           77         77         77   \n",
       "148286               5          610         1985         85        397   \n",
       "123116               2          175          175         82         82   \n",
       "\n",
       "        max_fpktl  max_bpktl  mean_fpktl   mean_bpktl  std_fpktl   std_bpktl  \\\n",
       "8772          400       1434   68.425377  1393.765503  41.308371  219.532662   \n",
       "54525          85        144   85.000000   144.000000   0.000000    0.000000   \n",
       "84875          70         70   70.000000    70.000000   0.000000    0.000000   \n",
       "133388         69         69   69.000000    69.000000   0.000000    0.000000   \n",
       "119845        105        152  101.500000   148.500000   4.949747    4.949747   \n",
       "...           ...        ...         ...          ...        ...         ...   \n",
       "121012         71         71   71.000000    71.000000   0.000000    0.000000   \n",
       "104650         84        440   84.000000   440.000000   0.000000    0.000000   \n",
       "133210         77         77   77.000000    77.000000   0.000000    0.000000   \n",
       "148286         97        397   87.142860   397.000000   4.488079    0.000000   \n",
       "123116         93         93   87.500000    87.500000   7.778175    7.778175   \n",
       "\n",
       "        total_fipt  total_bipt  min_fipt  min_bipt   max_fipt  max_bipt  \\\n",
       "8772      9.552326    9.552312  0.001491  0.000007   4.853084  4.904044   \n",
       "54525     0.000000    0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "84875     0.000000    0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "133388    0.000000    0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "119845    4.698249    4.697643  4.698249  4.697643   4.698249  4.697643   \n",
       "...            ...         ...       ...       ...        ...       ...   \n",
       "121012    0.000000    0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "104650    0.000000    0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "133210    0.000000    0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "148286   46.688584    0.000427  0.000008  0.000018  40.573093  0.000371   \n",
       "123116    0.327531    0.328248  0.327531  0.328248   0.327531  0.328248   \n",
       "\n",
       "        mean_fipt  mean_bipt   std_fipt  std_bipt  fpsh_cnt  bpsh_cnt  \\\n",
       "8772     0.071822   0.042455   0.479779  0.380285         2        91   \n",
       "54525    0.000000   0.000000   0.000000  0.000000         0         0   \n",
       "84875    0.000000   0.000000   0.000000  0.000000         0         0   \n",
       "133388   0.000000   0.000000   0.000000  0.000000         0         0   \n",
       "119845   4.698249   4.697643   0.000000  0.000000         0         0   \n",
       "...           ...        ...        ...       ...       ...       ...   \n",
       "121012   0.000000   0.000000   0.000000  0.000000         0         0   \n",
       "104650   0.000000   0.000000   0.000000  0.000000         0         0   \n",
       "133210   0.000000   0.000000   0.000000  0.000000         0         0   \n",
       "148286   7.781431   0.000107  16.249685  0.000176         0         0   \n",
       "123116   0.327531   0.328248   0.000000  0.000000         0         0   \n",
       "\n",
       "        furg_cnt  burg_cnt  total_fhlen  total_bhlen  fPktsPerSecond  \\\n",
       "8772           0         0         3352         4528       14.027991   \n",
       "54525          0         0           51          110     5714.310547   \n",
       "84875          0         0           36           36        1.065122   \n",
       "133388         0         0           35           35        5.430504   \n",
       "119845         0         0          135          229        0.417893   \n",
       "...          ...       ...          ...          ...             ...   \n",
       "121012         0         0           37           37        2.617336   \n",
       "104650         0         0           50          406       13.777700   \n",
       "133210         0         0           43           43        2.176193   \n",
       "148286         0         0          372         1815        0.149930   \n",
       "123116         0         0          107          107        3.050691   \n",
       "\n",
       "        bPktsPerSecond  flowPktsPerSecond  flowBytesPerSecond  mean_flowpktl  \\\n",
       "8772         23.659149          37.687141        3.393518e+04     900.444444   \n",
       "54525      5714.310547       11428.621094        1.308577e+06     114.500000   \n",
       "84875         1.065122           2.130243        1.491170e+02      70.000000   \n",
       "133388        5.430504          10.861008        7.494095e+02      69.000000   \n",
       "119845        0.417893           0.835785        1.044732e+02     125.000000   \n",
       "...                ...                ...                 ...            ...   \n",
       "121012        2.617336           5.234672        3.716617e+02      71.000000   \n",
       "104650       13.777700          27.555401        7.219515e+03     262.000000   \n",
       "133210        2.176193           4.352387        3.351338e+02      77.000000   \n",
       "148286        0.107093           0.257022        5.558104e+01     216.250000   \n",
       "123116        3.050691           6.101383        5.338710e+02      87.500000   \n",
       "\n",
       "        std_flowpktl  mean_flowipt  std_flowipt  flow_fin  flow_syn  flow_rst  \\\n",
       "8772      665.156799      0.040129     0.387836         2         2         0   \n",
       "54525      41.719299      0.000175     0.000000         0         0         0   \n",
       "84875       0.000000      0.938860     0.000000         0         0         0   \n",
       "133388      0.000000      0.184145     0.000000         0         0         0   \n",
       "119845     27.434771      1.624731     2.661745         0         0         0   \n",
       "...              ...           ...          ...       ...       ...       ...   \n",
       "121012      0.000000      0.382068     0.000000         0         0         0   \n",
       "104650    251.730011      0.072581     0.000000         0         0         0   \n",
       "133210      0.000000      0.459518     0.000000         0         0         0   \n",
       "148286    159.588745      4.252745    12.184536         0         0         0   \n",
       "123116      6.350853      0.327643     0.000371         0         0         0   \n",
       "\n",
       "        flow_ack  flow_urg  flow_cwr  flow_ece  downUpRatio  \n",
       "8772         359         0         0         0    34.353909  \n",
       "54525          0         0         0         0     1.694118  \n",
       "84875          0         0         0         0     1.000000  \n",
       "133388         0         0         0         0     1.000000  \n",
       "119845         0         0         0         0     1.463054  \n",
       "...          ...       ...       ...       ...          ...  \n",
       "121012         0         0         0         0     1.000000  \n",
       "104650         0         0         0         0     5.238095  \n",
       "133210         0         0         0         0     1.000000  \n",
       "148286         0         0         0         0     3.254098  \n",
       "123116         0         0         0         0     1.000000  \n",
       "\n",
       "[165725 rows x 48 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show trainning dataset\n",
    "training_numeric_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proto</th>\n",
       "      <th>srcPrt</th>\n",
       "      <th>dstPrt</th>\n",
       "      <th>flowduration</th>\n",
       "      <th>total_fpackets</th>\n",
       "      <th>total_bpackets</th>\n",
       "      <th>total_fpktl</th>\n",
       "      <th>total_bpktl</th>\n",
       "      <th>min_fpktl</th>\n",
       "      <th>min_bpktl</th>\n",
       "      <th>max_fpktl</th>\n",
       "      <th>max_bpktl</th>\n",
       "      <th>mean_fpktl</th>\n",
       "      <th>mean_bpktl</th>\n",
       "      <th>std_fpktl</th>\n",
       "      <th>std_bpktl</th>\n",
       "      <th>total_fipt</th>\n",
       "      <th>total_bipt</th>\n",
       "      <th>min_fipt</th>\n",
       "      <th>min_bipt</th>\n",
       "      <th>max_fipt</th>\n",
       "      <th>max_bipt</th>\n",
       "      <th>mean_fipt</th>\n",
       "      <th>mean_bipt</th>\n",
       "      <th>std_fipt</th>\n",
       "      <th>std_bipt</th>\n",
       "      <th>fpsh_cnt</th>\n",
       "      <th>bpsh_cnt</th>\n",
       "      <th>furg_cnt</th>\n",
       "      <th>burg_cnt</th>\n",
       "      <th>total_fhlen</th>\n",
       "      <th>total_bhlen</th>\n",
       "      <th>fPktsPerSecond</th>\n",
       "      <th>bPktsPerSecond</th>\n",
       "      <th>flowPktsPerSecond</th>\n",
       "      <th>flowBytesPerSecond</th>\n",
       "      <th>mean_flowpktl</th>\n",
       "      <th>std_flowpktl</th>\n",
       "      <th>mean_flowipt</th>\n",
       "      <th>std_flowipt</th>\n",
       "      <th>flow_fin</th>\n",
       "      <th>flow_syn</th>\n",
       "      <th>flow_rst</th>\n",
       "      <th>flow_ack</th>\n",
       "      <th>flow_urg</th>\n",
       "      <th>flow_cwr</th>\n",
       "      <th>flow_ece</th>\n",
       "      <th>downUpRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144590</th>\n",
       "      <td>0.002892</td>\n",
       "      <td>8.308825e-04</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.057055</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>289</td>\n",
       "      <td>75</td>\n",
       "      <td>289</td>\n",
       "      <td>75</td>\n",
       "      <td>289</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>255</td>\n",
       "      <td>17.526949</td>\n",
       "      <td>17.526949</td>\n",
       "      <td>35.053898</td>\n",
       "      <td>6.379810e+03</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>151.320847</td>\n",
       "      <td>0.057055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.853333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174762</th>\n",
       "      <td>0.002892</td>\n",
       "      <td>3.089455e-03</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.093740</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>354</td>\n",
       "      <td>81</td>\n",
       "      <td>354</td>\n",
       "      <td>81</td>\n",
       "      <td>354</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>320</td>\n",
       "      <td>10.667779</td>\n",
       "      <td>10.667779</td>\n",
       "      <td>21.335558</td>\n",
       "      <td>4.640484e+03</td>\n",
       "      <td>217.500000</td>\n",
       "      <td>193.040146</td>\n",
       "      <td>0.093740</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.370370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20836</th>\n",
       "      <td>0.004343</td>\n",
       "      <td>5.556759e-05</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>15.021914</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1018</td>\n",
       "      <td>848</td>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>712</td>\n",
       "      <td>674</td>\n",
       "      <td>169.666672</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>265.698827</td>\n",
       "      <td>308.051944</td>\n",
       "      <td>15.021914</td>\n",
       "      <td>6.389717</td>\n",
       "      <td>0.009656</td>\n",
       "      <td>0.030542</td>\n",
       "      <td>8.612408</td>\n",
       "      <td>5.008085</td>\n",
       "      <td>3.004383</td>\n",
       "      <td>2.129906</td>\n",
       "      <td>3.693772</td>\n",
       "      <td>2.578546</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>92</td>\n",
       "      <td>0.399417</td>\n",
       "      <td>0.266278</td>\n",
       "      <td>0.665694</td>\n",
       "      <td>1.242185e+02</td>\n",
       "      <td>186.600000</td>\n",
       "      <td>267.076447</td>\n",
       "      <td>2.350367</td>\n",
       "      <td>3.055030</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.833006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161575</th>\n",
       "      <td>0.002892</td>\n",
       "      <td>8.308825e-04</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>136</td>\n",
       "      <td>85</td>\n",
       "      <td>136</td>\n",
       "      <td>85</td>\n",
       "      <td>136</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>102</td>\n",
       "      <td>5461.333496</td>\n",
       "      <td>5461.333496</td>\n",
       "      <td>10922.666992</td>\n",
       "      <td>1.206955e+06</td>\n",
       "      <td>110.500000</td>\n",
       "      <td>36.062447</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41335</th>\n",
       "      <td>0.002892</td>\n",
       "      <td>4.290636e-14</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.608493</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>540</td>\n",
       "      <td>61</td>\n",
       "      <td>270</td>\n",
       "      <td>61</td>\n",
       "      <td>270</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.608157</td>\n",
       "      <td>0.608155</td>\n",
       "      <td>0.608157</td>\n",
       "      <td>0.608155</td>\n",
       "      <td>0.608157</td>\n",
       "      <td>0.608155</td>\n",
       "      <td>0.608157</td>\n",
       "      <td>0.608155</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>472</td>\n",
       "      <td>3.286808</td>\n",
       "      <td>3.286808</td>\n",
       "      <td>6.573616</td>\n",
       "      <td>1.087933e+03</td>\n",
       "      <td>165.500000</td>\n",
       "      <td>120.666206</td>\n",
       "      <td>0.202944</td>\n",
       "      <td>0.350925</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.426229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131731</th>\n",
       "      <td>0.002892</td>\n",
       "      <td>3.089455e-03</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>30.023242</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>219</td>\n",
       "      <td>219</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.049953</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>10.022589</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>10.027365</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>10.024977</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.003377</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>0.099923</td>\n",
       "      <td>0.099923</td>\n",
       "      <td>0.199845</td>\n",
       "      <td>1.458870e+01</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.004648</td>\n",
       "      <td>5.481442</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4393</th>\n",
       "      <td>0.004343</td>\n",
       "      <td>8.308825e-04</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>5.741911</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>5436</td>\n",
       "      <td>21569</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>852</td>\n",
       "      <td>1434</td>\n",
       "      <td>236.347824</td>\n",
       "      <td>937.782593</td>\n",
       "      <td>329.620933</td>\n",
       "      <td>593.587931</td>\n",
       "      <td>5.741901</td>\n",
       "      <td>5.741894</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>5.001964</td>\n",
       "      <td>5.005466</td>\n",
       "      <td>0.260995</td>\n",
       "      <td>0.260995</td>\n",
       "      <td>1.059760</td>\n",
       "      <td>1.061274</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>744</td>\n",
       "      <td>748</td>\n",
       "      <td>4.005635</td>\n",
       "      <td>4.005635</td>\n",
       "      <td>8.011271</td>\n",
       "      <td>4.703138e+03</td>\n",
       "      <td>587.065217</td>\n",
       "      <td>592.547241</td>\n",
       "      <td>0.236708</td>\n",
       "      <td>1.029460</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.967807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>0.004343</td>\n",
       "      <td>3.812220e-07</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>62.587642</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>982</td>\n",
       "      <td>8373</td>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>556</td>\n",
       "      <td>1434</td>\n",
       "      <td>122.750000</td>\n",
       "      <td>837.299988</td>\n",
       "      <td>175.072026</td>\n",
       "      <td>685.954010</td>\n",
       "      <td>62.587625</td>\n",
       "      <td>62.587623</td>\n",
       "      <td>0.012259</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>57.512791</td>\n",
       "      <td>57.526875</td>\n",
       "      <td>8.941089</td>\n",
       "      <td>6.954180</td>\n",
       "      <td>21.496969</td>\n",
       "      <td>19.035740</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>212</td>\n",
       "      <td>0.127821</td>\n",
       "      <td>0.159776</td>\n",
       "      <td>0.287597</td>\n",
       "      <td>1.494704e+02</td>\n",
       "      <td>519.722222</td>\n",
       "      <td>628.658691</td>\n",
       "      <td>3.973791</td>\n",
       "      <td>13.893184</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.526477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61237</th>\n",
       "      <td>0.002892</td>\n",
       "      <td>3.682721e-04</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>170</td>\n",
       "      <td>86</td>\n",
       "      <td>170</td>\n",
       "      <td>86</td>\n",
       "      <td>170</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>136</td>\n",
       "      <td>3390.706543</td>\n",
       "      <td>3390.706543</td>\n",
       "      <td>6781.413086</td>\n",
       "      <td>8.680209e+05</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>59.396969</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.976744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107563</th>\n",
       "      <td>0.002892</td>\n",
       "      <td>2.067726e-05</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.091881</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>203</td>\n",
       "      <td>74</td>\n",
       "      <td>203</td>\n",
       "      <td>74</td>\n",
       "      <td>203</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>169</td>\n",
       "      <td>10.883638</td>\n",
       "      <td>10.883638</td>\n",
       "      <td>21.767277</td>\n",
       "      <td>3.014768e+03</td>\n",
       "      <td>138.500000</td>\n",
       "      <td>91.216774</td>\n",
       "      <td>0.091881</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.743243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41432 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           proto        srcPrt    dstPrt  flowduration  total_fpackets  \\\n",
       "144590  0.002892  8.308825e-04  0.000042      0.057055               1   \n",
       "174762  0.002892  3.089455e-03  0.000042      0.093740               1   \n",
       "20836   0.004343  5.556759e-05  0.004387     15.021914               6   \n",
       "161575  0.002892  8.308825e-04  0.000042      0.000183               1   \n",
       "41335   0.002892  4.290636e-14  0.000042      0.608493               2   \n",
       "...          ...           ...       ...           ...             ...   \n",
       "131731  0.002892  3.089455e-03  0.000042     30.023242               3   \n",
       "4393    0.004343  8.308825e-04  0.004387      5.741911              23   \n",
       "476     0.004343  3.812220e-07  0.004387     62.587642               8   \n",
       "61237   0.002892  3.682721e-04  0.000042      0.000295               1   \n",
       "107563  0.002892  2.067726e-05  0.000042      0.091881               1   \n",
       "\n",
       "        total_bpackets  total_fpktl  total_bpktl  min_fpktl  min_bpktl  \\\n",
       "144590               1           75          289         75        289   \n",
       "174762               1           81          354         81        354   \n",
       "20836                4         1018          848         60         54   \n",
       "161575               1           85          136         85        136   \n",
       "41335                2          122          540         61        270   \n",
       "...                ...          ...          ...        ...        ...   \n",
       "131731               3          219          219         73         73   \n",
       "4393                23         5436        21569         66         66   \n",
       "476                 10          982         8373         60         54   \n",
       "61237                1           86          170         86        170   \n",
       "107563               1           74          203         74        203   \n",
       "\n",
       "        max_fpktl  max_bpktl  mean_fpktl  mean_bpktl   std_fpktl   std_bpktl  \\\n",
       "144590         75        289   75.000000  289.000000    0.000000    0.000000   \n",
       "174762         81        354   81.000000  354.000000    0.000000    0.000000   \n",
       "20836         712        674  169.666672  212.000000  265.698827  308.051944   \n",
       "161575         85        136   85.000000  136.000000    0.000000    0.000000   \n",
       "41335          61        270   61.000000  270.000000    0.000000    0.000000   \n",
       "...           ...        ...         ...         ...         ...         ...   \n",
       "131731         73         73   73.000000   73.000000    0.000000    0.000000   \n",
       "4393          852       1434  236.347824  937.782593  329.620933  593.587931   \n",
       "476           556       1434  122.750000  837.299988  175.072026  685.954010   \n",
       "61237          86        170   86.000000  170.000000    0.000000    0.000000   \n",
       "107563         74        203   74.000000  203.000000    0.000000    0.000000   \n",
       "\n",
       "        total_fipt  total_bipt   min_fipt  min_bipt   max_fipt   max_bipt  \\\n",
       "144590    0.000000    0.000000   0.000000  0.000000   0.000000   0.000000   \n",
       "174762    0.000000    0.000000   0.000000  0.000000   0.000000   0.000000   \n",
       "20836    15.021914    6.389717   0.009656  0.030542   8.612408   5.008085   \n",
       "161575    0.000000    0.000000   0.000000  0.000000   0.000000   0.000000   \n",
       "41335     0.608157    0.608155   0.608157  0.608155   0.608157   0.608155   \n",
       "...            ...         ...        ...       ...        ...        ...   \n",
       "131731   20.049953    0.000148  10.022589  0.000010  10.027365   0.000138   \n",
       "4393      5.741901    5.741894   0.000012  0.000007   5.001964   5.005466   \n",
       "476      62.587625   62.587623   0.012259  0.000007  57.512791  57.526875   \n",
       "61237     0.000000    0.000000   0.000000  0.000000   0.000000   0.000000   \n",
       "107563    0.000000    0.000000   0.000000  0.000000   0.000000   0.000000   \n",
       "\n",
       "        mean_fipt  mean_bipt   std_fipt   std_bipt  fpsh_cnt  bpsh_cnt  \\\n",
       "144590   0.000000   0.000000   0.000000   0.000000         0         0   \n",
       "174762   0.000000   0.000000   0.000000   0.000000         0         0   \n",
       "20836    3.004383   2.129906   3.693772   2.578546         1         1   \n",
       "161575   0.000000   0.000000   0.000000   0.000000         0         0   \n",
       "41335    0.608157   0.608155   0.000000   0.000000         0         0   \n",
       "...           ...        ...        ...        ...       ...       ...   \n",
       "131731  10.024977   0.000074   0.003377   0.000091         0         0   \n",
       "4393     0.260995   0.260995   1.059760   1.061274         5         8   \n",
       "476      8.941089   6.954180  21.496969  19.035740         1         2   \n",
       "61237    0.000000   0.000000   0.000000   0.000000         0         0   \n",
       "107563   0.000000   0.000000   0.000000   0.000000         0         0   \n",
       "\n",
       "        furg_cnt  burg_cnt  total_fhlen  total_bhlen  fPktsPerSecond  \\\n",
       "144590         0         0           41          255       17.526949   \n",
       "174762         0         0           47          320       10.667779   \n",
       "20836          0         0          132           92        0.399417   \n",
       "161575         0         0           51          102     5461.333496   \n",
       "41335          0         0           54          472        3.286808   \n",
       "...          ...       ...          ...          ...             ...   \n",
       "131731         0         0          117          117        0.099923   \n",
       "4393           0         0          744          748        4.005635   \n",
       "476            0         0          172          212        0.127821   \n",
       "61237          0         0           52          136     3390.706543   \n",
       "107563         0         0           40          169       10.883638   \n",
       "\n",
       "        bPktsPerSecond  flowPktsPerSecond  flowBytesPerSecond  mean_flowpktl  \\\n",
       "144590       17.526949          35.053898        6.379810e+03     182.000000   \n",
       "174762       10.667779          21.335558        4.640484e+03     217.500000   \n",
       "20836         0.266278           0.665694        1.242185e+02     186.600000   \n",
       "161575     5461.333496       10922.666992        1.206955e+06     110.500000   \n",
       "41335         3.286808           6.573616        1.087933e+03     165.500000   \n",
       "...                ...                ...                 ...            ...   \n",
       "131731        0.099923           0.199845        1.458870e+01      73.000000   \n",
       "4393          4.005635           8.011271        4.703138e+03     587.065217   \n",
       "476           0.159776           0.287597        1.494704e+02     519.722222   \n",
       "61237      3390.706543        6781.413086        8.680209e+05     128.000000   \n",
       "107563       10.883638          21.767277        3.014768e+03     138.500000   \n",
       "\n",
       "        std_flowpktl  mean_flowipt  std_flowipt  flow_fin  flow_syn  flow_rst  \\\n",
       "144590    151.320847      0.057055     0.000000         0         0         0   \n",
       "174762    193.040146      0.093740     0.000000         0         0         0   \n",
       "20836     267.076447      2.350367     3.055030         1         2         1   \n",
       "161575     36.062447      0.000183     0.000000         0         0         0   \n",
       "41335     120.666206      0.202944     0.350925         0         0         0   \n",
       "...              ...           ...          ...       ...       ...       ...   \n",
       "131731      0.000000      6.004648     5.481442         0         0         0   \n",
       "4393      592.547241      0.236708     1.029460         2         2         0   \n",
       "476       628.658691      3.973791    13.893184         2         2         0   \n",
       "61237      59.396969      0.000295     0.000000         0         0         0   \n",
       "107563     91.216774      0.091881     0.000000         0         0         0   \n",
       "\n",
       "        flow_ack  flow_urg  flow_cwr  flow_ece  downUpRatio  \n",
       "144590         0         0         0         0     3.853333  \n",
       "174762         0         0         0         0     4.370370  \n",
       "20836          9         0         0         0     0.833006  \n",
       "161575         0         0         0         0     1.600000  \n",
       "41335          0         0         0         0     4.426229  \n",
       "...          ...       ...       ...       ...          ...  \n",
       "131731         0         0         0         0     1.000000  \n",
       "4393          45         0         0         0     3.967807  \n",
       "476           17         0         0         0     8.526477  \n",
       "61237          0         0         0         0     1.976744  \n",
       "107563         0         0         0         0     2.743243  \n",
       "\n",
       "[41432 rows x 48 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show testing dataset\n",
    "testing_numeric_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardization and scaling of numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_cols = training_numeric_dataset.select_dtypes(include=['float64', 'int']).columns.to_list()\n",
    "preprocessor = ColumnTransformer([('scale', StandardScaler(), numeric_cols)], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit on the trainning dataset\n",
    "preprocessor.fit_transform(training_numeric_dataset)\n",
    "X_train_stand = preprocessor.transform(training_numeric_dataset)\n",
    "X_test_stand  = preprocessor.transform(testing_numeric_dataset)\n",
    "#The result returned by ColumnTransformer is a numpy array, so the column names are lost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-generate the dataset as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=list(training_numeric_dataset.columns.values.tolist())\n",
    "df_X_train_stand=pd.DataFrame(X_train_stand,columns=labels)\n",
    "df_X_test_stand=pd.DataFrame(X_test_stand,columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proto</th>\n",
       "      <th>srcPrt</th>\n",
       "      <th>dstPrt</th>\n",
       "      <th>flowduration</th>\n",
       "      <th>total_fpackets</th>\n",
       "      <th>total_bpackets</th>\n",
       "      <th>total_fpktl</th>\n",
       "      <th>total_bpktl</th>\n",
       "      <th>min_fpktl</th>\n",
       "      <th>min_bpktl</th>\n",
       "      <th>max_fpktl</th>\n",
       "      <th>max_bpktl</th>\n",
       "      <th>mean_fpktl</th>\n",
       "      <th>mean_bpktl</th>\n",
       "      <th>std_fpktl</th>\n",
       "      <th>std_bpktl</th>\n",
       "      <th>total_fipt</th>\n",
       "      <th>total_bipt</th>\n",
       "      <th>min_fipt</th>\n",
       "      <th>min_bipt</th>\n",
       "      <th>max_fipt</th>\n",
       "      <th>max_bipt</th>\n",
       "      <th>mean_fipt</th>\n",
       "      <th>mean_bipt</th>\n",
       "      <th>std_fipt</th>\n",
       "      <th>std_bipt</th>\n",
       "      <th>fpsh_cnt</th>\n",
       "      <th>bpsh_cnt</th>\n",
       "      <th>furg_cnt</th>\n",
       "      <th>burg_cnt</th>\n",
       "      <th>total_fhlen</th>\n",
       "      <th>total_bhlen</th>\n",
       "      <th>fPktsPerSecond</th>\n",
       "      <th>bPktsPerSecond</th>\n",
       "      <th>flowPktsPerSecond</th>\n",
       "      <th>flowBytesPerSecond</th>\n",
       "      <th>mean_flowpktl</th>\n",
       "      <th>std_flowpktl</th>\n",
       "      <th>mean_flowipt</th>\n",
       "      <th>std_flowipt</th>\n",
       "      <th>flow_fin</th>\n",
       "      <th>flow_syn</th>\n",
       "      <th>flow_rst</th>\n",
       "      <th>flow_ack</th>\n",
       "      <th>flow_urg</th>\n",
       "      <th>flow_cwr</th>\n",
       "      <th>flow_ece</th>\n",
       "      <th>downUpRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.518732</td>\n",
       "      <td>-0.066967</td>\n",
       "      <td>0.09856</td>\n",
       "      <td>-0.011443</td>\n",
       "      <td>0.191268</td>\n",
       "      <td>0.306014</td>\n",
       "      <td>0.006471</td>\n",
       "      <td>0.340342</td>\n",
       "      <td>-0.907314</td>\n",
       "      <td>-0.702460</td>\n",
       "      <td>1.852141</td>\n",
       "      <td>2.991803</td>\n",
       "      <td>-0.606705</td>\n",
       "      <td>4.703384</td>\n",
       "      <td>0.423317</td>\n",
       "      <td>1.009757</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>0.046772</td>\n",
       "      <td>-0.201367</td>\n",
       "      <td>-0.096527</td>\n",
       "      <td>0.067811</td>\n",
       "      <td>0.145794</td>\n",
       "      <td>-0.255675</td>\n",
       "      <td>-0.154274</td>\n",
       "      <td>-0.122918</td>\n",
       "      <td>-0.102339</td>\n",
       "      <td>-0.007881</td>\n",
       "      <td>0.528190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.224615</td>\n",
       "      <td>0.265866</td>\n",
       "      <td>-0.229440</td>\n",
       "      <td>-0.252831</td>\n",
       "      <td>-0.251250</td>\n",
       "      <td>-0.327730</td>\n",
       "      <td>4.972696</td>\n",
       "      <td>3.445108</td>\n",
       "      <td>-0.396509</td>\n",
       "      <td>-0.199340</td>\n",
       "      <td>2.784526</td>\n",
       "      <td>2.476054</td>\n",
       "      <td>-0.150798</td>\n",
       "      <td>0.265856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.046623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.397025</td>\n",
       "      <td>-0.050652</td>\n",
       "      <td>-0.05044</td>\n",
       "      <td>-0.074769</td>\n",
       "      <td>-0.019826</td>\n",
       "      <td>-0.019120</td>\n",
       "      <td>-0.009393</td>\n",
       "      <td>-0.013940</td>\n",
       "      <td>0.151494</td>\n",
       "      <td>0.265570</td>\n",
       "      <td>-0.323013</td>\n",
       "      <td>-0.294656</td>\n",
       "      <td>-0.144867</td>\n",
       "      <td>-0.210466</td>\n",
       "      <td>-0.330526</td>\n",
       "      <td>-0.347526</td>\n",
       "      <td>-0.061876</td>\n",
       "      <td>-0.065519</td>\n",
       "      <td>-0.201584</td>\n",
       "      <td>-0.096528</td>\n",
       "      <td>-0.317501</td>\n",
       "      <td>-0.202109</td>\n",
       "      <td>-0.265029</td>\n",
       "      <td>-0.160461</td>\n",
       "      <td>-0.236612</td>\n",
       "      <td>-0.176743</td>\n",
       "      <td>-0.011500</td>\n",
       "      <td>-0.014573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.023832</td>\n",
       "      <td>-0.027449</td>\n",
       "      <td>0.527619</td>\n",
       "      <td>0.659091</td>\n",
       "      <td>0.614623</td>\n",
       "      <td>1.053806</td>\n",
       "      <td>-0.233110</td>\n",
       "      <td>-0.315703</td>\n",
       "      <td>-0.402527</td>\n",
       "      <td>-0.282505</td>\n",
       "      <td>-0.349100</td>\n",
       "      <td>-0.383596</td>\n",
       "      <td>-0.150798</td>\n",
       "      <td>-0.018744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.176085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.397025</td>\n",
       "      <td>-0.065053</td>\n",
       "      <td>-0.05044</td>\n",
       "      <td>-0.068546</td>\n",
       "      <td>-0.019826</td>\n",
       "      <td>-0.019120</td>\n",
       "      <td>-0.009420</td>\n",
       "      <td>-0.014024</td>\n",
       "      <td>-0.483791</td>\n",
       "      <td>-0.530366</td>\n",
       "      <td>-0.426591</td>\n",
       "      <td>-0.483181</td>\n",
       "      <td>-0.562830</td>\n",
       "      <td>-0.501421</td>\n",
       "      <td>-0.330526</td>\n",
       "      <td>-0.347526</td>\n",
       "      <td>-0.061876</td>\n",
       "      <td>-0.065519</td>\n",
       "      <td>-0.201584</td>\n",
       "      <td>-0.096528</td>\n",
       "      <td>-0.317501</td>\n",
       "      <td>-0.202109</td>\n",
       "      <td>-0.265029</td>\n",
       "      <td>-0.160461</td>\n",
       "      <td>-0.236612</td>\n",
       "      <td>-0.176743</td>\n",
       "      <td>-0.011500</td>\n",
       "      <td>-0.014573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.024961</td>\n",
       "      <td>-0.032362</td>\n",
       "      <td>-0.231161</td>\n",
       "      <td>-0.256452</td>\n",
       "      <td>-0.253953</td>\n",
       "      <td>-0.364350</td>\n",
       "      <td>-0.527862</td>\n",
       "      <td>-0.567370</td>\n",
       "      <td>-0.261140</td>\n",
       "      <td>-0.282505</td>\n",
       "      <td>-0.349100</td>\n",
       "      <td>-0.383596</td>\n",
       "      <td>-0.150798</td>\n",
       "      <td>-0.018744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.329589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.397025</td>\n",
       "      <td>-0.060387</td>\n",
       "      <td>-0.05044</td>\n",
       "      <td>-0.073549</td>\n",
       "      <td>-0.019826</td>\n",
       "      <td>-0.019120</td>\n",
       "      <td>-0.009421</td>\n",
       "      <td>-0.014025</td>\n",
       "      <td>-0.526143</td>\n",
       "      <td>-0.541122</td>\n",
       "      <td>-0.433497</td>\n",
       "      <td>-0.485729</td>\n",
       "      <td>-0.590694</td>\n",
       "      <td>-0.505352</td>\n",
       "      <td>-0.330526</td>\n",
       "      <td>-0.347526</td>\n",
       "      <td>-0.061876</td>\n",
       "      <td>-0.065519</td>\n",
       "      <td>-0.201584</td>\n",
       "      <td>-0.096528</td>\n",
       "      <td>-0.317501</td>\n",
       "      <td>-0.202109</td>\n",
       "      <td>-0.265029</td>\n",
       "      <td>-0.160461</td>\n",
       "      <td>-0.236612</td>\n",
       "      <td>-0.176743</td>\n",
       "      <td>-0.011500</td>\n",
       "      <td>-0.014573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.025037</td>\n",
       "      <td>-0.032429</td>\n",
       "      <td>-0.230582</td>\n",
       "      <td>-0.255752</td>\n",
       "      <td>-0.253290</td>\n",
       "      <td>-0.363699</td>\n",
       "      <td>-0.534486</td>\n",
       "      <td>-0.567370</td>\n",
       "      <td>-0.374817</td>\n",
       "      <td>-0.282505</td>\n",
       "      <td>-0.349100</td>\n",
       "      <td>-0.383596</td>\n",
       "      <td>-0.150798</td>\n",
       "      <td>-0.018744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.329589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.397025</td>\n",
       "      <td>-0.068137</td>\n",
       "      <td>-0.05044</td>\n",
       "      <td>-0.043042</td>\n",
       "      <td>-0.018239</td>\n",
       "      <td>-0.017675</td>\n",
       "      <td>-0.009187</td>\n",
       "      <td>-0.013768</td>\n",
       "      <td>0.702074</td>\n",
       "      <td>0.276326</td>\n",
       "      <td>-0.184908</td>\n",
       "      <td>-0.274275</td>\n",
       "      <td>0.314891</td>\n",
       "      <td>-0.192773</td>\n",
       "      <td>-0.240197</td>\n",
       "      <td>-0.316924</td>\n",
       "      <td>-0.030658</td>\n",
       "      <td>-0.010296</td>\n",
       "      <td>0.483377</td>\n",
       "      <td>0.743168</td>\n",
       "      <td>0.055518</td>\n",
       "      <td>0.131152</td>\n",
       "      <td>0.346821</td>\n",
       "      <td>0.524146</td>\n",
       "      <td>-0.236612</td>\n",
       "      <td>-0.176743</td>\n",
       "      <td>-0.011500</td>\n",
       "      <td>-0.014573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.017510</td>\n",
       "      <td>-0.019549</td>\n",
       "      <td>-0.231247</td>\n",
       "      <td>-0.256555</td>\n",
       "      <td>-0.254052</td>\n",
       "      <td>-0.364398</td>\n",
       "      <td>-0.163562</td>\n",
       "      <td>-0.401873</td>\n",
       "      <td>-0.157833</td>\n",
       "      <td>0.288263</td>\n",
       "      <td>-0.349100</td>\n",
       "      <td>-0.383596</td>\n",
       "      <td>-0.150798</td>\n",
       "      <td>-0.018744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.227185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165720</th>\n",
       "      <td>-0.397025</td>\n",
       "      <td>-0.068077</td>\n",
       "      <td>-0.05044</td>\n",
       "      <td>-0.072237</td>\n",
       "      <td>-0.019826</td>\n",
       "      <td>-0.019120</td>\n",
       "      <td>-0.009418</td>\n",
       "      <td>-0.014023</td>\n",
       "      <td>-0.441438</td>\n",
       "      <td>-0.519610</td>\n",
       "      <td>-0.419686</td>\n",
       "      <td>-0.480634</td>\n",
       "      <td>-0.534965</td>\n",
       "      <td>-0.497489</td>\n",
       "      <td>-0.330526</td>\n",
       "      <td>-0.347526</td>\n",
       "      <td>-0.061876</td>\n",
       "      <td>-0.065519</td>\n",
       "      <td>-0.201584</td>\n",
       "      <td>-0.096528</td>\n",
       "      <td>-0.317501</td>\n",
       "      <td>-0.202109</td>\n",
       "      <td>-0.265029</td>\n",
       "      <td>-0.160461</td>\n",
       "      <td>-0.236612</td>\n",
       "      <td>-0.176743</td>\n",
       "      <td>-0.011500</td>\n",
       "      <td>-0.014573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.024886</td>\n",
       "      <td>-0.032296</td>\n",
       "      <td>-0.230955</td>\n",
       "      <td>-0.256203</td>\n",
       "      <td>-0.253717</td>\n",
       "      <td>-0.364108</td>\n",
       "      <td>-0.521238</td>\n",
       "      <td>-0.567370</td>\n",
       "      <td>-0.345005</td>\n",
       "      <td>-0.282505</td>\n",
       "      <td>-0.349100</td>\n",
       "      <td>-0.383596</td>\n",
       "      <td>-0.150798</td>\n",
       "      <td>-0.018744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.329589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165721</th>\n",
       "      <td>-0.397025</td>\n",
       "      <td>-0.066967</td>\n",
       "      <td>-0.05044</td>\n",
       "      <td>-0.074289</td>\n",
       "      <td>-0.019826</td>\n",
       "      <td>-0.019120</td>\n",
       "      <td>-0.009395</td>\n",
       "      <td>-0.013607</td>\n",
       "      <td>0.109142</td>\n",
       "      <td>3.449312</td>\n",
       "      <td>-0.329918</td>\n",
       "      <td>0.459446</td>\n",
       "      <td>-0.172731</td>\n",
       "      <td>0.953352</td>\n",
       "      <td>-0.330526</td>\n",
       "      <td>-0.347526</td>\n",
       "      <td>-0.061876</td>\n",
       "      <td>-0.065519</td>\n",
       "      <td>-0.201584</td>\n",
       "      <td>-0.096528</td>\n",
       "      <td>-0.317501</td>\n",
       "      <td>-0.202109</td>\n",
       "      <td>-0.265029</td>\n",
       "      <td>-0.160461</td>\n",
       "      <td>-0.236612</td>\n",
       "      <td>-0.176743</td>\n",
       "      <td>-0.011500</td>\n",
       "      <td>-0.014573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.023908</td>\n",
       "      <td>-0.007798</td>\n",
       "      <td>-0.229473</td>\n",
       "      <td>-0.254414</td>\n",
       "      <td>-0.252021</td>\n",
       "      <td>-0.356686</td>\n",
       "      <td>0.743875</td>\n",
       "      <td>0.951161</td>\n",
       "      <td>-0.391621</td>\n",
       "      <td>-0.282505</td>\n",
       "      <td>-0.349100</td>\n",
       "      <td>-0.383596</td>\n",
       "      <td>-0.150798</td>\n",
       "      <td>-0.018744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.607665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165722</th>\n",
       "      <td>-0.397025</td>\n",
       "      <td>-0.050652</td>\n",
       "      <td>-0.05044</td>\n",
       "      <td>-0.071724</td>\n",
       "      <td>-0.019826</td>\n",
       "      <td>-0.019120</td>\n",
       "      <td>-0.009407</td>\n",
       "      <td>-0.014016</td>\n",
       "      <td>-0.187324</td>\n",
       "      <td>-0.455075</td>\n",
       "      <td>-0.378255</td>\n",
       "      <td>-0.465348</td>\n",
       "      <td>-0.367781</td>\n",
       "      <td>-0.473898</td>\n",
       "      <td>-0.330526</td>\n",
       "      <td>-0.347526</td>\n",
       "      <td>-0.061876</td>\n",
       "      <td>-0.065519</td>\n",
       "      <td>-0.201584</td>\n",
       "      <td>-0.096528</td>\n",
       "      <td>-0.317501</td>\n",
       "      <td>-0.202109</td>\n",
       "      <td>-0.265029</td>\n",
       "      <td>-0.160461</td>\n",
       "      <td>-0.236612</td>\n",
       "      <td>-0.176743</td>\n",
       "      <td>-0.011500</td>\n",
       "      <td>-0.014573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.024434</td>\n",
       "      <td>-0.031898</td>\n",
       "      <td>-0.231014</td>\n",
       "      <td>-0.256273</td>\n",
       "      <td>-0.253784</td>\n",
       "      <td>-0.364148</td>\n",
       "      <td>-0.481496</td>\n",
       "      <td>-0.567370</td>\n",
       "      <td>-0.333340</td>\n",
       "      <td>-0.282505</td>\n",
       "      <td>-0.349100</td>\n",
       "      <td>-0.383596</td>\n",
       "      <td>-0.150798</td>\n",
       "      <td>-0.018744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.329589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165723</th>\n",
       "      <td>-0.397025</td>\n",
       "      <td>-0.068137</td>\n",
       "      <td>-0.05044</td>\n",
       "      <td>0.234753</td>\n",
       "      <td>-0.010303</td>\n",
       "      <td>-0.013340</td>\n",
       "      <td>-0.008476</td>\n",
       "      <td>-0.011869</td>\n",
       "      <td>0.151494</td>\n",
       "      <td>2.986809</td>\n",
       "      <td>-0.240150</td>\n",
       "      <td>0.349898</td>\n",
       "      <td>-0.085158</td>\n",
       "      <td>0.784284</td>\n",
       "      <td>-0.248622</td>\n",
       "      <td>-0.347526</td>\n",
       "      <td>0.248352</td>\n",
       "      <td>-0.065514</td>\n",
       "      <td>-0.201583</td>\n",
       "      <td>-0.096525</td>\n",
       "      <td>2.903815</td>\n",
       "      <td>-0.202082</td>\n",
       "      <td>0.748342</td>\n",
       "      <td>-0.160446</td>\n",
       "      <td>3.614087</td>\n",
       "      <td>-0.176709</td>\n",
       "      <td>-0.011500</td>\n",
       "      <td>-0.014573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.085747</td>\n",
       "      <td>-0.231283</td>\n",
       "      <td>-0.256605</td>\n",
       "      <td>-0.254096</td>\n",
       "      <td>-0.364451</td>\n",
       "      <td>0.440844</td>\n",
       "      <td>0.395330</td>\n",
       "      <td>0.238004</td>\n",
       "      <td>2.330269</td>\n",
       "      <td>-0.349100</td>\n",
       "      <td>-0.383596</td>\n",
       "      <td>-0.150798</td>\n",
       "      <td>-0.018744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.168905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165724</th>\n",
       "      <td>-0.397025</td>\n",
       "      <td>-0.068137</td>\n",
       "      <td>-0.05044</td>\n",
       "      <td>-0.070424</td>\n",
       "      <td>-0.018239</td>\n",
       "      <td>-0.017675</td>\n",
       "      <td>-0.009236</td>\n",
       "      <td>-0.013906</td>\n",
       "      <td>0.024437</td>\n",
       "      <td>-0.401295</td>\n",
       "      <td>-0.267771</td>\n",
       "      <td>-0.424585</td>\n",
       "      <td>-0.075207</td>\n",
       "      <td>-0.432614</td>\n",
       "      <td>-0.188581</td>\n",
       "      <td>-0.299437</td>\n",
       "      <td>-0.059700</td>\n",
       "      <td>-0.061660</td>\n",
       "      <td>-0.153833</td>\n",
       "      <td>-0.037854</td>\n",
       "      <td>-0.291497</td>\n",
       "      <td>-0.178822</td>\n",
       "      <td>-0.222375</td>\n",
       "      <td>-0.112624</td>\n",
       "      <td>-0.236612</td>\n",
       "      <td>-0.176743</td>\n",
       "      <td>-0.011500</td>\n",
       "      <td>-0.014573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.019618</td>\n",
       "      <td>-0.027649</td>\n",
       "      <td>-0.230898</td>\n",
       "      <td>-0.256133</td>\n",
       "      <td>-0.253651</td>\n",
       "      <td>-0.363933</td>\n",
       "      <td>-0.411948</td>\n",
       "      <td>-0.529059</td>\n",
       "      <td>-0.353203</td>\n",
       "      <td>-0.282426</td>\n",
       "      <td>-0.349100</td>\n",
       "      <td>-0.383596</td>\n",
       "      <td>-0.150798</td>\n",
       "      <td>-0.018744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.329589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165725 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           proto    srcPrt   dstPrt  flowduration  total_fpackets  \\\n",
       "0       2.518732 -0.066967  0.09856     -0.011443        0.191268   \n",
       "1      -0.397025 -0.050652 -0.05044     -0.074769       -0.019826   \n",
       "2      -0.397025 -0.065053 -0.05044     -0.068546       -0.019826   \n",
       "3      -0.397025 -0.060387 -0.05044     -0.073549       -0.019826   \n",
       "4      -0.397025 -0.068137 -0.05044     -0.043042       -0.018239   \n",
       "...          ...       ...      ...           ...             ...   \n",
       "165720 -0.397025 -0.068077 -0.05044     -0.072237       -0.019826   \n",
       "165721 -0.397025 -0.066967 -0.05044     -0.074289       -0.019826   \n",
       "165722 -0.397025 -0.050652 -0.05044     -0.071724       -0.019826   \n",
       "165723 -0.397025 -0.068137 -0.05044      0.234753       -0.010303   \n",
       "165724 -0.397025 -0.068137 -0.05044     -0.070424       -0.018239   \n",
       "\n",
       "        total_bpackets  total_fpktl  total_bpktl  min_fpktl  min_bpktl  \\\n",
       "0             0.306014     0.006471     0.340342  -0.907314  -0.702460   \n",
       "1            -0.019120    -0.009393    -0.013940   0.151494   0.265570   \n",
       "2            -0.019120    -0.009420    -0.014024  -0.483791  -0.530366   \n",
       "3            -0.019120    -0.009421    -0.014025  -0.526143  -0.541122   \n",
       "4            -0.017675    -0.009187    -0.013768   0.702074   0.276326   \n",
       "...                ...          ...          ...        ...        ...   \n",
       "165720       -0.019120    -0.009418    -0.014023  -0.441438  -0.519610   \n",
       "165721       -0.019120    -0.009395    -0.013607   0.109142   3.449312   \n",
       "165722       -0.019120    -0.009407    -0.014016  -0.187324  -0.455075   \n",
       "165723       -0.013340    -0.008476    -0.011869   0.151494   2.986809   \n",
       "165724       -0.017675    -0.009236    -0.013906   0.024437  -0.401295   \n",
       "\n",
       "        max_fpktl  max_bpktl  mean_fpktl  mean_bpktl  std_fpktl  std_bpktl  \\\n",
       "0        1.852141   2.991803   -0.606705    4.703384   0.423317   1.009757   \n",
       "1       -0.323013  -0.294656   -0.144867   -0.210466  -0.330526  -0.347526   \n",
       "2       -0.426591  -0.483181   -0.562830   -0.501421  -0.330526  -0.347526   \n",
       "3       -0.433497  -0.485729   -0.590694   -0.505352  -0.330526  -0.347526   \n",
       "4       -0.184908  -0.274275    0.314891   -0.192773  -0.240197  -0.316924   \n",
       "...           ...        ...         ...         ...        ...        ...   \n",
       "165720  -0.419686  -0.480634   -0.534965   -0.497489  -0.330526  -0.347526   \n",
       "165721  -0.329918   0.459446   -0.172731    0.953352  -0.330526  -0.347526   \n",
       "165722  -0.378255  -0.465348   -0.367781   -0.473898  -0.330526  -0.347526   \n",
       "165723  -0.240150   0.349898   -0.085158    0.784284  -0.248622  -0.347526   \n",
       "165724  -0.267771  -0.424585   -0.075207   -0.432614  -0.188581  -0.299437   \n",
       "\n",
       "        total_fipt  total_bipt  min_fipt  min_bipt  max_fipt  max_bipt  \\\n",
       "0         0.001595    0.046772 -0.201367 -0.096527  0.067811  0.145794   \n",
       "1        -0.061876   -0.065519 -0.201584 -0.096528 -0.317501 -0.202109   \n",
       "2        -0.061876   -0.065519 -0.201584 -0.096528 -0.317501 -0.202109   \n",
       "3        -0.061876   -0.065519 -0.201584 -0.096528 -0.317501 -0.202109   \n",
       "4        -0.030658   -0.010296  0.483377  0.743168  0.055518  0.131152   \n",
       "...            ...         ...       ...       ...       ...       ...   \n",
       "165720   -0.061876   -0.065519 -0.201584 -0.096528 -0.317501 -0.202109   \n",
       "165721   -0.061876   -0.065519 -0.201584 -0.096528 -0.317501 -0.202109   \n",
       "165722   -0.061876   -0.065519 -0.201584 -0.096528 -0.317501 -0.202109   \n",
       "165723    0.248352   -0.065514 -0.201583 -0.096525  2.903815 -0.202082   \n",
       "165724   -0.059700   -0.061660 -0.153833 -0.037854 -0.291497 -0.178822   \n",
       "\n",
       "        mean_fipt  mean_bipt  std_fipt  std_bipt  fpsh_cnt  bpsh_cnt  \\\n",
       "0       -0.255675  -0.154274 -0.122918 -0.102339 -0.007881  0.528190   \n",
       "1       -0.265029  -0.160461 -0.236612 -0.176743 -0.011500 -0.014573   \n",
       "2       -0.265029  -0.160461 -0.236612 -0.176743 -0.011500 -0.014573   \n",
       "3       -0.265029  -0.160461 -0.236612 -0.176743 -0.011500 -0.014573   \n",
       "4        0.346821   0.524146 -0.236612 -0.176743 -0.011500 -0.014573   \n",
       "...           ...        ...       ...       ...       ...       ...   \n",
       "165720  -0.265029  -0.160461 -0.236612 -0.176743 -0.011500 -0.014573   \n",
       "165721  -0.265029  -0.160461 -0.236612 -0.176743 -0.011500 -0.014573   \n",
       "165722  -0.265029  -0.160461 -0.236612 -0.176743 -0.011500 -0.014573   \n",
       "165723   0.748342  -0.160446  3.614087 -0.176709 -0.011500 -0.014573   \n",
       "165724  -0.222375  -0.112624 -0.236612 -0.176743 -0.011500 -0.014573   \n",
       "\n",
       "        furg_cnt  burg_cnt  total_fhlen  total_bhlen  fPktsPerSecond  \\\n",
       "0            0.0       0.0     0.224615     0.265866       -0.229440   \n",
       "1            0.0       0.0    -0.023832    -0.027449        0.527619   \n",
       "2            0.0       0.0    -0.024961    -0.032362       -0.231161   \n",
       "3            0.0       0.0    -0.025037    -0.032429       -0.230582   \n",
       "4            0.0       0.0    -0.017510    -0.019549       -0.231247   \n",
       "...          ...       ...          ...          ...             ...   \n",
       "165720       0.0       0.0    -0.024886    -0.032296       -0.230955   \n",
       "165721       0.0       0.0    -0.023908    -0.007798       -0.229473   \n",
       "165722       0.0       0.0    -0.024434    -0.031898       -0.231014   \n",
       "165723       0.0       0.0     0.000328     0.085747       -0.231283   \n",
       "165724       0.0       0.0    -0.019618    -0.027649       -0.230898   \n",
       "\n",
       "        bPktsPerSecond  flowPktsPerSecond  flowBytesPerSecond  mean_flowpktl  \\\n",
       "0            -0.252831          -0.251250           -0.327730       4.972696   \n",
       "1             0.659091           0.614623            1.053806      -0.233110   \n",
       "2            -0.256452          -0.253953           -0.364350      -0.527862   \n",
       "3            -0.255752          -0.253290           -0.363699      -0.534486   \n",
       "4            -0.256555          -0.254052           -0.364398      -0.163562   \n",
       "...                ...                ...                 ...            ...   \n",
       "165720       -0.256203          -0.253717           -0.364108      -0.521238   \n",
       "165721       -0.254414          -0.252021           -0.356686       0.743875   \n",
       "165722       -0.256273          -0.253784           -0.364148      -0.481496   \n",
       "165723       -0.256605          -0.254096           -0.364451       0.440844   \n",
       "165724       -0.256133          -0.253651           -0.363933      -0.411948   \n",
       "\n",
       "        std_flowpktl  mean_flowipt  std_flowipt  flow_fin  flow_syn  flow_rst  \\\n",
       "0           3.445108     -0.396509    -0.199340  2.784526  2.476054 -0.150798   \n",
       "1          -0.315703     -0.402527    -0.282505 -0.349100 -0.383596 -0.150798   \n",
       "2          -0.567370     -0.261140    -0.282505 -0.349100 -0.383596 -0.150798   \n",
       "3          -0.567370     -0.374817    -0.282505 -0.349100 -0.383596 -0.150798   \n",
       "4          -0.401873     -0.157833     0.288263 -0.349100 -0.383596 -0.150798   \n",
       "...              ...           ...          ...       ...       ...       ...   \n",
       "165720     -0.567370     -0.345005    -0.282505 -0.349100 -0.383596 -0.150798   \n",
       "165721      0.951161     -0.391621    -0.282505 -0.349100 -0.383596 -0.150798   \n",
       "165722     -0.567370     -0.333340    -0.282505 -0.349100 -0.383596 -0.150798   \n",
       "165723      0.395330      0.238004     2.330269 -0.349100 -0.383596 -0.150798   \n",
       "165724     -0.529059     -0.353203    -0.282426 -0.349100 -0.383596 -0.150798   \n",
       "\n",
       "        flow_ack  flow_urg  flow_cwr  flow_ece  downUpRatio  \n",
       "0       0.265856       0.0 -0.004913       0.0     7.046623  \n",
       "1      -0.018744       0.0 -0.004913       0.0    -0.176085  \n",
       "2      -0.018744       0.0 -0.004913       0.0    -0.329589  \n",
       "3      -0.018744       0.0 -0.004913       0.0    -0.329589  \n",
       "4      -0.018744       0.0 -0.004913       0.0    -0.227185  \n",
       "...          ...       ...       ...       ...          ...  \n",
       "165720 -0.018744       0.0 -0.004913       0.0    -0.329589  \n",
       "165721 -0.018744       0.0 -0.004913       0.0     0.607665  \n",
       "165722 -0.018744       0.0 -0.004913       0.0    -0.329589  \n",
       "165723 -0.018744       0.0 -0.004913       0.0     0.168905  \n",
       "165724 -0.018744       0.0 -0.004913       0.0    -0.329589  \n",
       "\n",
       "[165725 rows x 48 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_train_stand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proto</th>\n",
       "      <th>srcPrt</th>\n",
       "      <th>dstPrt</th>\n",
       "      <th>flowduration</th>\n",
       "      <th>total_fpackets</th>\n",
       "      <th>total_bpackets</th>\n",
       "      <th>total_fpktl</th>\n",
       "      <th>total_bpktl</th>\n",
       "      <th>min_fpktl</th>\n",
       "      <th>min_bpktl</th>\n",
       "      <th>max_fpktl</th>\n",
       "      <th>max_bpktl</th>\n",
       "      <th>mean_fpktl</th>\n",
       "      <th>mean_bpktl</th>\n",
       "      <th>std_fpktl</th>\n",
       "      <th>std_bpktl</th>\n",
       "      <th>total_fipt</th>\n",
       "      <th>total_bipt</th>\n",
       "      <th>min_fipt</th>\n",
       "      <th>min_bipt</th>\n",
       "      <th>max_fipt</th>\n",
       "      <th>max_bipt</th>\n",
       "      <th>mean_fipt</th>\n",
       "      <th>mean_bipt</th>\n",
       "      <th>std_fipt</th>\n",
       "      <th>std_bipt</th>\n",
       "      <th>fpsh_cnt</th>\n",
       "      <th>bpsh_cnt</th>\n",
       "      <th>furg_cnt</th>\n",
       "      <th>burg_cnt</th>\n",
       "      <th>total_fhlen</th>\n",
       "      <th>total_bhlen</th>\n",
       "      <th>fPktsPerSecond</th>\n",
       "      <th>bPktsPerSecond</th>\n",
       "      <th>flowPktsPerSecond</th>\n",
       "      <th>flowBytesPerSecond</th>\n",
       "      <th>mean_flowpktl</th>\n",
       "      <th>std_flowpktl</th>\n",
       "      <th>mean_flowipt</th>\n",
       "      <th>std_flowipt</th>\n",
       "      <th>flow_fin</th>\n",
       "      <th>flow_syn</th>\n",
       "      <th>flow_rst</th>\n",
       "      <th>flow_ack</th>\n",
       "      <th>flow_urg</th>\n",
       "      <th>flow_cwr</th>\n",
       "      <th>flow_ece</th>\n",
       "      <th>downUpRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.397025</td>\n",
       "      <td>-0.050652</td>\n",
       "      <td>-0.05044</td>\n",
       "      <td>-0.074392</td>\n",
       "      <td>-0.019826</td>\n",
       "      <td>-0.019120</td>\n",
       "      <td>-0.009411</td>\n",
       "      <td>-0.013777</td>\n",
       "      <td>-0.272029</td>\n",
       "      <td>1.825173</td>\n",
       "      <td>-0.392065</td>\n",
       "      <td>0.074752</td>\n",
       "      <td>-0.423509</td>\n",
       "      <td>0.359647</td>\n",
       "      <td>-0.330526</td>\n",
       "      <td>-0.347526</td>\n",
       "      <td>-0.061876</td>\n",
       "      <td>-0.065519</td>\n",
       "      <td>-0.201584</td>\n",
       "      <td>-0.096528</td>\n",
       "      <td>-0.317501</td>\n",
       "      <td>-0.202109</td>\n",
       "      <td>-0.265029</td>\n",
       "      <td>-0.160461</td>\n",
       "      <td>-0.236612</td>\n",
       "      <td>-0.176743</td>\n",
       "      <td>-0.011500</td>\n",
       "      <td>-0.014573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.024585</td>\n",
       "      <td>-0.017823</td>\n",
       "      <td>-0.228975</td>\n",
       "      <td>-0.253814</td>\n",
       "      <td>-0.251451</td>\n",
       "      <td>-0.357596</td>\n",
       "      <td>0.213985</td>\n",
       "      <td>0.345455</td>\n",
       "      <td>-0.393959</td>\n",
       "      <td>-0.282505</td>\n",
       "      <td>-0.349100</td>\n",
       "      <td>-0.383596</td>\n",
       "      <td>-0.150798</td>\n",
       "      <td>-0.018744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.301425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.397025</td>\n",
       "      <td>-0.003123</td>\n",
       "      <td>-0.05044</td>\n",
       "      <td>-0.074149</td>\n",
       "      <td>-0.019826</td>\n",
       "      <td>-0.019120</td>\n",
       "      <td>-0.009400</td>\n",
       "      <td>-0.013704</td>\n",
       "      <td>-0.017915</td>\n",
       "      <td>2.524306</td>\n",
       "      <td>-0.350634</td>\n",
       "      <td>0.240349</td>\n",
       "      <td>-0.256324</td>\n",
       "      <td>0.615216</td>\n",
       "      <td>-0.330526</td>\n",
       "      <td>-0.347526</td>\n",
       "      <td>-0.061876</td>\n",
       "      <td>-0.065519</td>\n",
       "      <td>-0.201584</td>\n",
       "      <td>-0.096528</td>\n",
       "      <td>-0.317501</td>\n",
       "      <td>-0.202109</td>\n",
       "      <td>-0.265029</td>\n",
       "      <td>-0.160461</td>\n",
       "      <td>-0.236612</td>\n",
       "      <td>-0.176743</td>\n",
       "      <td>-0.011500</td>\n",
       "      <td>-0.014573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.024133</td>\n",
       "      <td>-0.013507</td>\n",
       "      <td>-0.229886</td>\n",
       "      <td>-0.254913</td>\n",
       "      <td>-0.252493</td>\n",
       "      <td>-0.359482</td>\n",
       "      <td>0.449124</td>\n",
       "      <td>0.597122</td>\n",
       "      <td>-0.388434</td>\n",
       "      <td>-0.282505</td>\n",
       "      <td>-0.349100</td>\n",
       "      <td>-0.383596</td>\n",
       "      <td>-0.150798</td>\n",
       "      <td>-0.018744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.415768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.518732</td>\n",
       "      <td>-0.066967</td>\n",
       "      <td>0.09856</td>\n",
       "      <td>0.024818</td>\n",
       "      <td>-0.011890</td>\n",
       "      <td>-0.014785</td>\n",
       "      <td>-0.007764</td>\n",
       "      <td>-0.013148</td>\n",
       "      <td>-0.907314</td>\n",
       "      <td>-0.702460</td>\n",
       "      <td>4.006578</td>\n",
       "      <td>1.055595</td>\n",
       "      <td>2.214297</td>\n",
       "      <td>0.056898</td>\n",
       "      <td>4.518255</td>\n",
       "      <td>1.557036</td>\n",
       "      <td>0.037939</td>\n",
       "      <td>0.009594</td>\n",
       "      <td>-0.200176</td>\n",
       "      <td>-0.091069</td>\n",
       "      <td>0.366284</td>\n",
       "      <td>0.153175</td>\n",
       "      <td>0.126230</td>\n",
       "      <td>0.149939</td>\n",
       "      <td>0.638704</td>\n",
       "      <td>0.327761</td>\n",
       "      <td>-0.009691</td>\n",
       "      <td>-0.008609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.017736</td>\n",
       "      <td>-0.028645</td>\n",
       "      <td>-0.231250</td>\n",
       "      <td>-0.256580</td>\n",
       "      <td>-0.254065</td>\n",
       "      <td>-0.364377</td>\n",
       "      <td>0.244454</td>\n",
       "      <td>1.043737</td>\n",
       "      <td>-0.048536</td>\n",
       "      <td>0.372596</td>\n",
       "      <td>1.217713</td>\n",
       "      <td>2.476054</td>\n",
       "      <td>3.639171</td>\n",
       "      <td>-0.011609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.366520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.397025</td>\n",
       "      <td>-0.050652</td>\n",
       "      <td>-0.05044</td>\n",
       "      <td>-0.074769</td>\n",
       "      <td>-0.019826</td>\n",
       "      <td>-0.019120</td>\n",
       "      <td>-0.009393</td>\n",
       "      <td>-0.013949</td>\n",
       "      <td>0.151494</td>\n",
       "      <td>0.179523</td>\n",
       "      <td>-0.323013</td>\n",
       "      <td>-0.315037</td>\n",
       "      <td>-0.144867</td>\n",
       "      <td>-0.241921</td>\n",
       "      <td>-0.330526</td>\n",
       "      <td>-0.347526</td>\n",
       "      <td>-0.061876</td>\n",
       "      <td>-0.065519</td>\n",
       "      <td>-0.201584</td>\n",
       "      <td>-0.096528</td>\n",
       "      <td>-0.317501</td>\n",
       "      <td>-0.202109</td>\n",
       "      <td>-0.265029</td>\n",
       "      <td>-0.160461</td>\n",
       "      <td>-0.236612</td>\n",
       "      <td>-0.176743</td>\n",
       "      <td>-0.011500</td>\n",
       "      <td>-0.014573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.023832</td>\n",
       "      <td>-0.027981</td>\n",
       "      <td>0.494021</td>\n",
       "      <td>0.618551</td>\n",
       "      <td>0.576163</td>\n",
       "      <td>0.943661</td>\n",
       "      <td>-0.259605</td>\n",
       "      <td>-0.349827</td>\n",
       "      <td>-0.402526</td>\n",
       "      <td>-0.282505</td>\n",
       "      <td>-0.349100</td>\n",
       "      <td>-0.383596</td>\n",
       "      <td>-0.150798</td>\n",
       "      <td>-0.018744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.196899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.397025</td>\n",
       "      <td>-0.068137</td>\n",
       "      <td>-0.05044</td>\n",
       "      <td>-0.070736</td>\n",
       "      <td>-0.018239</td>\n",
       "      <td>-0.017675</td>\n",
       "      <td>-0.009329</td>\n",
       "      <td>-0.013495</td>\n",
       "      <td>-0.864961</td>\n",
       "      <td>1.620811</td>\n",
       "      <td>-0.488739</td>\n",
       "      <td>0.026347</td>\n",
       "      <td>-0.813607</td>\n",
       "      <td>0.284943</td>\n",
       "      <td>-0.330526</td>\n",
       "      <td>-0.347526</td>\n",
       "      <td>-0.057835</td>\n",
       "      <td>-0.058370</td>\n",
       "      <td>-0.112920</td>\n",
       "      <td>0.012178</td>\n",
       "      <td>-0.269216</td>\n",
       "      <td>-0.158965</td>\n",
       "      <td>-0.185829</td>\n",
       "      <td>-0.071832</td>\n",
       "      <td>-0.236612</td>\n",
       "      <td>-0.176743</td>\n",
       "      <td>-0.011500</td>\n",
       "      <td>-0.014573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.023607</td>\n",
       "      <td>-0.003416</td>\n",
       "      <td>-0.230866</td>\n",
       "      <td>-0.256095</td>\n",
       "      <td>-0.253616</td>\n",
       "      <td>-0.363332</td>\n",
       "      <td>0.104695</td>\n",
       "      <td>0.160535</td>\n",
       "      <td>-0.371985</td>\n",
       "      <td>-0.207255</td>\n",
       "      <td>-0.349100</td>\n",
       "      <td>-0.383596</td>\n",
       "      <td>-0.150798</td>\n",
       "      <td>-0.018744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41427</th>\n",
       "      <td>-0.397025</td>\n",
       "      <td>-0.003123</td>\n",
       "      <td>-0.05044</td>\n",
       "      <td>0.124270</td>\n",
       "      <td>-0.016652</td>\n",
       "      <td>-0.016230</td>\n",
       "      <td>-0.009159</td>\n",
       "      <td>-0.013856</td>\n",
       "      <td>-0.356734</td>\n",
       "      <td>-0.498098</td>\n",
       "      <td>-0.405876</td>\n",
       "      <td>-0.475538</td>\n",
       "      <td>-0.479237</td>\n",
       "      <td>-0.489625</td>\n",
       "      <td>-0.330526</td>\n",
       "      <td>-0.347526</td>\n",
       "      <td>0.071348</td>\n",
       "      <td>-0.065517</td>\n",
       "      <td>1.259617</td>\n",
       "      <td>-0.096526</td>\n",
       "      <td>0.478625</td>\n",
       "      <td>-0.202099</td>\n",
       "      <td>1.040517</td>\n",
       "      <td>-0.160451</td>\n",
       "      <td>-0.235812</td>\n",
       "      <td>-0.176726</td>\n",
       "      <td>-0.011500</td>\n",
       "      <td>-0.014573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.018865</td>\n",
       "      <td>-0.026985</td>\n",
       "      <td>-0.231290</td>\n",
       "      <td>-0.256606</td>\n",
       "      <td>-0.254100</td>\n",
       "      <td>-0.364495</td>\n",
       "      <td>-0.507991</td>\n",
       "      <td>-0.567370</td>\n",
       "      <td>0.501880</td>\n",
       "      <td>0.892900</td>\n",
       "      <td>-0.349100</td>\n",
       "      <td>-0.383596</td>\n",
       "      <td>-0.150798</td>\n",
       "      <td>-0.018744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.329589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41428</th>\n",
       "      <td>2.518732</td>\n",
       "      <td>-0.050652</td>\n",
       "      <td>0.09856</td>\n",
       "      <td>-0.036704</td>\n",
       "      <td>0.015092</td>\n",
       "      <td>0.012671</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>0.010168</td>\n",
       "      <td>-0.653200</td>\n",
       "      <td>-0.573389</td>\n",
       "      <td>4.973313</td>\n",
       "      <td>2.991803</td>\n",
       "      <td>4.072311</td>\n",
       "      <td>2.910542</td>\n",
       "      <td>5.684780</td>\n",
       "      <td>3.322391</td>\n",
       "      <td>-0.023724</td>\n",
       "      <td>0.001979</td>\n",
       "      <td>-0.201582</td>\n",
       "      <td>-0.096527</td>\n",
       "      <td>0.079632</td>\n",
       "      <td>0.152989</td>\n",
       "      <td>-0.231039</td>\n",
       "      <td>-0.122425</td>\n",
       "      <td>0.014520</td>\n",
       "      <td>0.030900</td>\n",
       "      <td>-0.002454</td>\n",
       "      <td>0.033142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028326</td>\n",
       "      <td>0.014908</td>\n",
       "      <td>-0.230771</td>\n",
       "      <td>-0.255980</td>\n",
       "      <td>-0.253506</td>\n",
       "      <td>-0.359414</td>\n",
       "      <td>2.896988</td>\n",
       "      <td>3.007100</td>\n",
       "      <td>-0.366900</td>\n",
       "      <td>-0.061754</td>\n",
       "      <td>2.784526</td>\n",
       "      <td>2.476054</td>\n",
       "      <td>-0.150798</td>\n",
       "      <td>0.016930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.326741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41429</th>\n",
       "      <td>2.518732</td>\n",
       "      <td>-0.068128</td>\n",
       "      <td>0.09856</td>\n",
       "      <td>0.340156</td>\n",
       "      <td>-0.008716</td>\n",
       "      <td>-0.006115</td>\n",
       "      <td>-0.007827</td>\n",
       "      <td>-0.004681</td>\n",
       "      <td>-0.907314</td>\n",
       "      <td>-0.702460</td>\n",
       "      <td>2.929359</td>\n",
       "      <td>2.991803</td>\n",
       "      <td>0.907004</td>\n",
       "      <td>2.515463</td>\n",
       "      <td>2.864392</td>\n",
       "      <td>3.893454</td>\n",
       "      <td>0.353995</td>\n",
       "      <td>0.670218</td>\n",
       "      <td>-0.199797</td>\n",
       "      <td>-0.096527</td>\n",
       "      <td>4.248749</td>\n",
       "      <td>3.878966</td>\n",
       "      <td>0.899363</td>\n",
       "      <td>0.853001</td>\n",
       "      <td>4.857540</td>\n",
       "      <td>3.547685</td>\n",
       "      <td>-0.009691</td>\n",
       "      <td>-0.002645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.014725</td>\n",
       "      <td>-0.020678</td>\n",
       "      <td>-0.231286</td>\n",
       "      <td>-0.256597</td>\n",
       "      <td>-0.254093</td>\n",
       "      <td>-0.364349</td>\n",
       "      <td>2.450933</td>\n",
       "      <td>3.224938</td>\n",
       "      <td>0.195988</td>\n",
       "      <td>2.696661</td>\n",
       "      <td>2.784526</td>\n",
       "      <td>2.476054</td>\n",
       "      <td>-0.150798</td>\n",
       "      <td>-0.005267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.334890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41430</th>\n",
       "      <td>-0.397025</td>\n",
       "      <td>-0.060387</td>\n",
       "      <td>-0.05044</td>\n",
       "      <td>-0.074768</td>\n",
       "      <td>-0.019826</td>\n",
       "      <td>-0.019120</td>\n",
       "      <td>-0.009392</td>\n",
       "      <td>-0.013911</td>\n",
       "      <td>0.193846</td>\n",
       "      <td>0.545223</td>\n",
       "      <td>-0.316107</td>\n",
       "      <td>-0.228417</td>\n",
       "      <td>-0.117003</td>\n",
       "      <td>-0.108239</td>\n",
       "      <td>-0.330526</td>\n",
       "      <td>-0.347526</td>\n",
       "      <td>-0.061876</td>\n",
       "      <td>-0.065519</td>\n",
       "      <td>-0.201584</td>\n",
       "      <td>-0.096528</td>\n",
       "      <td>-0.317501</td>\n",
       "      <td>-0.202109</td>\n",
       "      <td>-0.265029</td>\n",
       "      <td>-0.160461</td>\n",
       "      <td>-0.236612</td>\n",
       "      <td>-0.176743</td>\n",
       "      <td>-0.011500</td>\n",
       "      <td>-0.014573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.023757</td>\n",
       "      <td>-0.025723</td>\n",
       "      <td>0.219020</td>\n",
       "      <td>0.286735</td>\n",
       "      <td>0.261369</td>\n",
       "      <td>0.576304</td>\n",
       "      <td>-0.143691</td>\n",
       "      <td>-0.209065</td>\n",
       "      <td>-0.402509</td>\n",
       "      <td>-0.282505</td>\n",
       "      <td>-0.349100</td>\n",
       "      <td>-0.383596</td>\n",
       "      <td>-0.150798</td>\n",
       "      <td>-0.018744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.113582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41431</th>\n",
       "      <td>-0.397025</td>\n",
       "      <td>-0.067701</td>\n",
       "      <td>-0.05044</td>\n",
       "      <td>-0.074161</td>\n",
       "      <td>-0.019826</td>\n",
       "      <td>-0.019120</td>\n",
       "      <td>-0.009413</td>\n",
       "      <td>-0.013874</td>\n",
       "      <td>-0.314381</td>\n",
       "      <td>0.900167</td>\n",
       "      <td>-0.398970</td>\n",
       "      <td>-0.144345</td>\n",
       "      <td>-0.451373</td>\n",
       "      <td>0.021511</td>\n",
       "      <td>-0.330526</td>\n",
       "      <td>-0.347526</td>\n",
       "      <td>-0.061876</td>\n",
       "      <td>-0.065519</td>\n",
       "      <td>-0.201584</td>\n",
       "      <td>-0.096528</td>\n",
       "      <td>-0.317501</td>\n",
       "      <td>-0.202109</td>\n",
       "      <td>-0.265029</td>\n",
       "      <td>-0.160461</td>\n",
       "      <td>-0.236612</td>\n",
       "      <td>-0.176743</td>\n",
       "      <td>-0.011500</td>\n",
       "      <td>-0.014573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.024660</td>\n",
       "      <td>-0.023532</td>\n",
       "      <td>-0.229857</td>\n",
       "      <td>-0.254878</td>\n",
       "      <td>-0.252461</td>\n",
       "      <td>-0.361244</td>\n",
       "      <td>-0.074143</td>\n",
       "      <td>-0.017116</td>\n",
       "      <td>-0.388714</td>\n",
       "      <td>-0.282505</td>\n",
       "      <td>-0.349100</td>\n",
       "      <td>-0.383596</td>\n",
       "      <td>-0.150798</td>\n",
       "      <td>-0.018744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41432 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          proto    srcPrt   dstPrt  flowduration  total_fpackets  \\\n",
       "0     -0.397025 -0.050652 -0.05044     -0.074392       -0.019826   \n",
       "1     -0.397025 -0.003123 -0.05044     -0.074149       -0.019826   \n",
       "2      2.518732 -0.066967  0.09856      0.024818       -0.011890   \n",
       "3     -0.397025 -0.050652 -0.05044     -0.074769       -0.019826   \n",
       "4     -0.397025 -0.068137 -0.05044     -0.070736       -0.018239   \n",
       "...         ...       ...      ...           ...             ...   \n",
       "41427 -0.397025 -0.003123 -0.05044      0.124270       -0.016652   \n",
       "41428  2.518732 -0.050652  0.09856     -0.036704        0.015092   \n",
       "41429  2.518732 -0.068128  0.09856      0.340156       -0.008716   \n",
       "41430 -0.397025 -0.060387 -0.05044     -0.074768       -0.019826   \n",
       "41431 -0.397025 -0.067701 -0.05044     -0.074161       -0.019826   \n",
       "\n",
       "       total_bpackets  total_fpktl  total_bpktl  min_fpktl  min_bpktl  \\\n",
       "0           -0.019120    -0.009411    -0.013777  -0.272029   1.825173   \n",
       "1           -0.019120    -0.009400    -0.013704  -0.017915   2.524306   \n",
       "2           -0.014785    -0.007764    -0.013148  -0.907314  -0.702460   \n",
       "3           -0.019120    -0.009393    -0.013949   0.151494   0.179523   \n",
       "4           -0.017675    -0.009329    -0.013495  -0.864961   1.620811   \n",
       "...               ...          ...          ...        ...        ...   \n",
       "41427       -0.016230    -0.009159    -0.013856  -0.356734  -0.498098   \n",
       "41428        0.012671    -0.000048     0.010168  -0.653200  -0.573389   \n",
       "41429       -0.006115    -0.007827    -0.004681  -0.907314  -0.702460   \n",
       "41430       -0.019120    -0.009392    -0.013911   0.193846   0.545223   \n",
       "41431       -0.019120    -0.009413    -0.013874  -0.314381   0.900167   \n",
       "\n",
       "       max_fpktl  max_bpktl  mean_fpktl  mean_bpktl  std_fpktl  std_bpktl  \\\n",
       "0      -0.392065   0.074752   -0.423509    0.359647  -0.330526  -0.347526   \n",
       "1      -0.350634   0.240349   -0.256324    0.615216  -0.330526  -0.347526   \n",
       "2       4.006578   1.055595    2.214297    0.056898   4.518255   1.557036   \n",
       "3      -0.323013  -0.315037   -0.144867   -0.241921  -0.330526  -0.347526   \n",
       "4      -0.488739   0.026347   -0.813607    0.284943  -0.330526  -0.347526   \n",
       "...          ...        ...         ...         ...        ...        ...   \n",
       "41427  -0.405876  -0.475538   -0.479237   -0.489625  -0.330526  -0.347526   \n",
       "41428   4.973313   2.991803    4.072311    2.910542   5.684780   3.322391   \n",
       "41429   2.929359   2.991803    0.907004    2.515463   2.864392   3.893454   \n",
       "41430  -0.316107  -0.228417   -0.117003   -0.108239  -0.330526  -0.347526   \n",
       "41431  -0.398970  -0.144345   -0.451373    0.021511  -0.330526  -0.347526   \n",
       "\n",
       "       total_fipt  total_bipt  min_fipt  min_bipt  max_fipt  max_bipt  \\\n",
       "0       -0.061876   -0.065519 -0.201584 -0.096528 -0.317501 -0.202109   \n",
       "1       -0.061876   -0.065519 -0.201584 -0.096528 -0.317501 -0.202109   \n",
       "2        0.037939    0.009594 -0.200176 -0.091069  0.366284  0.153175   \n",
       "3       -0.061876   -0.065519 -0.201584 -0.096528 -0.317501 -0.202109   \n",
       "4       -0.057835   -0.058370 -0.112920  0.012178 -0.269216 -0.158965   \n",
       "...           ...         ...       ...       ...       ...       ...   \n",
       "41427    0.071348   -0.065517  1.259617 -0.096526  0.478625 -0.202099   \n",
       "41428   -0.023724    0.001979 -0.201582 -0.096527  0.079632  0.152989   \n",
       "41429    0.353995    0.670218 -0.199797 -0.096527  4.248749  3.878966   \n",
       "41430   -0.061876   -0.065519 -0.201584 -0.096528 -0.317501 -0.202109   \n",
       "41431   -0.061876   -0.065519 -0.201584 -0.096528 -0.317501 -0.202109   \n",
       "\n",
       "       mean_fipt  mean_bipt  std_fipt  std_bipt  fpsh_cnt  bpsh_cnt  furg_cnt  \\\n",
       "0      -0.265029  -0.160461 -0.236612 -0.176743 -0.011500 -0.014573       0.0   \n",
       "1      -0.265029  -0.160461 -0.236612 -0.176743 -0.011500 -0.014573       0.0   \n",
       "2       0.126230   0.149939  0.638704  0.327761 -0.009691 -0.008609       0.0   \n",
       "3      -0.265029  -0.160461 -0.236612 -0.176743 -0.011500 -0.014573       0.0   \n",
       "4      -0.185829  -0.071832 -0.236612 -0.176743 -0.011500 -0.014573       0.0   \n",
       "...          ...        ...       ...       ...       ...       ...       ...   \n",
       "41427   1.040517  -0.160451 -0.235812 -0.176726 -0.011500 -0.014573       0.0   \n",
       "41428  -0.231039  -0.122425  0.014520  0.030900 -0.002454  0.033142       0.0   \n",
       "41429   0.899363   0.853001  4.857540  3.547685 -0.009691 -0.002645       0.0   \n",
       "41430  -0.265029  -0.160461 -0.236612 -0.176743 -0.011500 -0.014573       0.0   \n",
       "41431  -0.265029  -0.160461 -0.236612 -0.176743 -0.011500 -0.014573       0.0   \n",
       "\n",
       "       burg_cnt  total_fhlen  total_bhlen  fPktsPerSecond  bPktsPerSecond  \\\n",
       "0           0.0    -0.024585    -0.017823       -0.228975       -0.253814   \n",
       "1           0.0    -0.024133    -0.013507       -0.229886       -0.254913   \n",
       "2           0.0    -0.017736    -0.028645       -0.231250       -0.256580   \n",
       "3           0.0    -0.023832    -0.027981        0.494021        0.618551   \n",
       "4           0.0    -0.023607    -0.003416       -0.230866       -0.256095   \n",
       "...         ...          ...          ...             ...             ...   \n",
       "41427       0.0    -0.018865    -0.026985       -0.231290       -0.256606   \n",
       "41428       0.0     0.028326     0.014908       -0.230771       -0.255980   \n",
       "41429       0.0    -0.014725    -0.020678       -0.231286       -0.256597   \n",
       "41430       0.0    -0.023757    -0.025723        0.219020        0.286735   \n",
       "41431       0.0    -0.024660    -0.023532       -0.229857       -0.254878   \n",
       "\n",
       "       flowPktsPerSecond  flowBytesPerSecond  mean_flowpktl  std_flowpktl  \\\n",
       "0              -0.251451           -0.357596       0.213985      0.345455   \n",
       "1              -0.252493           -0.359482       0.449124      0.597122   \n",
       "2              -0.254065           -0.364377       0.244454      1.043737   \n",
       "3               0.576163            0.943661      -0.259605     -0.349827   \n",
       "4              -0.253616           -0.363332       0.104695      0.160535   \n",
       "...                  ...                 ...            ...           ...   \n",
       "41427          -0.254100           -0.364495      -0.507991     -0.567370   \n",
       "41428          -0.253506           -0.359414       2.896988      3.007100   \n",
       "41429          -0.254093           -0.364349       2.450933      3.224938   \n",
       "41430           0.261369            0.576304      -0.143691     -0.209065   \n",
       "41431          -0.252461           -0.361244      -0.074143     -0.017116   \n",
       "\n",
       "       mean_flowipt  std_flowipt  flow_fin  flow_syn  flow_rst  flow_ack  \\\n",
       "0         -0.393959    -0.282505 -0.349100 -0.383596 -0.150798 -0.018744   \n",
       "1         -0.388434    -0.282505 -0.349100 -0.383596 -0.150798 -0.018744   \n",
       "2         -0.048536     0.372596  1.217713  2.476054  3.639171 -0.011609   \n",
       "3         -0.402526    -0.282505 -0.349100 -0.383596 -0.150798 -0.018744   \n",
       "4         -0.371985    -0.207255 -0.349100 -0.383596 -0.150798 -0.018744   \n",
       "...             ...          ...       ...       ...       ...       ...   \n",
       "41427      0.501880     0.892900 -0.349100 -0.383596 -0.150798 -0.018744   \n",
       "41428     -0.366900    -0.061754  2.784526  2.476054 -0.150798  0.016930   \n",
       "41429      0.195988     2.696661  2.784526  2.476054 -0.150798 -0.005267   \n",
       "41430     -0.402509    -0.282505 -0.349100 -0.383596 -0.150798 -0.018744   \n",
       "41431     -0.388714    -0.282505 -0.349100 -0.383596 -0.150798 -0.018744   \n",
       "\n",
       "       flow_urg  flow_cwr  flow_ece  downUpRatio  \n",
       "0           0.0 -0.004913       0.0     0.301425  \n",
       "1           0.0 -0.004913       0.0     0.415768  \n",
       "2           0.0 -0.004913       0.0    -0.366520  \n",
       "3           0.0 -0.004913       0.0    -0.196899  \n",
       "4           0.0 -0.004913       0.0     0.428121  \n",
       "...         ...       ...       ...          ...  \n",
       "41427       0.0 -0.004913       0.0    -0.329589  \n",
       "41428       0.0 -0.004913       0.0     0.326741  \n",
       "41429       0.0 -0.004913       0.0     1.334890  \n",
       "41430       0.0 -0.004913       0.0    -0.113582  \n",
       "41431       0.0 -0.004913       0.0     0.055929  \n",
       "\n",
       "[41432 rows x 48 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_test_stand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection\n",
    "`VarianceThreshold` is a simple baseline approach to feature selection. It removes all features whose variance doesnâ€™t meet some threshold. Defining and Fiting Threshold\n",
    "For quasi-constant features, that have the same value for a very large subset, i.e. using threshold as 0.01 would mean dropping the column where 99% of the values are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True, False,  True])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the VarianceThreshold class from sklearn support a type of feature selection\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "var_thr = VarianceThreshold(threshold = 0.25) #.25 would mean dropping the column where 75% of the values are similar.\n",
    "# fit on the trainning dataset\n",
    "var_thr.fit(df_X_train_stand)\n",
    "# Get a mask of the selected features \n",
    "var_thr.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "furg_cnt\n",
      "burg_cnt\n",
      "flow_urg\n",
      "flow_ece\n"
     ]
    }
   ],
   "source": [
    "#Show features that do not meet the threshold\n",
    "concol = [column for column in df_X_train_stand.columns \n",
    "          if column not in df_X_train_stand.columns[var_thr.get_support()]]\n",
    "\n",
    "for features in concol:\n",
    "    print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping Low Variance Columns:\n",
    "df_X_train_stand.drop(concol,axis=1,inplace=True)\n",
    "df_X_test_stand.drop(concol,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['proto', 'srcPrt', 'dstPrt', 'flowduration', 'total_fpackets',\n",
       "       'total_bpackets', 'total_fpktl', 'total_bpktl', 'min_fpktl',\n",
       "       'min_bpktl', 'max_fpktl', 'max_bpktl', 'mean_fpktl', 'mean_bpktl',\n",
       "       'std_fpktl', 'std_bpktl', 'total_fipt', 'total_bipt', 'min_fipt',\n",
       "       'min_bipt', 'max_fipt', 'max_bipt', 'mean_fipt', 'mean_bipt',\n",
       "       'std_fipt', 'std_bipt', 'fpsh_cnt', 'bpsh_cnt', 'total_fhlen',\n",
       "       'total_bhlen', 'fPktsPerSecond', 'bPktsPerSecond', 'flowPktsPerSecond',\n",
       "       'flowBytesPerSecond', 'mean_flowpktl', 'std_flowpktl', 'mean_flowipt',\n",
       "       'std_flowipt', 'flow_fin', 'flow_syn', 'flow_rst', 'flow_ack',\n",
       "       'flow_cwr', 'downUpRatio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show selected features\n",
    "df_X_train_stand.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((165725, 44), (41432, 44))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##final dataset dimensions\n",
    "df_X_train_stand.shape,df_X_test_stand.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Weighted Logistic Regression (W-LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run grid search only on training set using cross-validation\n",
    "parameters={'C':np.logspace(-3,3,7), 'penalty':[\"l1\",\"l2\"]}# l1 lasso l2 ridge\n",
    "model1=GridSearchCV(LogisticRegression(class_weight='balanced', solver='saga' ,max_iter=1000),parameters,cv=5, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "[CV 1/5] END ...............C=0.001, penalty=l1;, score=0.997 total time=  56.0s\n",
      "[CV 2/5] END ...............C=0.001, penalty=l1;, score=0.996 total time= 1.2min\n",
      "[CV 3/5] END ...............C=0.001, penalty=l1;, score=0.997 total time= 1.2min\n",
      "[CV 4/5] END ...............C=0.001, penalty=l1;, score=0.997 total time= 1.0min\n",
      "[CV 5/5] END ...............C=0.001, penalty=l1;, score=0.997 total time= 1.1min\n",
      "[CV 1/5] END ...............C=0.001, penalty=l2;, score=0.997 total time=  42.5s\n",
      "[CV 2/5] END ...............C=0.001, penalty=l2;, score=0.996 total time=  53.7s\n",
      "[CV 3/5] END ...............C=0.001, penalty=l2;, score=0.997 total time=  55.0s\n",
      "[CV 4/5] END ...............C=0.001, penalty=l2;, score=0.997 total time=  52.5s\n",
      "[CV 5/5] END ...............C=0.001, penalty=l2;, score=0.997 total time=  58.3s\n",
      "[CV 1/5] END ................C=0.01, penalty=l1;, score=0.997 total time= 1.8min\n",
      "[CV 2/5] END ................C=0.01, penalty=l1;, score=0.996 total time= 1.8min\n",
      "[CV 3/5] END ................C=0.01, penalty=l1;, score=0.997 total time= 1.8min\n",
      "[CV 4/5] END ................C=0.01, penalty=l1;, score=0.997 total time= 1.8min\n",
      "[CV 5/5] END ................C=0.01, penalty=l1;, score=0.996 total time= 1.8min\n",
      "[CV 1/5] END ................C=0.01, penalty=l2;, score=0.997 total time= 1.6min\n",
      "[CV 2/5] END ................C=0.01, penalty=l2;, score=0.996 total time= 1.7min\n",
      "[CV 3/5] END ................C=0.01, penalty=l2;, score=0.997 total time= 1.7min\n",
      "[CV 4/5] END ................C=0.01, penalty=l2;, score=0.997 total time= 1.7min\n",
      "[CV 5/5] END ................C=0.01, penalty=l2;, score=0.996 total time= 1.7min\n",
      "[CV 1/5] END .................C=0.1, penalty=l1;, score=0.997 total time= 1.8min\n",
      "[CV 2/5] END .................C=0.1, penalty=l1;, score=0.996 total time= 1.9min\n",
      "[CV 3/5] END .................C=0.1, penalty=l1;, score=0.997 total time= 1.9min\n",
      "[CV 4/5] END .................C=0.1, penalty=l1;, score=0.997 total time= 1.9min\n",
      "[CV 5/5] END .................C=0.1, penalty=l1;, score=0.996 total time= 1.9min\n",
      "[CV 1/5] END .................C=0.1, penalty=l2;, score=0.997 total time= 1.7min\n",
      "[CV 2/5] END .................C=0.1, penalty=l2;, score=0.996 total time= 1.6min\n",
      "[CV 3/5] END .................C=0.1, penalty=l2;, score=0.997 total time= 1.6min\n",
      "[CV 4/5] END .................C=0.1, penalty=l2;, score=0.997 total time= 1.6min\n",
      "[CV 5/5] END .................C=0.1, penalty=l2;, score=0.996 total time= 1.6min\n",
      "[CV 1/5] END .................C=1.0, penalty=l1;, score=0.997 total time= 1.9min\n",
      "[CV 2/5] END .................C=1.0, penalty=l1;, score=0.996 total time= 1.9min\n",
      "[CV 3/5] END .................C=1.0, penalty=l1;, score=0.997 total time= 1.9min\n",
      "[CV 4/5] END .................C=1.0, penalty=l1;, score=0.997 total time= 1.9min\n",
      "[CV 5/5] END .................C=1.0, penalty=l1;, score=0.996 total time= 1.9min\n",
      "[CV 1/5] END .................C=1.0, penalty=l2;, score=0.997 total time= 1.7min\n",
      "[CV 2/5] END .................C=1.0, penalty=l2;, score=0.996 total time= 1.7min\n",
      "[CV 3/5] END .................C=1.0, penalty=l2;, score=0.997 total time= 1.6min\n",
      "[CV 4/5] END .................C=1.0, penalty=l2;, score=0.997 total time= 1.6min\n",
      "[CV 5/5] END .................C=1.0, penalty=l2;, score=0.996 total time= 1.7min\n",
      "[CV 1/5] END ................C=10.0, penalty=l1;, score=0.997 total time= 1.9min\n",
      "[CV 2/5] END ................C=10.0, penalty=l1;, score=0.996 total time= 1.9min\n",
      "[CV 3/5] END ................C=10.0, penalty=l1;, score=0.997 total time= 1.9min\n",
      "[CV 4/5] END ................C=10.0, penalty=l1;, score=0.997 total time= 1.9min\n",
      "[CV 5/5] END ................C=10.0, penalty=l1;, score=0.996 total time= 1.9min\n",
      "[CV 1/5] END ................C=10.0, penalty=l2;, score=0.997 total time= 1.7min\n",
      "[CV 2/5] END ................C=10.0, penalty=l2;, score=0.996 total time= 1.7min\n",
      "[CV 3/5] END ................C=10.0, penalty=l2;, score=0.997 total time= 1.7min\n",
      "[CV 4/5] END ................C=10.0, penalty=l2;, score=0.997 total time= 1.6min\n",
      "[CV 5/5] END ................C=10.0, penalty=l2;, score=0.996 total time= 1.7min\n",
      "[CV 1/5] END ...............C=100.0, penalty=l1;, score=0.997 total time= 1.9min\n",
      "[CV 2/5] END ...............C=100.0, penalty=l1;, score=0.996 total time= 1.9min\n",
      "[CV 3/5] END ...............C=100.0, penalty=l1;, score=0.997 total time= 1.9min\n",
      "[CV 4/5] END ...............C=100.0, penalty=l1;, score=0.997 total time= 1.9min\n",
      "[CV 5/5] END ...............C=100.0, penalty=l1;, score=0.996 total time= 1.9min\n",
      "[CV 1/5] END ...............C=100.0, penalty=l2;, score=0.997 total time= 1.6min\n",
      "[CV 2/5] END ...............C=100.0, penalty=l2;, score=0.996 total time= 1.6min\n",
      "[CV 3/5] END ...............C=100.0, penalty=l2;, score=0.997 total time= 1.7min\n",
      "[CV 4/5] END ...............C=100.0, penalty=l2;, score=0.997 total time= 1.7min\n",
      "[CV 5/5] END ...............C=100.0, penalty=l2;, score=0.996 total time= 1.6min\n",
      "[CV 1/5] END ..............C=1000.0, penalty=l1;, score=0.997 total time= 1.9min\n",
      "[CV 2/5] END ..............C=1000.0, penalty=l1;, score=0.996 total time= 1.9min\n",
      "[CV 3/5] END ..............C=1000.0, penalty=l1;, score=0.997 total time= 1.9min\n",
      "[CV 4/5] END ..............C=1000.0, penalty=l1;, score=0.997 total time= 1.9min\n",
      "[CV 5/5] END ..............C=1000.0, penalty=l1;, score=0.996 total time= 1.9min\n",
      "[CV 1/5] END ..............C=1000.0, penalty=l2;, score=0.997 total time= 1.6min\n",
      "[CV 2/5] END ..............C=1000.0, penalty=l2;, score=0.996 total time= 1.6min\n",
      "[CV 3/5] END ..............C=1000.0, penalty=l2;, score=0.997 total time= 1.7min\n",
      "[CV 4/5] END ..............C=1000.0, penalty=l2;, score=0.997 total time= 1.7min\n",
      "[CV 5/5] END ..............C=1000.0, penalty=l2;, score=0.996 total time= 1.6min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=LogisticRegression(class_weight='balanced',\n",
       "                                          max_iter=1000, solver='saga'),\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit on the trainning dataset\n",
    "model1.fit(df_X_train_stand,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'C': 0.01, 'penalty': 'l2'}\n",
      "accuracy : 0.996868305928496\n"
     ]
    }
   ],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",model1.best_params_)\n",
    "print(\"accuracy :\",model1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = model1.predict(df_X_test_stand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      1.00      1.00     41313\n",
      "     class 1       0.45      0.92      0.61       119\n",
      "\n",
      "    accuracy                           1.00     41432\n",
      "   macro avg       0.73      0.96      0.80     41432\n",
      "weighted avg       1.00      1.00      1.00     41432\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#performance results\n",
    "print(classification_report(y_test, y_pred1, target_names=target_names))\n",
    "plot_confusion_matrix(model1, df_X_test_stand, y_test, display_labels=target_names,cmap=plt.cm.Blues);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Over-sampling with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origianl dataset shape: Counter({0: 165213, 1: 512})\n",
      "Resample dataset shape: Counter({0: 165213, 1: 165213})\n"
     ]
    }
   ],
   "source": [
    "# load library\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE()\n",
    "\n",
    "# fit on the trainning dataset\n",
    "X_smote , y_smote = smote.fit_resample(df_X_train_stand, y_train)\n",
    "\n",
    "print('Origianl dataset shape:', Counter(y_train))\n",
    "print('Resample dataset shape:', Counter(y_smote))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### b) Logistic Regression with Synthetic minority over-sampling technique (LR+SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "[CV 1/5] END ...............C=0.001, penalty=l1;, score=0.993 total time= 1.6min\n",
      "[CV 2/5] END ...............C=0.001, penalty=l1;, score=0.992 total time= 2.3min\n",
      "[CV 3/5] END ...............C=0.001, penalty=l1;, score=0.993 total time= 2.2min\n",
      "[CV 4/5] END ...............C=0.001, penalty=l1;, score=0.992 total time= 2.3min\n",
      "[CV 5/5] END ...............C=0.001, penalty=l1;, score=0.992 total time= 2.3min\n",
      "[CV 1/5] END ...............C=0.001, penalty=l2;, score=0.995 total time= 1.4min\n",
      "[CV 2/5] END ...............C=0.001, penalty=l2;, score=0.994 total time= 2.1min\n",
      "[CV 3/5] END ...............C=0.001, penalty=l2;, score=0.994 total time= 2.5min\n",
      "[CV 4/5] END ...............C=0.001, penalty=l2;, score=0.994 total time= 2.0min\n",
      "[CV 5/5] END ...............C=0.001, penalty=l2;, score=0.994 total time= 2.5min\n",
      "[CV 1/5] END ................C=0.01, penalty=l1;, score=0.998 total time= 5.6min\n",
      "[CV 2/5] END ................C=0.01, penalty=l1;, score=0.997 total time= 4.5min\n",
      "[CV 3/5] END ................C=0.01, penalty=l1;, score=0.997 total time= 4.3min\n",
      "[CV 4/5] END ................C=0.01, penalty=l1;, score=0.997 total time= 4.5min\n",
      "[CV 5/5] END ................C=0.01, penalty=l1;, score=0.997 total time= 4.5min\n",
      "[CV 1/5] END ................C=0.01, penalty=l2;, score=0.998 total time= 4.1min\n",
      "[CV 2/5] END ................C=0.01, penalty=l2;, score=0.997 total time= 4.0min\n",
      "[CV 3/5] END ................C=0.01, penalty=l2;, score=0.998 total time= 4.0min\n",
      "[CV 4/5] END ................C=0.01, penalty=l2;, score=0.998 total time= 4.1min\n",
      "[CV 5/5] END ................C=0.01, penalty=l2;, score=0.998 total time= 4.0min\n",
      "[CV 1/5] END .................C=0.1, penalty=l1;, score=0.998 total time= 4.4min\n",
      "[CV 2/5] END .................C=0.1, penalty=l1;, score=0.998 total time= 4.5min\n",
      "[CV 3/5] END .................C=0.1, penalty=l1;, score=0.998 total time= 4.5min\n",
      "[CV 4/5] END .................C=0.1, penalty=l1;, score=0.998 total time= 4.6min\n",
      "[CV 5/5] END .................C=0.1, penalty=l1;, score=0.998 total time= 4.5min\n",
      "[CV 1/5] END .................C=0.1, penalty=l2;, score=0.998 total time= 4.1min\n",
      "[CV 2/5] END .................C=0.1, penalty=l2;, score=0.998 total time= 4.1min\n",
      "[CV 3/5] END .................C=0.1, penalty=l2;, score=0.998 total time= 4.2min\n",
      "[CV 4/5] END .................C=0.1, penalty=l2;, score=0.998 total time= 4.1min\n",
      "[CV 5/5] END .................C=0.1, penalty=l2;, score=0.998 total time= 4.0min\n",
      "[CV 1/5] END .................C=1.0, penalty=l1;, score=0.998 total time= 4.4min\n",
      "[CV 2/5] END .................C=1.0, penalty=l1;, score=0.998 total time= 4.6min\n",
      "[CV 3/5] END .................C=1.0, penalty=l1;, score=0.998 total time= 4.6min\n",
      "[CV 4/5] END .................C=1.0, penalty=l1;, score=0.998 total time= 4.5min\n",
      "[CV 5/5] END .................C=1.0, penalty=l1;, score=0.998 total time= 4.4min\n",
      "[CV 1/5] END .................C=1.0, penalty=l2;, score=0.998 total time= 4.0min\n",
      "[CV 2/5] END .................C=1.0, penalty=l2;, score=0.998 total time= 4.2min\n",
      "[CV 3/5] END .................C=1.0, penalty=l2;, score=0.998 total time= 4.2min\n",
      "[CV 4/5] END .................C=1.0, penalty=l2;, score=0.998 total time= 4.1min\n",
      "[CV 5/5] END .................C=1.0, penalty=l2;, score=0.998 total time= 4.0min\n",
      "[CV 1/5] END ................C=10.0, penalty=l1;, score=0.998 total time= 4.4min\n",
      "[CV 2/5] END ................C=10.0, penalty=l1;, score=0.998 total time= 4.6min\n",
      "[CV 3/5] END ................C=10.0, penalty=l1;, score=0.998 total time= 4.6min\n",
      "[CV 4/5] END ................C=10.0, penalty=l1;, score=0.998 total time= 4.6min\n",
      "[CV 5/5] END ................C=10.0, penalty=l1;, score=0.998 total time= 4.4min\n",
      "[CV 1/5] END ................C=10.0, penalty=l2;, score=0.998 total time= 4.0min\n",
      "[CV 2/5] END ................C=10.0, penalty=l2;, score=0.998 total time= 4.0min\n",
      "[CV 3/5] END ................C=10.0, penalty=l2;, score=0.998 total time= 4.0min\n",
      "[CV 4/5] END ................C=10.0, penalty=l2;, score=0.998 total time= 3.8min\n",
      "[CV 5/5] END ................C=10.0, penalty=l2;, score=0.998 total time= 3.7min\n",
      "[CV 1/5] END ...............C=100.0, penalty=l1;, score=0.998 total time= 4.1min\n",
      "[CV 2/5] END ...............C=100.0, penalty=l1;, score=0.998 total time= 4.1min\n",
      "[CV 3/5] END ...............C=100.0, penalty=l1;, score=0.998 total time= 4.1min\n",
      "[CV 4/5] END ...............C=100.0, penalty=l1;, score=0.998 total time= 4.1min\n",
      "[CV 5/5] END ...............C=100.0, penalty=l1;, score=0.998 total time= 4.1min\n",
      "[CV 1/5] END ...............C=100.0, penalty=l2;, score=0.998 total time= 3.7min\n",
      "[CV 2/5] END ...............C=100.0, penalty=l2;, score=0.998 total time= 3.6min\n",
      "[CV 3/5] END ...............C=100.0, penalty=l2;, score=0.998 total time= 3.6min\n",
      "[CV 4/5] END ...............C=100.0, penalty=l2;, score=0.998 total time= 3.6min\n",
      "[CV 5/5] END ...............C=100.0, penalty=l2;, score=0.998 total time= 3.7min\n",
      "[CV 1/5] END ..............C=1000.0, penalty=l1;, score=0.998 total time= 4.1min\n",
      "[CV 2/5] END ..............C=1000.0, penalty=l1;, score=0.998 total time= 4.1min\n",
      "[CV 3/5] END ..............C=1000.0, penalty=l1;, score=0.998 total time= 4.0min\n",
      "[CV 4/5] END ..............C=1000.0, penalty=l1;, score=0.998 total time= 4.0min\n",
      "[CV 5/5] END ..............C=1000.0, penalty=l1;, score=0.998 total time= 4.0min\n",
      "[CV 1/5] END ..............C=1000.0, penalty=l2;, score=0.998 total time= 3.5min\n",
      "[CV 2/5] END ..............C=1000.0, penalty=l2;, score=0.998 total time= 3.6min\n",
      "[CV 3/5] END ..............C=1000.0, penalty=l2;, score=0.998 total time= 3.5min\n",
      "[CV 4/5] END ..............C=1000.0, penalty=l2;, score=0.998 total time= 3.5min\n",
      "[CV 5/5] END ..............C=1000.0, penalty=l2;, score=0.998 total time= 3.5min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=1000, solver='saga'),\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run grid search only on training set using cross-validation\n",
    "parameters={'C':np.logspace(-3,3,7), 'penalty':[\"l1\",\"l2\"]}# l1 lasso l2 ridge\n",
    "model2=GridSearchCV(LogisticRegression(solver='saga' ,max_iter=1000),parameters,cv=5, verbose=3)\n",
    "model2.fit(X_smote,y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'C': 1.0, 'penalty': 'l2'}\n",
      "accuracy : 0.9978573110767318\n",
      "Best Model: LogisticRegression(max_iter=1000, solver='saga')\n"
     ]
    }
   ],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",model2.best_params_)\n",
    "print(\"accuracy :\",model2.best_score_)\n",
    "print('Best Model:',model2.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2=model2.predict(df_X_test_stand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      1.00      1.00     41313\n",
      "     class 1       0.48      0.92      0.63       119\n",
      "\n",
      "    accuracy                           1.00     41432\n",
      "   macro avg       0.74      0.96      0.82     41432\n",
      "weighted avg       1.00      1.00      1.00     41432\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#performance results\n",
    "print(classification_report(y_test, y_pred2, target_names=target_names))\n",
    "plot_confusion_matrix(model2, df_X_test_stand, y_test, display_labels=target_names,cmap=plt.cm.Blues); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Weighted Decision Tree (W-SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 1/5] END .......criterion=gini, max_depth=2;, score=0.998 total time=   0.5s\n",
      "[CV 2/5] END .......criterion=gini, max_depth=2;, score=0.997 total time=   0.4s\n",
      "[CV 3/5] END .......criterion=gini, max_depth=2;, score=0.998 total time=   0.4s\n",
      "[CV 4/5] END .......criterion=gini, max_depth=2;, score=0.998 total time=   0.4s\n",
      "[CV 5/5] END .......criterion=gini, max_depth=2;, score=0.997 total time=   0.4s\n",
      "[CV 1/5] END .......criterion=gini, max_depth=4;, score=0.998 total time=   0.9s\n",
      "[CV 2/5] END .......criterion=gini, max_depth=4;, score=0.998 total time=   0.9s\n",
      "[CV 3/5] END .......criterion=gini, max_depth=4;, score=0.998 total time=   0.9s\n",
      "[CV 4/5] END .......criterion=gini, max_depth=4;, score=0.998 total time=   0.7s\n",
      "[CV 5/5] END .......criterion=gini, max_depth=4;, score=0.998 total time=   0.6s\n",
      "[CV 1/5] END .......criterion=gini, max_depth=6;, score=1.000 total time=   0.9s\n",
      "[CV 2/5] END .......criterion=gini, max_depth=6;, score=0.998 total time=   0.8s\n",
      "[CV 3/5] END .......criterion=gini, max_depth=6;, score=0.999 total time=   0.9s\n",
      "[CV 4/5] END .......criterion=gini, max_depth=6;, score=0.999 total time=   0.6s\n",
      "[CV 5/5] END .......criterion=gini, max_depth=6;, score=0.999 total time=   0.6s\n",
      "[CV 1/5] END .......criterion=gini, max_depth=8;, score=1.000 total time=   0.9s\n",
      "[CV 2/5] END .......criterion=gini, max_depth=8;, score=0.999 total time=   0.9s\n",
      "[CV 3/5] END .......criterion=gini, max_depth=8;, score=1.000 total time=   0.7s\n",
      "[CV 4/5] END .......criterion=gini, max_depth=8;, score=1.000 total time=   0.6s\n",
      "[CV 5/5] END .......criterion=gini, max_depth=8;, score=1.000 total time=   0.7s\n",
      "[CV 1/5] END ......criterion=gini, max_depth=10;, score=1.000 total time=   0.9s\n",
      "[CV 2/5] END ......criterion=gini, max_depth=10;, score=0.999 total time=   0.9s\n",
      "[CV 3/5] END ......criterion=gini, max_depth=10;, score=1.000 total time=   0.9s\n",
      "[CV 4/5] END ......criterion=gini, max_depth=10;, score=1.000 total time=   0.6s\n",
      "[CV 5/5] END ......criterion=gini, max_depth=10;, score=1.000 total time=   0.7s\n",
      "[CV 1/5] END ......criterion=gini, max_depth=12;, score=1.000 total time=   0.9s\n",
      "[CV 2/5] END ......criterion=gini, max_depth=12;, score=1.000 total time=   0.9s\n",
      "[CV 3/5] END ......criterion=gini, max_depth=12;, score=1.000 total time=   0.9s\n",
      "[CV 4/5] END ......criterion=gini, max_depth=12;, score=1.000 total time=   0.7s\n",
      "[CV 5/5] END ......criterion=gini, max_depth=12;, score=1.000 total time=   0.7s\n",
      "[CV 1/5] END ....criterion=entropy, max_depth=2;, score=0.997 total time=   0.5s\n",
      "[CV 2/5] END ....criterion=entropy, max_depth=2;, score=0.997 total time=   0.5s\n",
      "[CV 3/5] END ....criterion=entropy, max_depth=2;, score=0.998 total time=   0.5s\n",
      "[CV 4/5] END ....criterion=entropy, max_depth=2;, score=0.998 total time=   0.5s\n",
      "[CV 5/5] END ....criterion=entropy, max_depth=2;, score=0.997 total time=   0.5s\n",
      "[CV 1/5] END ....criterion=entropy, max_depth=4;, score=0.998 total time=   0.7s\n",
      "[CV 2/5] END ....criterion=entropy, max_depth=4;, score=0.997 total time=   0.7s\n",
      "[CV 3/5] END ....criterion=entropy, max_depth=4;, score=0.998 total time=   0.7s\n",
      "[CV 4/5] END ....criterion=entropy, max_depth=4;, score=0.998 total time=   0.5s\n",
      "[CV 5/5] END ....criterion=entropy, max_depth=4;, score=0.998 total time=   0.5s\n",
      "[CV 1/5] END ....criterion=entropy, max_depth=6;, score=0.999 total time=   0.6s\n",
      "[CV 2/5] END ....criterion=entropy, max_depth=6;, score=0.999 total time=   0.7s\n",
      "[CV 3/5] END ....criterion=entropy, max_depth=6;, score=1.000 total time=   0.5s\n",
      "[CV 4/5] END ....criterion=entropy, max_depth=6;, score=0.999 total time=   0.5s\n",
      "[CV 5/5] END ....criterion=entropy, max_depth=6;, score=0.999 total time=   0.5s\n",
      "[CV 1/5] END ....criterion=entropy, max_depth=8;, score=1.000 total time=   0.8s\n",
      "[CV 2/5] END ....criterion=entropy, max_depth=8;, score=1.000 total time=   0.8s\n",
      "[CV 3/5] END ....criterion=entropy, max_depth=8;, score=1.000 total time=   0.8s\n",
      "[CV 4/5] END ....criterion=entropy, max_depth=8;, score=1.000 total time=   0.5s\n",
      "[CV 5/5] END ....criterion=entropy, max_depth=8;, score=1.000 total time=   0.5s\n",
      "[CV 1/5] END ...criterion=entropy, max_depth=10;, score=1.000 total time=   0.8s\n",
      "[CV 2/5] END ...criterion=entropy, max_depth=10;, score=1.000 total time=   0.7s\n",
      "[CV 3/5] END ...criterion=entropy, max_depth=10;, score=1.000 total time=   0.5s\n",
      "[CV 4/5] END ...criterion=entropy, max_depth=10;, score=1.000 total time=   0.5s\n",
      "[CV 5/5] END ...criterion=entropy, max_depth=10;, score=1.000 total time=   0.5s\n",
      "[CV 1/5] END ...criterion=entropy, max_depth=12;, score=1.000 total time=   0.8s\n",
      "[CV 2/5] END ...criterion=entropy, max_depth=12;, score=1.000 total time=   0.8s\n",
      "[CV 3/5] END ...criterion=entropy, max_depth=12;, score=1.000 total time=   0.8s\n",
      "[CV 4/5] END ...criterion=entropy, max_depth=12;, score=1.000 total time=   0.5s\n",
      "[CV 5/5] END ...criterion=entropy, max_depth=12;, score=1.000 total time=   0.5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(class_weight='balanced'),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [2, 4, 6, 8, 10, 12]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run grid search only on training set using cross-validation\n",
    "parameters = {'criterion':['gini','entropy'], 'max_depth' : [2,4,6,8,10,12]}\n",
    "model3 = GridSearchCV(DecisionTreeClassifier(class_weight='balanced'), parameters, cv=5, verbose=3)\n",
    "# fit on the trainning dataset\n",
    "model3.fit(df_X_train_stand, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'criterion': 'entropy', 'max_depth': 12}\n",
      "accuracy : 0.9997767385729371\n",
      "Best Model: DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=12)\n"
     ]
    }
   ],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",model3.best_params_)\n",
    "print(\"accuracy :\",model3.best_score_)\n",
    "print('Best Model:',model3.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = model3.predict(df_X_test_stand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      1.00      1.00     41313\n",
      "     class 1       0.94      0.80      0.86       119\n",
      "\n",
      "    accuracy                           1.00     41432\n",
      "   macro avg       0.97      0.90      0.93     41432\n",
      "weighted avg       1.00      1.00      1.00     41432\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAEGCAYAAAC0DiQ1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAmC0lEQVR4nO3de7xVVbn/8c8XUPACgiDITfGCGqBikGkeS6WfcuqcNIPCLOjECfWnabfjrfJWlFZGWWlpdgDTlNSSTDPTzBuBmFwEUym8bEEQRUVFE3zOH3MsXGzXXnttWHuvuRff9+s1X3utZ84x1lhsfRiMOeYYigjMzKw2OtS6AWZmWzInYTOzGnISNjOrISdhM7MachI2M6uhTrVuQC2p0zahrbvWuhnWAge8a5daN8Fa4Mknn2DVqlXanDo6dts1Yt3aiq6Ntc/dFhGjN+fz2tqWnYS37krnvT9e62ZYC9w3+8e1boK1wCHvHbnZdcS6tRX/f/r6vJ/02uwPbGNbdBI2s/ZAoPodOXUSNrN8E9ChY61b0Wrq968XM6sfUmVHRVWpo6SHJN2c3u8o6XZJj6efPYquPUvSEkmPSjqqKD5C0sJ07hIp+3BJnSVdl+KzJQ1qrj1OwmaWc2k4opKjMqcBjxS9PxO4IyIGA3ek90gaAowDhgKjgUslFbrklwGTgMHpKNwMnAisjog9gSnARc01xknYzPKvSj1hSQOADwM/LwofDUxLr6cBxxTFr42INyJiKbAEOFBSX6BbRMyKbPGd6Y3KFOq6HhhV6CU3xUnYzPJNtKQn3EvS3KJjUqPafgCcDrxVFOsTEcsB0s/eKd4feLrouoYU659eN45vVCYi1gEvAT3LfT3fmDOznKt8vBdYFREl58VJ+g9gZUQ8KOmwyj74HaJMvFyZJjkJm1n+VWd2xCHARyR9COgCdJP0S2CFpL4RsTwNNaxM1zcAA4vKDwCWpfiAEvHiMg2SOgE7AC+Ua5SHI8ws56pzYy4izoqIARExiOyG250R8SlgJjAhXTYBuCm9ngmMSzMediO7ATcnDVmskXRQGu8d36hMoa4x6TPcEzazdky0ZDhiU1wIzJA0EXgKGAsQEYskzQAWA+uAkyNifSpzEjAV2Aa4NR0AVwJXSVpC1gMe19yHOwmbWf5V+Ym5iLgLuCu9fh4Y1cR1k4HJJeJzgWEl4q+TknilnITNLOf82LKZWe0I6Fi/jy07CZtZ/rXumHBNOQmbWc55OMLMrLbcEzYzqyH3hM3MaqQFy1S2R07CZpZ/dbyou5OwmeWcb8yZmdWWhyPMzGqksJ5wnXISNrOc83CEmVlt+cacmVkNeUzYzKxG5OEIM7Pack/YzKx2mtk1vl2r3z6+mdWFbHcjVXSUrUfqImmOpPmSFkk6P8XPk/SMpHnp+FBRmbMkLZH0qKSjiuIjJC1M5y5Je82R9qO7LsVnSxrU3PdzT9jM8k1CHarSE34DOCIiXpG0FXCvpMLecFMi4nsbf6yGkO0RNxToB/xJ0l5pn7nLgEnAX4FbgNFk+8xNBFZHxJ6SxgEXAZ8o1yj3hM0s96rRE47MK+ntVukotxPy0cC1EfFGRCwFlgAHSuoLdIuIWWkn5enAMUVlpqXX1wOj1EzDnITNLPeqkYRTPR0lzQNWArdHxOx06hRJCyT9QlKPFOsPPF1UvCHF+qfXjeMblYmIdcBLQM9ybXISNrPca0ES7iVpbtExqbieiFgfEcOBAWS92mFkQwt7AMOB5cDFhY8t0ZQoEy9XpkkeEzazfBOlU1tpqyJiZHMXRcSLku4CRhePBUu6Arg5vW0ABhYVGwAsS/EBJeLFZRokdQJ2AF4o1xb3hM0s10RlveAKZkfsJKl7er0N8EHg72mMt+CjwMPp9UxgXJrxsBswGJgTEcuBNZIOSuO944GbispMSK/HAHemceMmuSdsZrnXoUNV+ot9gWmSOpJ1QGdExM2SrpI0nGzY4AngBICIWCRpBrAYWAecnGZGAJwETAW2IZsVUZhlcSVwlaQlZD3gcc01yknYzHKvGg9rRMQC4IAS8U+XKTMZmFwiPhcYViL+OjC2Je1yEjazfGvZmHC74yRsZrlXz48tOwmbWa4VbszVKydhM8u9Kj22nEtOwmaWb/JwhJlZTTkJm5nVkJOwmVmN+MacmVmt1W8OdhI2s5xT1R5bziUnYTPLPQ9HmJnVUv3mYCfhvOvQQfx5+uksX/kS4770U44edQBnTPoQew/qw6jPfI95jzwFwLuH7MoPvnockP33euEVt/D7uxYAsP8+A7n03E/TpfNW3H7fIs68+HoAJn/xWA4duRcA23Temp123J5BR5ze9l9yC/bSmtc49ZvX8Mg/liPBj75+PAfut3utm5U77glXiaTzgFcab6hXpbpH8PbScrcApzW3jmd7cOK4w3ls6Qq6btcFgEf+sYzxp1/BlLOO2+i6R/6xjMPHf4f169+iT89u3HPNWfzhnodZv/4tLj7zE3zhW7/igYVL+fUPT+KD7xvCn+5fzFen3Lih/Oc+/gH223sA1rbOvPh6Rh08hGkX/Tf/enMda1//V62blDuVbl3UXtXTaHdh99PB6Rhd2+Zsvn69u3Pkvw1l+k33b4g99sQKljy58h3Xrn3jTdavfwuAzp23ovD3T5+e3ei6XRceWLgUgGt/P4cPf2C/d5Qfc9QIbrjtwdb4GtaEl19Zy/0P/YNPH30wAFtv1Ykdum5b41blU7X2mMujVkvCksanjfPmS7qqxPnPSXognb9B0rYpPlbSwyl+d4oNlTRH0rxU5+BGdZXb/bTd+taXPsa5l/yWt96qrEM/Yuiu3H/dV7nvV2fzpQuvZf36t+jbuzvLVr644ZplK1+k707dNyo3cOce7NKvJ3fPfbSKrbfmPPnM8/Tqvj0nn/9L3n/8hZz6zat5de0btW5WLqmDKjrao1ZJwpKGAl8FjoiI/YHTSlx2Y0S8J51/BJiY4ucAR6X4R1LsROCHaYO+kWy80ymU3/20cdsmFTYBjHVrW/7l2shR/zaMVavXMP/vTzd/cfLgoid53ycmM2rCd/jiZ46k89adKNU5iEb7Dh575Ahm3jGv4mRv1bFu/XrmP/o0nx1zKHdffSbbdunMD6beXutm5ZJ7wi13BHB9RKwCiIhSG90Nk3SPpIXA8cDQFL8PmCrpc0DHFJsFnC3pDGDXiGicPSve4TQiLo+IkRExUp22adm3akPv3X93Rh+6L/NvOp8rv/VfHPqevfjZBeMrKvvYEyt4be2/eNce/Vi24kX69e6+4Vy/3t159rmXNrr+2CNHcMMf51az+VaBfr170K93d0YOGwTAR0YNZ/6jlf+lu8WQk/CmEM1s80x2E+2UiNgXOB/oAhARJwJfI9uxdJ6knhFxDVmveC1wm6QjGtVVbvfTdumCn8xk2H98nf2PPpeJZ/8v9zzwGCecM73J63fp15OOHbNf58Cde7Dnrn14atnzrHj+ZV557Y0N/6OP+/CB3PKXBRvK7blrb7p33ZY5C5a26vexd+rTqxv9+/Tg8SdWAHD3A4+y924717hV+SNAquwoW4/UJQ1rzpe0SNL5Kb6jpNslPZ5+9igqc5akJZIelXRUUXyEpIXp3CVpw0/SpqDXpfhsSYOa+36tNTviDuA3kqZExPOSdizRG+4KLJe0FVlP+BkASXtExGxgtqT/BAZK2gH4Z0RcIml3YD/gzkJFEbFc0hpJBwGzyXY//VErfbea+vBh+3HRV8bSq8f2XDflRBY+9gxjTv0JB++/O6d95kjWrVvPW28FX7noOl546VUAvnzhdVx67qfo0nkr/nT/Ym6/f/GG+j525EhuvN035GrlO18Zy6RzpvKvN9czqH8vfnLOp2rdpByqWi/3DbIh0ldS3rlX0q3AscAdEXGhpDOBM4EzJA0h26hzKNAP+JOkvdJmn4WJAH8lm401mmyzz4nA6ojYU9I44CLgE2W/XWvN4pI0AfgfYD3wUER8pniKmqSTgNOBJ4GFQNd0zY1ksxtElsy/QPaH8ingTeBZ4JONk7qkkWy8++nnm5ui1mHb3tF5749X5wtbm1j9wI9r3QRrgUPeO5IHH5y7WRm0y857xa4TKutTPfad0Q9GxMjmrksTAe4l2zV5OnBY6sz1Be6KiL0lnQUQEd9OZW4DziPbkfnPEbFPih+Xyp9QuCYiZknqRJavdiqXi1ptnnBETAOmNYqdV/T6MrK/TRqXO7ZEdd9OR7nPK7n7qZm1cxUMNRTpJan4BsflEXH5hqqy7e4fBPYEfhIRsyX1iYjlsOFf1b3T5f3JeroFhRv+b9L0RID+wNOprnWSXgJ6AquaarCfmDOzXBPZk6MVWlWuJ5yGEoZL6k42ZFqu49bUDf9yEwEqniRQUE8Pa5hZnarGjbliEfEicBfZWO6KNAxReOag8DRUA9kEgYLCDf9yEwE2lEnDETsApWaHbeAkbGa5V40papJ2Sj1gJG0DfBD4OzATmJAumwDclF7PBMalGQ+7kd2rmpOGLtZIOijNihjfqEyhrjHAnc3dm/JwhJnlWwt7uWX0BaalceEOwIyIuFnSLGCGpInAU8BYgIhYJGkGsBhYB5ychjMgu6E3lbcnAtya4lcCV0laQtYDHtdco5yEzSzXhKqyqHtELAAOKBF/HhjVRJnJwOQS8ZITASLidVISr5STsJnlXjt9GK4iTsJmlnvt9ZHkSjgJm1m+VW9MOJechM0s17K1I+o3CzsJm1nu1XEOdhI2s/xrwRNz7Y6TsJnlmzwcYWZWM4X1hOuVk7CZ5Vz73TWjEk7CZpZ7dZyDnYTNLOfkG3NmZjXjecJmZjXmJGxmVkN1nIOdhM0s/9wTNjOrFS/gY2ZWO9mi7vWbhb3HnJnlXgepoqM5kgZK+rOkRyQtknRaip8n6RlJ89LxoaIyZ0laIulRSUcVxUdIWpjOXZL2myPtSXddis+WNKjsd9vUPxQzs7ZSxd2W1wFfjoh3AQcBJ0saks5NiYjh6bgl+1wNIdsnbijZzsyXpj3qAC4DJpFtADo4nQeYCKyOiD2BKcBF5RrkJGxmuSZVZ7dlgIhYHhF/S6/XAI8A/csUORq4NiLeiIilwBLgQEl9gW4RMSvtpjwdOKaozLT0+npglMo0zknYzHKvgyo7gF6S5hYdk5qqMw0THADMTqFTJC2Q9AtJPVKsP/B0UbGGFOufXjeOb1QmItYBLwE9m2pHkzfmJP0IiKbOR8SpTZ0zM6umFtyYWxURI5u7SNL2wA3AFyLiZUmXAd8gy3nfAC4GPkv2wF5jUSZOM+feodzsiLllzpmZtQmRzZCoWn3SVmQJ+OqIuBEgIlYUnb8CuDm9bQAGFhUfACxL8QEl4sVlGiR1AnYAXmiqPU0m4YiYVvxe0nYR8Wq5L2dm1hqqNUMtjc1eCTwSEd8viveNiOXp7UeBh9PrmcA1kr4P9CO7ATcnItZLWiPpILLhjPHAj4rKTABmAWOAO9O4cUnNzhOWdHBq9PbALpL2B06IiP9f4fc2M9t0Fd50q9AhwKeBhZLmpdjZwHGShpMNGzwBnAAQEYskzQAWk82sODki1qdyJwFTgW2AW9MBWb68StISsh7wuHINquRhjR8AR5FldyJivqT3V1DOzKwqqpWDI+JeSo/Z3lKmzGRgcon4XGBYifjrwNhK21TRE3MR8XSjv4nWN3WtmVk1CSp6EKO9qiQJPy3pfUBI2ho4lWxunZlZm9jSH1s+ETiZbO7bM8Dw9N7MrNVV+rRce+0sN9sTjohVwPFt0BYzs5LqeTii2Z6wpN0l/U7Sc5JWSrpJ0u5t0TgzMyjMFW7+aI8qGY64BpgB9CWbJ/dr4Fet2Sgzs2LVWjsijypJwoqIqyJiXTp+SZlH8MzMqimbHVHx2hHtTrm1I3ZML/8s6UzgWrLk+wng923QNjMzUH0v6l7uxtyDbLxQxQlF5wqLXJiZtbr2OtRQiXJrR+zWlg0xMyulMBxRryp6Yk7SMGAI0KUQi4jprdUoM7NiW2RPuEDSucBhZEn4FuDfgXvJVpI3M2t19ZuCK5sdMQYYBTwbEf8F7A90btVWmZklEnTsoIqO9qiS4Yi1EfGWpHWSugErAT+sYWZtZosejgDmSuoOXEE2Y+IVYE5rNsrMrFgd5+CK1o4oLN7+U0l/INthdEHrNsvMLCNU12tHlHtY493lzhW2jTYza1XteIW0SpTrCV9c5lwAR1S5LW3ugHftwn2zf1zrZphZM6o1JixpINnMrp2Bt4DLI+KH6Qnh64BBZNsbfTwiVqcyZwETyTazODUibkvxEby9vdEtwGkREZI6p88YATwPfCIinmiqTeUe1jh8M76rmVlVCOhYva7wOuDLEfE3SV2BByXdDnwGuCMiLkzLNJwJnCFpCNkecUPJFjD7k6S90j5zlwGTgL+SJeHRZPvMTQRWR8SeksYBF5Et91BSJVPUzMxqqloL+ETE8sJQakSsIdslqD9wNFDYYX4acEx6fTRwbUS8ERFLgSXAgZL6kt0fm5V2Up7eqEyhruuBUSrTlXcSNrPca41V1CQNAg4g27K+T2HL+/Szd7qsP/B0UbGGFOufXjeOb1QmItYBLwE9m2pHRY8tm5nVSrZ1UcUZtpekuUXvL4+Iy99Zp7YHbgC+EBEvl6m/1IkoEy9XpqRKHlsW2fZGu0fEBZJ2AXaOCM8VNrM20YJe7qqIGFnuAklbkSXgqyPixhReIalvRCxPQw0rU7wBGFhUfACwLMUHlIgXl2mQ1AnYAXihqfZUMhxxKXAwcFx6vwb4SQXlzMyqolobfaZO5ZXAIxHx/aJTM4EJ6fUE4Kai+DhJnSXtBgwG5qQhizWSDkp1jm9UplDXGODONG5cUiXDEe+NiHdLegggIlZL2rqCcmZmm01Ap+rNjjgE+DSwUNK8FDsbuBCYIWki8BQwFiAiFkmaASwmm1lxcpoZAXASb09RuzUdkCX5qyQtIesBjyvXoEqS8JuSOpLGNCTtRDa/zsysTVQrB0fEvTS9KNuoJspMBiaXiM8FhpWIv05K4pWoJAlfAvwG6C1pMln3+muVfoCZ2eaQttDHlgsi4mpJD5L9LSHgmIh4pNVbZmaW1HEOrmh2xC7Aa8DvimMR8VRrNszMrKCdLhVckUqGI37P2/PiugC7AY+SPcZnZtaqBO12wfZKVDIcsW/x+7S62glNXG5mVl2b8DRce9LiJ+bSwhfvaY3GmJmVojreZa6SMeEvFb3tALwbeK7VWmRmVsRb3kPXotfryMaIb2id5piZvdMWm4TTQxrbR8T/tFF7zMzeYYvc6FNSp4hYV26bIzOz1pZteV/rVrSecj3hOWTjv/MkzQR+DbxaOFm0+pCZWavaop+YA3Yk2yfpCN6eLxyAk7CZtbot+cZc7zQz4mHeuYhxk8uymZlVWx13hMsm4Y7A9rRwlXgzs+oSHbbQecLLI+KCNmuJmVkJYsvtCdfx1zazdkPQqY4Hhcsl4ZILHJuZtaUtticcEU1uTGdm1pbqeYpaHU+BNrN6UcWNPn8haaWkh4ti50l6RtK8dHyo6NxZkpZIelTSUUXxEZIWpnOXpM0+SRuCXpfisyUNaq5NTsJmlmsiS1SVHBWYCowuEZ8SEcPTcQuApCFkm3QOTWUuTUs5AFwGTCLbfXlwUZ0TgdURsScwBbiouQY5CZtZvikbjqjkaE5E3E22A3IljgaujYg3ImIpsAQ4UFJfoFtEzEpb2U8HjikqMy29vh4YpWYWvnASNrNcy56YqzgJ95I0t+iYVOHHnCJpQRqu6JFi/YGni65pSLH+6XXj+EZlImId8BLQs9wHOwmbWe6pwgNYFREji47LK6j+MmAPYDiwHLi46GMba/z0cHG8XJkmOQmbWe5V68ZcKRGxIiLWR8RbwBXAgelUAzCw6NIBwLIUH1AivlEZSZ2AHWhm+MNJ2MxyTkiVHZtUezbGW/BRsvVyAGYC49KMh93IbsDNiYjlwBpJB6Xx3vHATUVlJqTXY4A707hxk1q8x5yZWVsqzI6oSl3Sr4DDyMaOG4BzgcMkDScbNniCtJFxRCySNANYTLar0MkRsT5VdRLZTIttgFvTAXAlcJWkJWQ94HHNtclJ2Mxyr1oPa0TEcSXCV5a5fjIwuUR8LjCsRPx1YGxL2uQkbGb5pi10eyMzszyo5nBEHjkJm1nuuSdsZlZD9ZuCnYTNLOcEdHRP2Mysduo4BzsJm1neCdXxgISTsJnlnnvCZmY1kk1Rq98s7CRsZvm2GYvztAdOwmaWe/W8x5yTsJnlWraoe61b0XqchM0s9zw7wsyshup4NMJJuD1reHY1J503nZXPv0wHiQkfPYQTjzt8w/kfXfUnzrnktyy5/UJ6dt++hi21Yj/91Z+Z9tv7IYLxxxzCSZ88nAsv/z3Tf3v/ht/T10/+CEceMrTGLc0P94SrRNJ5wCsR8b1WqHsy2Qr3PSJii8g4nTp14JtfOJb99xnImldf5/DxF3HYe/dhn9370vDsau6a83cG7Nyj+YqszSxesoxpv72fO6b9D1t36siYUy/lyH/Lku1Jxx3O5z/9wRq3MH/qfUy4nlaI+x1v7w21Rdi51w7sv0+2BVbX7bqw16CdWf7ciwB8dcoNnPf5Y+p69an26LEnnuU9+w5i2y5b06lTRw55957cfNf8Wjcr3yrcabm9zqBotSQsaXzaQnq+pKtKnP+cpAfS+RskbZviYyU9nOJ3p9hQSXMkzUt1Dm5cX0T8Ne39tEV6atnzLHi0gRFDB3HLXxbQd6fu7LvXgOYLWpt61x79uP+hJbzw4iu89vq/uP3+RTyzYjUAV/z6bg457luccsEvefHl12rc0nxpwW7L5evJtrRfKenhotiOkm6X9Hj62aPo3FmSlkh6VNJRRfERkhamc5ekveZI+9Fdl+KzJQ1qrk2tkoQlDQW+ChwREfsDp5W47MaIeE86/wgwMcXPAY5K8Y+k2InADyNiODCSbEfTTW3bJElzJc19btVzm1pNrrzy2huMP+PnfPtLH6NTp458/39v46wTP1zrZlkJe++2M6eN/3989JQfM+bUnzB0cH86dezIZz92KA/95jzuufpM+vTqxtd+cGOtm5ob2XBE1XrCU4HRjWJnAndExGDgjvQeSUPI9ogbmspcKqljKnMZMIls88/BRXVOBFZHxJ7AFOCi5hrUWj3hI4DrI2IVQESU2vJ5mKR7JC0Ejif7ogD3AVMlfQ4ofOFZwNmSzgB2jYi1m9qwiLg8IkZGxMideu20qdXkxpvr1jPhjCsYO3ok/3nEcJY2PMeTy57n0E9+m/0+cg7LVr7IBz51EStWvVzrplry6aPfx19+eSa3XP5FenTbjt0H7kTvnt3o2LEDHTp0YMIxh/Dgoidr3cxcqVZPOCLu5p1b0B8NTEuvpwHHFMWvjYg3ImIpsAQ4MO3O3C0iZqWdlKc3KlOo63pgVKGX3JTWSsIi27m0nKnAKRGxL3A+0AUgIk4EvgYMBOZJ6hkR15D1itcCt0k6opXa3a5EBJ//xtXsNWhnTj5+FABD9+zP43+8kAUzL2DBzAvo17s7f/nlGfTp1a3GrbWC515YA8DTz77AzX+ez5ijRvLsqpc2nL/5rvm8a4++TRXfMlWehXsV/qWbjkkV1N6nMJSZfvZO8f7A00XXNaRYfzb+13ghvlGZiFgHvAT0LPfhrTU74g7gN5KmRMTzknYs0RvuCiyXtBVZT/gZAEl7RMRsYLak/wQGStoB+GdEXCJpd2A/4M5Wanu78df5/+S6W+YwZM9+HPrJbwOe2tQejD/j56x+6VU6derId0//ON27bcsJ50xj4WMNSGKXvjsy5exSmwJvuVpw021VRIys0seW+tAoEy9XpkmtkoQjYlGaMvYXSeuBh4DPNLrs68Bs4ElgIVlSBvhuuvEmsmQ+n2yM5lOS3gSeBS5o/JmSvgN8EthWUgPw84g4r8pfLVcOHr4Hqx/4cdlrFsx8xx+V1ditV3zxHbGfXTChBi1pP1p53sMKSX0jYnkaaliZ4g1k/yIvGAAsS/EBJeLFZRokdQJ24J3DHxtptXnCETGNt8dGCrHzil5fRja43bjcsSWq+3Y6yn3e6cDpm9JWM8u51s3CM4EJwIXp501F8WskfR/oR3YDbk5ErJe0RtJBZB3J8cCPGtU1CxgD3JnGjZvkJ+bMLNey4d7qZGFJvwIOIxs7bgDOJUu+MyRNBJ4CxsKGf9HPABYD64CTI2J9quoksvta2wC3pgPgSuAqSUvIesDjmmuTk7CZ5VsV1xOOiKYG20c1cf1kYHKJ+FxgWIn466QkXiknYTPLvfb5LFxlnITNLOdU14/fOwmbWe7VcQ52EjazfKv0abj2yknYzPKvjrOwk7CZ5Z4XdTczqyGPCZuZ1UoV5wnnkZOwmeWehyPMzGpEuCdsZlZTdZyDnYTNrB2o4yzsJGxmudded1KuhJOwmeVe/aZgJ2Ezaw/qOAs7CZtZrlVzUfc8chI2s3yr84c1WmvLezOzqql8x/sK6pKekLRQ0jxJc1NsR0m3S3o8/exRdP1ZkpZIelTSUUXxEameJZIu0SYueuwkbGY5ly3qXsnRAodHxPCIGJnenwncERGDyXZ5PxNA0hCyfeKGAqOBSyV1TGUuAyaRbQA6OJ1vMSdhM8s9qbJjMxzN27vDTwOOKYpfGxFvRMRSYAlwoKS+QLeImJV2U55eVKZFnITNLNcqHYpoQQ4O4I+SHpQ0KcX6RMRygPSzd4r3B54uKtuQYv3T68bxFvONOTPLv8ozbK/COG9yeURc3uiaQyJimaTewO2S/t7CT44y8RZzEjaz3GvBFLVVReO8JUXEsvRzpaTfAAcCKyT1jYjlaahhZbq8ARhYVHwAsCzFB5SIt5iHI8ws96o1JixpO0ldC6+BI4GHgZnAhHTZBOCm9HomME5SZ0m7kd2Am5OGLNZIOijNihhfVKZF3BM2s3wTdKjePOE+wG/STIpOwDUR8QdJDwAzJE0EngLGAkTEIkkzgMXAOuDkiFif6joJmApsA9yajhZzEjazdqA6WTgi/gnsXyL+PDCqiTKTgckl4nOBYZvbJidhM8s1L+puZlZjdZyDnYTNLP/cEzYzq6FNXJahXXASNrPcq98U7CRsZjlXhXUhcs1J2Mxyz4u6m5nVUv3mYCdhM8u/Os7BTsJmlnfylvdmZrVS70/MeRU1M7Mack/YzHKvnnvCTsJmlnueomZmVit+WMPMrHbq/cack7CZ5Z6HI8zMasg9YTOzGqrjHOwkbGbtQB1nYSdhM8s1QV0/tqyIqHUbakbSc8CTtW5HK+gFrKp1I6xF6vV3tmtE7LQ5FUj6A9mfTyVWRcTozfm8trZFJ+F6JWluRIysdTuscv6dbbm8doSZWQ05CZuZ1ZCTcH26vNYNsBbz72wL5TFhM7Mack/YzKyGnITNzGrISbidkHSepK+0Ut0jJC2UtETSJVIdz4xvQ638O5ss6WlJr7RG/dZ2nIQN4DJgEjA4He1qsvsW6nfAgbVuhG0+J+EckjRe0gJJ8yVdVeL85yQ9kM7fIGnbFB8r6eEUvzvFhkqaI2leqnNwo7r6At0iYlZkd2mnA8e0/resL235OwOIiL9GxPLW/2bW2rx2RM5IGgp8FTgkIlZJ2rHEZTdGxBXp+m8CE4EfAecAR0XEM5K6p2tPBH4YEVdL2hro2Kiu/kBD0fuGFLMK1eB3ZnXEPeH8OQK4PiJWAUTECyWuGSbpHkkLgeOBoSl+HzBV0ud4+3/cWcDZks4ge45/baO6So3/et5iy7T178zqiJNw/ojmk+BU4JSI2Bc4H+gCEBEnAl8DBgLzJPWMiGuAjwBrgdskHdGorgZgQNH7AcCyzf0SW5i2/p1ZHXESzp87gI9L6gnQxD9tuwLLJW1F1qsiXbtHRMyOiHPIVuQaKGl34J8RcQkwE9ivuKI0rrhG0kFpVsR44KbW+GJ1rE1/Z1ZfnIRzJiIWAZOBv0iaD3y/xGVfB2YDtwN/L4p/N001exi4G5gPfAJ4WNI8YB+yG2+NnQT8HFgC/AO4tTrfZstQi9+ZpO9IagC2ldQg6bwqfiVrQ35s2cyshtwTNjOrISdhM7MachI2M6shJ2EzsxpyEjYzqyEnYWuSpPVp/YKHJf26sN7BJtY1VdKY9PrnkoaUufYwSe/bhM94QtI7duVtKt7omhatRtaaK6TZlsVJ2MpZGxHDI2IY8C+yNQ02kLRJaxpExH9HxOIylxwGtDgJm7VHTsJWqXuAPVMv9c+SrgEWSuoo6btphbAFkk4AUObHkhZL+j3Qu1CRpLskjUyvR0v6W1pF7A5Jg8iS/RdTL/xQSTullcceSMchqWxPSX+U9JCkn1F6HYyNSPqtpAclLZI0qdG5i1Nb7pC0U4rtIekPqcw9kvapyp+mWeJV1KxZkjoB/w78IYUOBIZFxNKUyF6KiPdI6gzcJ+mPwAHA3sC+QB9gMfCLRvXuBFwBvD/VtWNEvCDpp8ArEfG9dN01wJSIuFfSLsBtwLuAc4F7I+ICSR8mWxO5OZ9Nn7EN8ICkGyLieWA74G8R8WVJ56S6TyHbgPPEiHhc0nuBS8kW7DGrCidhK2eb9OgsZD3hK8mGCeZExNIUPxLYrzDeC+xAtjD8+4FfRcR6YJmkO0vUfxBwd6GuJlYfA/ggMERvb/jRTVLX9BnHprK/l7S6gu90qqSPptcDU1ufB94CrkvxXwI3Sto+fd9fF3125wo+w6xiTsJWztqIGF4cSMno1eIQ8PmIuK3RdR+i+ZXFKll9DLJhs4MbL+mY2lLxc/eSDiNL6AdHxGuS7iKtZlZCpM99sfGfgVk1eUzYNtdtwElpdTAk7SVpO7LFaMalMeO+wOElys4CPiBpt1S2sPrYGrJVxwr+SDY0QLpueHp5N2lFMkn/DvRopq07AKtTAt6HrCde0AEo9OY/STbM8TKwVNLY9BmStH8zn2HWIk7Ctrl+Tjbe+7e0EtjPyP6F9RvgcWAh2R52f2lcMCKeIxvHvTGtPlYYDvgd8NHCjTngVGBkuvG3mLdnaZwPvF/S38iGRZ5qpq1/ADpJWgB8A/hr0blXgaGSHiQb870gxY8HJqb2LQKOruDPxKxiXkXNzKyG3BM2M6shJ2EzsxpyEjYzqyEnYTOzGnISNjOrISdhM7MachI2M6uh/wMJG7uXql5PtQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#performance results\n",
    "print(classification_report(y_test, y_pred3, target_names=target_names))\n",
    "plot_confusion_matrix(model3, df_X_test_stand, y_test, display_labels=target_names,cmap=plt.cm.Blues);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling using OSS\n",
    "OneSidedSelection (OSS) is an undersampling technique that combines Tomek Links and the Condensed Nearest Neighbor (CNN) Rule. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "from imblearn.under_sampling import OneSidedSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 35451, 1: 512})\n"
     ]
    }
   ],
   "source": [
    "# define the undersampling method\n",
    "oss = OneSidedSelection(random_state=0)\n",
    "# transform the dataset\n",
    "X_oss, y_oss = oss.fit_resample(df_X_train_stand, y_train)\n",
    "# summarize the new class distribution\n",
    "counter = Counter(y_oss)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Weighted Support Vector Machine with One Sided Selection (SVM+OSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END ...............................C=1;, score=0.993 total time=   4.9s\n",
      "[CV 2/5] END ...............................C=1;, score=0.993 total time=   5.3s\n",
      "[CV 3/5] END ...............................C=1;, score=0.996 total time=   5.7s\n",
      "[CV 4/5] END ...............................C=1;, score=0.996 total time=   5.2s\n",
      "[CV 5/5] END ...............................C=1;, score=0.993 total time=   5.1s\n",
      "[CV 1/5] END ...............................C=5;, score=0.997 total time=   2.6s\n",
      "[CV 2/5] END ...............................C=5;, score=0.998 total time=   2.9s\n",
      "[CV 3/5] END ...............................C=5;, score=0.998 total time=   3.2s\n",
      "[CV 4/5] END ...............................C=5;, score=0.998 total time=   2.9s\n",
      "[CV 5/5] END ...............................C=5;, score=0.997 total time=   3.2s\n",
      "[CV 1/5] END ..............................C=10;, score=0.997 total time=   2.1s\n",
      "[CV 2/5] END ..............................C=10;, score=0.998 total time=   2.5s\n",
      "[CV 3/5] END ..............................C=10;, score=0.998 total time=   2.5s\n",
      "[CV 4/5] END ..............................C=10;, score=0.998 total time=   2.3s\n",
      "[CV 5/5] END ..............................C=10;, score=0.997 total time=   1.9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(class_weight='balanced'),\n",
       "             param_grid={'C': [1, 5, 10]}, verbose=3)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run grid search only on training set using cross-validation\n",
    "parameters = {'C':[1, 5, 10] }\n",
    "model4 = GridSearchCV(SVC(class_weight='balanced', kernel='rbf'), parameters, cv=5, verbose=3)\n",
    "model4.fit(X_oss, y_oss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'C': 10}\n",
      "accuracy : 0.9979145232503421\n",
      "Best Model: SVC(C=10, class_weight='balanced')\n"
     ]
    }
   ],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",model4.best_params_)\n",
    "print(\"accuracy :\",model4.best_score_)\n",
    "print('Best Model:',model4.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred4 = model4.predict(df_X_test_stand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      1.00      1.00     41313\n",
      "     class 1       0.91      0.89      0.90       119\n",
      "\n",
      "    accuracy                           1.00     41432\n",
      "   macro avg       0.95      0.95      0.95     41432\n",
      "weighted avg       1.00      1.00      1.00     41432\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#performance results\n",
    "print(classification_report(y_test, y_pred4, target_names=target_names))\n",
    "plot_confusion_matrix(model4, df_X_test_stand, y_test, display_labels=target_names,cmap=plt.cm.Blues);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e)  XG Boost, Extreme Gradient Boosting (XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=1.000 total time=   2.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=1.000 total time=   2.4s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=1.000 total time=   2.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=1.000 total time=   2.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=1.000 total time=   2.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=150;, score=1.000 total time=   3.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=150;, score=1.000 total time=   3.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=150;, score=1.000 total time=   3.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=150;, score=1.000 total time=   3.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=150;, score=1.000 total time=   3.1s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=100;, score=1.000 total time=   2.7s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=100;, score=1.000 total time=   2.7s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=100;, score=1.000 total time=   2.8s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=100;, score=1.000 total time=   2.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=100;, score=1.000 total time=   2.7s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=150;, score=1.000 total time=   3.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=150;, score=1.000 total time=   3.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=150;, score=1.000 total time=   3.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=150;, score=1.000 total time=   3.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=150;, score=1.000 total time=   3.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=1.000 total time=   1.8s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=1.000 total time=   1.9s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=1.000 total time=   1.9s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=1.000 total time=   1.8s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=1.000 total time=   1.9s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=150;, score=1.000 total time=   2.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=150;, score=1.000 total time=   2.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=150;, score=1.000 total time=   2.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=150;, score=1.000 total time=   2.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=150;, score=1.000 total time=   2.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=100;, score=1.000 total time=   2.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=100;, score=1.000 total time=   2.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=100;, score=1.000 total time=   2.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=100;, score=1.000 total time=   2.0s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=100;, score=1.000 total time=   2.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=150;, score=1.000 total time=   2.5s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=150;, score=1.000 total time=   2.6s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=150;, score=1.000 total time=   2.6s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=150;, score=1.000 total time=   2.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=150;, score=1.000 total time=   2.5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     eval_metric='logloss', gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, random_state=None,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, subsample=None,\n",
       "                                     tree_method=None, use_label_encoder=False,\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             param_grid={'learning_rate': [0.1, 0.2], 'max_depth': [5, 10],\n",
       "                         'n_estimators': [100, 150]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run grid search only on training set using cross-validation\n",
    "parameters = {'max_depth': [5, 10],'n_estimators': [100, 150], 'learning_rate': [0.1, 0.2]}\n",
    "model5 = GridSearchCV(XGBClassifier(eval_metric='logloss',use_label_encoder =False), parameters, cv=5, verbose=3)\n",
    "model5.fit(df_X_train_stand, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
      "accuracy : 0.9999517272590135\n",
      "Best Model: XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, eval_metric='logloss',\n",
      "              gamma=0, gpu_id=-1, importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.1, max_delta_step=0,\n",
      "              max_depth=5, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=32,\n",
      "              num_parallel_tree=1, random_state=0, reg_alpha=0, reg_lambda=1,\n",
      "              scale_pos_weight=1, subsample=1, tree_method='exact',\n",
      "              use_label_encoder=False, validate_parameters=1, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",model5.best_params_)\n",
    "print(\"accuracy :\",model5.best_score_)\n",
    "print('Best Model:',model5.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred5 = model5.predict(df_X_test_stand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      1.00      1.00     41313\n",
      "     class 1       0.99      0.90      0.94       119\n",
      "\n",
      "    accuracy                           1.00     41432\n",
      "   macro avg       1.00      0.95      0.97     41432\n",
      "weighted avg       1.00      1.00      1.00     41432\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#performance results\n",
    "print(classification_report(y_test, y_pred5, target_names=target_names))\n",
    "plot_confusion_matrix(model5, df_X_test_stand, y_test, display_labels=target_names,cmap=plt.cm.Blues);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save notebook session\n",
    "import dill\n",
    "dill.dump_session('session_esc-12.db')\n",
    "#to restore a notebook session\n",
    "#dill.load_session('session_esc-12.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
