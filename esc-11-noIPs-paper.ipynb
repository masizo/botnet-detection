{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupiter's Notebook for Scenario 11\n",
    "Requieres: [CategoryEncoders](http://contrib.scikit-learn.org/category_encoders/), [imbalanced-learn](https://imbalanced-learn.org/stable/), [XGBoost](https://pypi.org/project/xgboost/), and [dill](https://pypi.org/project/dill/)<br>\n",
    "`pip install category_encoders`<br>\n",
    "`pip install imbalanced-learn`<br>\n",
    "`pip install xgboost`<br>\n",
    "`pip install dill`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To identify class 0 and 1, respectively\n",
    "target_names = ['class 0', 'class 1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "df=pd.read_csv('esc-11-Mixed-traffic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No trunkated \n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(556478, 52)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataset dimensions, number of sessions and features\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 556217, 1: 261})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#counting classes\n",
    "collections.Counter(df.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proto                 0\n",
      "ts                    0\n",
      "srcIP                 0\n",
      "srcPrt                0\n",
      "dstIP                 0\n",
      "dstPrt                0\n",
      "flowduration          0\n",
      "total_fpackets        0\n",
      "total_bpackets        0\n",
      "total_fpktl           0\n",
      "total_bpktl           0\n",
      "min_fpktl             0\n",
      "min_bpktl             0\n",
      "max_fpktl             0\n",
      "max_bpktl             0\n",
      "mean_fpktl            0\n",
      "mean_bpktl            0\n",
      "std_fpktl             0\n",
      "std_bpktl             0\n",
      "total_fipt            0\n",
      "total_bipt            0\n",
      "min_fipt              0\n",
      "min_bipt              0\n",
      "max_fipt              0\n",
      "max_bipt              0\n",
      "mean_fipt             0\n",
      "mean_bipt             0\n",
      "std_fipt              0\n",
      "std_bipt              0\n",
      "fpsh_cnt              0\n",
      "bpsh_cnt              0\n",
      "furg_cnt              0\n",
      "burg_cnt              0\n",
      "total_fhlen           0\n",
      "total_bhlen           0\n",
      "fPktsPerSecond        0\n",
      "bPktsPerSecond        0\n",
      "flowPktsPerSecond     0\n",
      "flowBytesPerSecond    0\n",
      "mean_flowpktl         0\n",
      "std_flowpktl          0\n",
      "mean_flowipt          0\n",
      "std_flowipt           0\n",
      "flow_fin              0\n",
      "flow_syn              0\n",
      "flow_rst              0\n",
      "flow_ack              0\n",
      "flow_urg              0\n",
      "flow_cwr              0\n",
      "flow_ece              0\n",
      "downUpRatio           0\n",
      "label                 0\n",
      "dtype: int64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#check the number of null values\n",
    "print(df.isnull().sum())\n",
    "print(df.isnull().values.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping Rows with NA inplace\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proto                      2\n",
      "ts                    556478\n",
      "srcIP                  15205\n",
      "srcPrt                 58826\n",
      "dstIP                   9685\n",
      "dstPrt                   675\n",
      "flowduration          411532\n",
      "total_fpackets           754\n",
      "total_bpackets          1028\n",
      "total_fpktl            12662\n",
      "total_bpktl            41013\n",
      "min_fpktl                155\n",
      "min_bpktl                504\n",
      "max_fpktl               1366\n",
      "max_bpktl               1053\n",
      "mean_fpktl             40188\n",
      "mean_bpktl             51916\n",
      "std_fpktl              91695\n",
      "std_bpktl              65622\n",
      "total_fipt            248666\n",
      "total_bipt            218260\n",
      "min_fipt               95415\n",
      "min_bipt               35760\n",
      "max_fipt              235799\n",
      "max_bipt              180903\n",
      "mean_fipt             235038\n",
      "mean_bipt             207850\n",
      "std_fipt              221793\n",
      "std_bipt              206512\n",
      "fpsh_cnt                 149\n",
      "bpsh_cnt                 504\n",
      "furg_cnt                   1\n",
      "burg_cnt                   1\n",
      "total_fhlen             4093\n",
      "total_bhlen             5004\n",
      "fPktsPerSecond        364570\n",
      "bPktsPerSecond        358341\n",
      "flowPktsPerSecond     375963\n",
      "flowBytesPerSecond    476101\n",
      "mean_flowpktl          89815\n",
      "std_flowpktl          132319\n",
      "mean_flowipt          379950\n",
      "std_flowipt           238175\n",
      "flow_fin                  19\n",
      "flow_syn                  16\n",
      "flow_rst                  28\n",
      "flow_ack                1334\n",
      "flow_urg                   1\n",
      "flow_cwr                   4\n",
      "flow_ece                   2\n",
      "downUpRatio           130921\n",
      "label                      2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#sumarize the number of unique values for each column \n",
    "print(df.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete time stamp (ts), srcIP and dstIP features\n",
    "# Models do not learn with IP addresses\n",
    "df.drop(['ts','srcIP','dstIP'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(556478, 49)\n"
     ]
    }
   ],
   "source": [
    "#Dataset dimensions, number of sessions and features\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(556478, 49)\n",
      "(553430, 49)\n"
     ]
    }
   ],
   "source": [
    "#Delete Rows That Contain Duplicate Data\n",
    "print(df.shape)\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proto</th>\n",
       "      <th>srcPrt</th>\n",
       "      <th>dstPrt</th>\n",
       "      <th>flowduration</th>\n",
       "      <th>total_fpackets</th>\n",
       "      <th>total_bpackets</th>\n",
       "      <th>total_fpktl</th>\n",
       "      <th>total_bpktl</th>\n",
       "      <th>min_fpktl</th>\n",
       "      <th>min_bpktl</th>\n",
       "      <th>max_fpktl</th>\n",
       "      <th>max_bpktl</th>\n",
       "      <th>mean_fpktl</th>\n",
       "      <th>mean_bpktl</th>\n",
       "      <th>std_fpktl</th>\n",
       "      <th>std_bpktl</th>\n",
       "      <th>total_fipt</th>\n",
       "      <th>total_bipt</th>\n",
       "      <th>min_fipt</th>\n",
       "      <th>min_bipt</th>\n",
       "      <th>max_fipt</th>\n",
       "      <th>max_bipt</th>\n",
       "      <th>mean_fipt</th>\n",
       "      <th>mean_bipt</th>\n",
       "      <th>std_fipt</th>\n",
       "      <th>std_bipt</th>\n",
       "      <th>fpsh_cnt</th>\n",
       "      <th>bpsh_cnt</th>\n",
       "      <th>furg_cnt</th>\n",
       "      <th>burg_cnt</th>\n",
       "      <th>total_fhlen</th>\n",
       "      <th>total_bhlen</th>\n",
       "      <th>fPktsPerSecond</th>\n",
       "      <th>bPktsPerSecond</th>\n",
       "      <th>flowPktsPerSecond</th>\n",
       "      <th>flowBytesPerSecond</th>\n",
       "      <th>mean_flowpktl</th>\n",
       "      <th>std_flowpktl</th>\n",
       "      <th>mean_flowipt</th>\n",
       "      <th>std_flowipt</th>\n",
       "      <th>flow_fin</th>\n",
       "      <th>flow_syn</th>\n",
       "      <th>flow_rst</th>\n",
       "      <th>flow_ack</th>\n",
       "      <th>flow_urg</th>\n",
       "      <th>flow_cwr</th>\n",
       "      <th>flow_ece</th>\n",
       "      <th>downUpRatio</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCP</td>\n",
       "      <td>49425</td>\n",
       "      <td>80</td>\n",
       "      <td>5.330176</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>2995</td>\n",
       "      <td>34275</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>516</td>\n",
       "      <td>1434</td>\n",
       "      <td>119.800003</td>\n",
       "      <td>1142.500000</td>\n",
       "      <td>148.696564</td>\n",
       "      <td>542.507890</td>\n",
       "      <td>5.330171</td>\n",
       "      <td>5.309903</td>\n",
       "      <td>0.000865</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>4.783427</td>\n",
       "      <td>4.860974</td>\n",
       "      <td>0.222090</td>\n",
       "      <td>0.183100</td>\n",
       "      <td>0.972401</td>\n",
       "      <td>0.900639</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>960</td>\n",
       "      <td>4.690277</td>\n",
       "      <td>5.628332</td>\n",
       "      <td>10.318609</td>\n",
       "      <td>6992.264648</td>\n",
       "      <td>677.636364</td>\n",
       "      <td>657.270813</td>\n",
       "      <td>0.186642</td>\n",
       "      <td>0.905723</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.444074</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCP</td>\n",
       "      <td>49420</td>\n",
       "      <td>80</td>\n",
       "      <td>3.373492</td>\n",
       "      <td>98</td>\n",
       "      <td>198</td>\n",
       "      <td>7373</td>\n",
       "      <td>275691</td>\n",
       "      <td>60</td>\n",
       "      <td>66</td>\n",
       "      <td>526</td>\n",
       "      <td>1434</td>\n",
       "      <td>75.234695</td>\n",
       "      <td>1392.378784</td>\n",
       "      <td>64.750085</td>\n",
       "      <td>219.551855</td>\n",
       "      <td>3.373492</td>\n",
       "      <td>3.260409</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>2.707926</td>\n",
       "      <td>2.765924</td>\n",
       "      <td>0.034778</td>\n",
       "      <td>0.016550</td>\n",
       "      <td>0.274669</td>\n",
       "      <td>0.197082</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3124</td>\n",
       "      <td>6336</td>\n",
       "      <td>29.050016</td>\n",
       "      <td>58.692890</td>\n",
       "      <td>87.742905</td>\n",
       "      <td>83908.304688</td>\n",
       "      <td>956.297297</td>\n",
       "      <td>647.368469</td>\n",
       "      <td>0.011516</td>\n",
       "      <td>0.157800</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>295</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.391972</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCP</td>\n",
       "      <td>49424</td>\n",
       "      <td>80</td>\n",
       "      <td>5.314620</td>\n",
       "      <td>22</td>\n",
       "      <td>29</td>\n",
       "      <td>3764</td>\n",
       "      <td>32911</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>537</td>\n",
       "      <td>1434</td>\n",
       "      <td>171.090912</td>\n",
       "      <td>1134.862061</td>\n",
       "      <td>198.355357</td>\n",
       "      <td>546.003387</td>\n",
       "      <td>5.314620</td>\n",
       "      <td>5.314599</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>4.793556</td>\n",
       "      <td>4.876292</td>\n",
       "      <td>0.253077</td>\n",
       "      <td>0.189807</td>\n",
       "      <td>1.041010</td>\n",
       "      <td>0.919354</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>704</td>\n",
       "      <td>928</td>\n",
       "      <td>4.139524</td>\n",
       "      <td>5.456646</td>\n",
       "      <td>9.596170</td>\n",
       "      <td>6900.775391</td>\n",
       "      <td>719.117647</td>\n",
       "      <td>644.878052</td>\n",
       "      <td>0.204388</td>\n",
       "      <td>0.941021</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.743624</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCP</td>\n",
       "      <td>62676</td>\n",
       "      <td>80</td>\n",
       "      <td>10.007152</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>2147</td>\n",
       "      <td>38518</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>563</td>\n",
       "      <td>1434</td>\n",
       "      <td>85.879997</td>\n",
       "      <td>1283.933350</td>\n",
       "      <td>99.399997</td>\n",
       "      <td>419.238876</td>\n",
       "      <td>10.007138</td>\n",
       "      <td>9.997345</td>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>5.004730</td>\n",
       "      <td>4.980878</td>\n",
       "      <td>0.416964</td>\n",
       "      <td>0.344736</td>\n",
       "      <td>1.379174</td>\n",
       "      <td>1.274558</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>960</td>\n",
       "      <td>2.498213</td>\n",
       "      <td>2.997856</td>\n",
       "      <td>5.496069</td>\n",
       "      <td>4063.593750</td>\n",
       "      <td>739.363636</td>\n",
       "      <td>679.145874</td>\n",
       "      <td>0.274507</td>\n",
       "      <td>1.123926</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.940382</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TCP</td>\n",
       "      <td>49421</td>\n",
       "      <td>80</td>\n",
       "      <td>5.309026</td>\n",
       "      <td>25</td>\n",
       "      <td>37</td>\n",
       "      <td>2116</td>\n",
       "      <td>48472</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>532</td>\n",
       "      <td>1434</td>\n",
       "      <td>84.639999</td>\n",
       "      <td>1310.054077</td>\n",
       "      <td>93.199996</td>\n",
       "      <td>382.904824</td>\n",
       "      <td>5.309026</td>\n",
       "      <td>5.309011</td>\n",
       "      <td>0.000883</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>4.750392</td>\n",
       "      <td>4.669868</td>\n",
       "      <td>0.221209</td>\n",
       "      <td>0.147473</td>\n",
       "      <td>0.965569</td>\n",
       "      <td>0.776987</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>800</td>\n",
       "      <td>1184</td>\n",
       "      <td>4.708962</td>\n",
       "      <td>6.969263</td>\n",
       "      <td>11.678225</td>\n",
       "      <td>9528.677734</td>\n",
       "      <td>815.935484</td>\n",
       "      <td>676.177124</td>\n",
       "      <td>0.165709</td>\n",
       "      <td>0.840417</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.907372</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556471</th>\n",
       "      <td>UDP</td>\n",
       "      <td>43580</td>\n",
       "      <td>53</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556472</th>\n",
       "      <td>UDP</td>\n",
       "      <td>43618</td>\n",
       "      <td>53</td>\n",
       "      <td>0.184316</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>137</td>\n",
       "      <td>78</td>\n",
       "      <td>137</td>\n",
       "      <td>78</td>\n",
       "      <td>137</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>103</td>\n",
       "      <td>5.425460</td>\n",
       "      <td>5.425460</td>\n",
       "      <td>10.850921</td>\n",
       "      <td>1166.473999</td>\n",
       "      <td>107.500000</td>\n",
       "      <td>41.719299</td>\n",
       "      <td>0.184316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.756410</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556473</th>\n",
       "      <td>UDP</td>\n",
       "      <td>43583</td>\n",
       "      <td>53</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556475</th>\n",
       "      <td>UDP</td>\n",
       "      <td>43587</td>\n",
       "      <td>53</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556476</th>\n",
       "      <td>UDP</td>\n",
       "      <td>43618</td>\n",
       "      <td>53</td>\n",
       "      <td>0.164233</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>6.088912</td>\n",
       "      <td>6.088912</td>\n",
       "      <td>12.177823</td>\n",
       "      <td>1010.759277</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.164233</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>553430 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       proto  srcPrt  dstPrt  flowduration  total_fpackets  total_bpackets  \\\n",
       "0        TCP   49425      80      5.330176              25              30   \n",
       "1        TCP   49420      80      3.373492              98             198   \n",
       "2        TCP   49424      80      5.314620              22              29   \n",
       "3        TCP   62676      80     10.007152              25              30   \n",
       "4        TCP   49421      80      5.309026              25              37   \n",
       "...      ...     ...     ...           ...             ...             ...   \n",
       "556471   UDP   43580      53      0.000000               1               0   \n",
       "556472   UDP   43618      53      0.184316               1               1   \n",
       "556473   UDP   43583      53      0.000000               1               0   \n",
       "556475   UDP   43587      53      0.000000               1               0   \n",
       "556476   UDP   43618      53      0.164233               1               1   \n",
       "\n",
       "        total_fpktl  total_bpktl  min_fpktl  min_bpktl  max_fpktl  max_bpktl  \\\n",
       "0              2995        34275         66         66        516       1434   \n",
       "1              7373       275691         60         66        526       1434   \n",
       "2              3764        32911         66         66        537       1434   \n",
       "3              2147        38518         66         66        563       1434   \n",
       "4              2116        48472         66         66        532       1434   \n",
       "...             ...          ...        ...        ...        ...        ...   \n",
       "556471           73            0         73          0         73          0   \n",
       "556472           78          137         78        137         78        137   \n",
       "556473           72            0         72          0         72          0   \n",
       "556475           72            0         72          0         72          0   \n",
       "556476           83           83         83         83         83         83   \n",
       "\n",
       "        mean_fpktl   mean_bpktl   std_fpktl   std_bpktl  total_fipt  \\\n",
       "0       119.800003  1142.500000  148.696564  542.507890    5.330171   \n",
       "1        75.234695  1392.378784   64.750085  219.551855    3.373492   \n",
       "2       171.090912  1134.862061  198.355357  546.003387    5.314620   \n",
       "3        85.879997  1283.933350   99.399997  419.238876   10.007138   \n",
       "4        84.639999  1310.054077   93.199996  382.904824    5.309026   \n",
       "...            ...          ...         ...         ...         ...   \n",
       "556471   73.000000     0.000000    0.000000    0.000000    0.000000   \n",
       "556472   78.000000   137.000000    0.000000    0.000000    0.000000   \n",
       "556473   72.000000     0.000000    0.000000    0.000000    0.000000   \n",
       "556475   72.000000     0.000000    0.000000    0.000000    0.000000   \n",
       "556476   83.000000    83.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "        total_bipt  min_fipt  min_bipt  max_fipt  max_bipt  mean_fipt  \\\n",
       "0         5.309903  0.000865  0.000007  4.783427  4.860974   0.222090   \n",
       "1         3.260409  0.000645  0.000007  2.707926  2.765924   0.034778   \n",
       "2         5.314599  0.000986  0.000008  4.793556  4.876292   0.253077   \n",
       "3         9.997345  0.001918  0.000006  5.004730  4.980878   0.416964   \n",
       "4         5.309011  0.000883  0.000006  4.750392  4.669868   0.221209   \n",
       "...            ...       ...       ...       ...       ...        ...   \n",
       "556471    0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
       "556472    0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
       "556473    0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
       "556475    0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
       "556476    0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
       "\n",
       "        mean_bipt  std_fipt  std_bipt  fpsh_cnt  bpsh_cnt  furg_cnt  burg_cnt  \\\n",
       "0        0.183100  0.972401  0.900639         3        10         0         0   \n",
       "1        0.016550  0.274669  0.197082         2        66         0         0   \n",
       "2        0.189807  1.041010  0.919354         5         8         0         0   \n",
       "3        0.344736  1.379174  1.274558         1        13         0         0   \n",
       "4        0.147473  0.965569  0.776987         1        13         0         0   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "556471   0.000000  0.000000  0.000000         0         0         0         0   \n",
       "556472   0.000000  0.000000  0.000000         0         0         0         0   \n",
       "556473   0.000000  0.000000  0.000000         0         0         0         0   \n",
       "556475   0.000000  0.000000  0.000000         0         0         0         0   \n",
       "556476   0.000000  0.000000  0.000000         0         0         0         0   \n",
       "\n",
       "        total_fhlen  total_bhlen  fPktsPerSecond  bPktsPerSecond  \\\n",
       "0               800          960        4.690277        5.628332   \n",
       "1              3124         6336       29.050016       58.692890   \n",
       "2               704          928        4.139524        5.456646   \n",
       "3               800          960        2.498213        2.997856   \n",
       "4               800         1184        4.708962        6.969263   \n",
       "...             ...          ...             ...             ...   \n",
       "556471           39            0        0.000000        0.000000   \n",
       "556472           44          103        5.425460        5.425460   \n",
       "556473           38            0        0.000000        0.000000   \n",
       "556475           38            0        0.000000        0.000000   \n",
       "556476           49           49        6.088912        6.088912   \n",
       "\n",
       "        flowPktsPerSecond  flowBytesPerSecond  mean_flowpktl  std_flowpktl  \\\n",
       "0               10.318609         6992.264648     677.636364    657.270813   \n",
       "1               87.742905        83908.304688     956.297297    647.368469   \n",
       "2                9.596170         6900.775391     719.117647    644.878052   \n",
       "3                5.496069         4063.593750     739.363636    679.145874   \n",
       "4               11.678225         9528.677734     815.935484    676.177124   \n",
       "...                   ...                 ...            ...           ...   \n",
       "556471           0.000000            0.000000      73.000000      0.000000   \n",
       "556472          10.850921         1166.473999     107.500000     41.719299   \n",
       "556473           0.000000            0.000000      72.000000      0.000000   \n",
       "556475           0.000000            0.000000      72.000000      0.000000   \n",
       "556476          12.177823         1010.759277      83.000000      0.000000   \n",
       "\n",
       "        mean_flowipt  std_flowipt  flow_fin  flow_syn  flow_rst  flow_ack  \\\n",
       "0           0.186642     0.905723         2         0         0        55   \n",
       "1           0.011516     0.157800         2         0         1       295   \n",
       "2           0.204388     0.941021         2         0         0        51   \n",
       "3           0.274507     1.123926         2         0         0        55   \n",
       "4           0.165709     0.840417         2         0         0        62   \n",
       "...              ...          ...       ...       ...       ...       ...   \n",
       "556471      0.000000     0.000000         0         0         0         0   \n",
       "556472      0.184316     0.000000         0         0         0         0   \n",
       "556473      0.000000     0.000000         0         0         0         0   \n",
       "556475      0.000000     0.000000         0         0         0         0   \n",
       "556476      0.164233     0.000000         0         0         0         0   \n",
       "\n",
       "        flow_urg  flow_cwr  flow_ece  downUpRatio  label  \n",
       "0              0         0         0    11.444074      0  \n",
       "1              0         0         0    37.391972      0  \n",
       "2              0         0         0     8.743624      0  \n",
       "3              0         0         0    17.940382      0  \n",
       "4              0         0         0    22.907372      0  \n",
       "...          ...       ...       ...          ...    ...  \n",
       "556471         0         0         0     0.000000      0  \n",
       "556472         0         0         0     1.756410      0  \n",
       "556473         0         0         0     0.000000      0  \n",
       "556475         0         0         0     0.000000      0  \n",
       "556476         0         0         0     1.000000      0  \n",
       "\n",
       "[553430 rows x 49 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Class 0 : 553173 of 553430 (100.0%)\n",
      "> Class 1 : 257 of 553430 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "#check % class distribution \n",
    "y=df['label'].values #convert to nparray\n",
    "\n",
    "classes=np.unique(y)\n",
    "total=len(y)\n",
    "\n",
    "for c in classes:\n",
    "    n_examples=len(y[y==c])\n",
    "    percent = n_examples/total*100\n",
    "    print('> Class %d : %d of %d (%.1f%%)' % (c, n_examples,total,percent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(df.drop(columns=['label']), df['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((442744, 48), (110686, 48))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Original dataset dimensions\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding of categorical variables\n",
    "[Target encoding](https://contrib.scikit-learn.org/category_encoders/targetencoder.html) for categorical features will be used to encode three nominal categorical variables: protocol, source and destination ports. This method is supervised and requires training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load library for target encoder \n",
    "from category_encoders import TargetEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "proto                  object\n",
       "srcPrt                  int64\n",
       "dstPrt                  int64\n",
       "flowduration          float64\n",
       "total_fpackets          int64\n",
       "total_bpackets          int64\n",
       "total_fpktl             int64\n",
       "total_bpktl             int64\n",
       "min_fpktl               int64\n",
       "min_bpktl               int64\n",
       "max_fpktl               int64\n",
       "max_bpktl               int64\n",
       "mean_fpktl            float64\n",
       "mean_bpktl            float64\n",
       "std_fpktl             float64\n",
       "std_bpktl             float64\n",
       "total_fipt            float64\n",
       "total_bipt            float64\n",
       "min_fipt              float64\n",
       "min_bipt              float64\n",
       "max_fipt              float64\n",
       "max_bipt              float64\n",
       "mean_fipt             float64\n",
       "mean_bipt             float64\n",
       "std_fipt              float64\n",
       "std_bipt              float64\n",
       "fpsh_cnt                int64\n",
       "bpsh_cnt                int64\n",
       "furg_cnt                int64\n",
       "burg_cnt                int64\n",
       "total_fhlen             int64\n",
       "total_bhlen             int64\n",
       "fPktsPerSecond        float64\n",
       "bPktsPerSecond        float64\n",
       "flowPktsPerSecond     float64\n",
       "flowBytesPerSecond    float64\n",
       "mean_flowpktl         float64\n",
       "std_flowpktl          float64\n",
       "mean_flowipt          float64\n",
       "std_flowipt           float64\n",
       "flow_fin                int64\n",
       "flow_syn                int64\n",
       "flow_rst                int64\n",
       "flow_ack                int64\n",
       "flow_urg                int64\n",
       "flow_cwr                int64\n",
       "flow_ece                int64\n",
       "downUpRatio           float64\n",
       "label                   int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check data types for each feature\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the three categorical variables to be coded\n",
    "enc = TargetEncoder(cols=['proto','srcPrt','dstPrt'])\n",
    "# fit on the trainning dataset\n",
    "enc.fit_transform(X_train, y_train)\n",
    "# Coding categorical variables of the trainning dataset\n",
    "training_numeric_dataset=enc.transform(X_train)\n",
    "# Coding categorical variables of the test dataset\n",
    "testing_numeric_dataset = enc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proto</th>\n",
       "      <th>srcPrt</th>\n",
       "      <th>dstPrt</th>\n",
       "      <th>flowduration</th>\n",
       "      <th>total_fpackets</th>\n",
       "      <th>total_bpackets</th>\n",
       "      <th>total_fpktl</th>\n",
       "      <th>total_bpktl</th>\n",
       "      <th>min_fpktl</th>\n",
       "      <th>min_bpktl</th>\n",
       "      <th>max_fpktl</th>\n",
       "      <th>max_bpktl</th>\n",
       "      <th>mean_fpktl</th>\n",
       "      <th>mean_bpktl</th>\n",
       "      <th>std_fpktl</th>\n",
       "      <th>std_bpktl</th>\n",
       "      <th>total_fipt</th>\n",
       "      <th>total_bipt</th>\n",
       "      <th>min_fipt</th>\n",
       "      <th>min_bipt</th>\n",
       "      <th>max_fipt</th>\n",
       "      <th>max_bipt</th>\n",
       "      <th>mean_fipt</th>\n",
       "      <th>mean_bipt</th>\n",
       "      <th>std_fipt</th>\n",
       "      <th>std_bipt</th>\n",
       "      <th>fpsh_cnt</th>\n",
       "      <th>bpsh_cnt</th>\n",
       "      <th>furg_cnt</th>\n",
       "      <th>burg_cnt</th>\n",
       "      <th>total_fhlen</th>\n",
       "      <th>total_bhlen</th>\n",
       "      <th>fPktsPerSecond</th>\n",
       "      <th>bPktsPerSecond</th>\n",
       "      <th>flowPktsPerSecond</th>\n",
       "      <th>flowBytesPerSecond</th>\n",
       "      <th>mean_flowpktl</th>\n",
       "      <th>std_flowpktl</th>\n",
       "      <th>mean_flowipt</th>\n",
       "      <th>std_flowipt</th>\n",
       "      <th>flow_fin</th>\n",
       "      <th>flow_syn</th>\n",
       "      <th>flow_rst</th>\n",
       "      <th>flow_ack</th>\n",
       "      <th>flow_urg</th>\n",
       "      <th>flow_cwr</th>\n",
       "      <th>flow_ece</th>\n",
       "      <th>downUpRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>360095</th>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>5.565753</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>224</td>\n",
       "      <td>1213</td>\n",
       "      <td>72</td>\n",
       "      <td>147</td>\n",
       "      <td>76</td>\n",
       "      <td>533</td>\n",
       "      <td>74.666664</td>\n",
       "      <td>404.333344</td>\n",
       "      <td>2.309401</td>\n",
       "      <td>222.857210</td>\n",
       "      <td>5.467604</td>\n",
       "      <td>5.465035</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>5.467538</td>\n",
       "      <td>5.464669</td>\n",
       "      <td>2.733802</td>\n",
       "      <td>2.732518</td>\n",
       "      <td>3.866086</td>\n",
       "      <td>3.863846</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>1111</td>\n",
       "      <td>0.539011</td>\n",
       "      <td>0.539011</td>\n",
       "      <td>1.078021</td>\n",
       "      <td>2.581861e+02</td>\n",
       "      <td>239.500000</td>\n",
       "      <td>229.068329</td>\n",
       "      <td>1.133354</td>\n",
       "      <td>2.423390</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.415179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519307</th>\n",
       "      <td>0.00009</td>\n",
       "      <td>1.388756e-10</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.346718</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>2.884190</td>\n",
       "      <td>2.884190</td>\n",
       "      <td>5.768379</td>\n",
       "      <td>4.268601e+02</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.346718</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267399</th>\n",
       "      <td>0.00009</td>\n",
       "      <td>1.122539e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.353651</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>2.827648</td>\n",
       "      <td>2.827648</td>\n",
       "      <td>5.655296</td>\n",
       "      <td>3.789048e+02</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.353651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278703</th>\n",
       "      <td>0.00009</td>\n",
       "      <td>4.136054e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.121386</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>458</td>\n",
       "      <td>87</td>\n",
       "      <td>458</td>\n",
       "      <td>87</td>\n",
       "      <td>458</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>458.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>424</td>\n",
       "      <td>8.238179</td>\n",
       "      <td>8.238179</td>\n",
       "      <td>16.476358</td>\n",
       "      <td>4.489808e+03</td>\n",
       "      <td>272.500000</td>\n",
       "      <td>262.336609</td>\n",
       "      <td>0.121386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.264368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165020</th>\n",
       "      <td>0.00113</td>\n",
       "      <td>2.789375e-09</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>16.283991</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>1298</td>\n",
       "      <td>6100</td>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>436</td>\n",
       "      <td>1434</td>\n",
       "      <td>144.222229</td>\n",
       "      <td>610.000000</td>\n",
       "      <td>165.434107</td>\n",
       "      <td>640.384780</td>\n",
       "      <td>16.283980</td>\n",
       "      <td>16.283965</td>\n",
       "      <td>0.205139</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>7.884252</td>\n",
       "      <td>8.960174</td>\n",
       "      <td>2.035497</td>\n",
       "      <td>1.809329</td>\n",
       "      <td>2.918911</td>\n",
       "      <td>3.135475</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "      <td>212</td>\n",
       "      <td>0.552690</td>\n",
       "      <td>0.614100</td>\n",
       "      <td>1.166790</td>\n",
       "      <td>4.543112e+02</td>\n",
       "      <td>389.368421</td>\n",
       "      <td>523.738403</td>\n",
       "      <td>1.143414</td>\n",
       "      <td>2.270825</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.699538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110301</th>\n",
       "      <td>0.00113</td>\n",
       "      <td>1.155229e-16</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.101769</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>736</td>\n",
       "      <td>509</td>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>494</td>\n",
       "      <td>285</td>\n",
       "      <td>147.199997</td>\n",
       "      <td>101.800003</td>\n",
       "      <td>193.869023</td>\n",
       "      <td>102.470483</td>\n",
       "      <td>0.101763</td>\n",
       "      <td>0.101745</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.055367</td>\n",
       "      <td>0.053541</td>\n",
       "      <td>0.025441</td>\n",
       "      <td>0.025436</td>\n",
       "      <td>0.023072</td>\n",
       "      <td>0.027463</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>49.130890</td>\n",
       "      <td>49.130890</td>\n",
       "      <td>98.261780</td>\n",
       "      <td>1.223359e+04</td>\n",
       "      <td>124.500000</td>\n",
       "      <td>148.134506</td>\n",
       "      <td>0.011737</td>\n",
       "      <td>0.019236</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.691576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259756</th>\n",
       "      <td>0.00009</td>\n",
       "      <td>3.038467e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.209169</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>4.780820</td>\n",
       "      <td>4.780820</td>\n",
       "      <td>9.561640</td>\n",
       "      <td>6.884380e+02</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.209169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367242</th>\n",
       "      <td>0.00009</td>\n",
       "      <td>2.543596e-12</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.365718</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>0.732216</td>\n",
       "      <td>0.732216</td>\n",
       "      <td>1.464431</td>\n",
       "      <td>1.127612e+02</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.365718</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131978</th>\n",
       "      <td>0.00113</td>\n",
       "      <td>1.522446e-07</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>2.197188</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>971</td>\n",
       "      <td>6995</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>369</td>\n",
       "      <td>1434</td>\n",
       "      <td>97.099998</td>\n",
       "      <td>777.222229</td>\n",
       "      <td>95.568997</td>\n",
       "      <td>686.858385</td>\n",
       "      <td>2.197188</td>\n",
       "      <td>2.131603</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1.174286</td>\n",
       "      <td>1.109786</td>\n",
       "      <td>0.244132</td>\n",
       "      <td>0.266450</td>\n",
       "      <td>0.438293</td>\n",
       "      <td>0.457806</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>328</td>\n",
       "      <td>300</td>\n",
       "      <td>4.551272</td>\n",
       "      <td>4.096145</td>\n",
       "      <td>8.647417</td>\n",
       "      <td>3.625543e+03</td>\n",
       "      <td>419.263158</td>\n",
       "      <td>579.631104</td>\n",
       "      <td>0.183730</td>\n",
       "      <td>0.398321</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.203914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121998</th>\n",
       "      <td>0.00113</td>\n",
       "      <td>5.108950e-11</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>110376.421875</td>\n",
       "      <td>110376.421875</td>\n",
       "      <td>220752.843750</td>\n",
       "      <td>1.258291e+07</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>4.242640</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442744 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          proto        srcPrt    dstPrt  flowduration  total_fpackets  \\\n",
       "360095  0.00009  0.000000e+00  0.000003      5.565753               3   \n",
       "519307  0.00009  1.388756e-10  0.000003      0.346718               1   \n",
       "267399  0.00009  1.122539e-06  0.000003      0.353651               1   \n",
       "278703  0.00009  4.136054e-07  0.000003      0.121386               1   \n",
       "165020  0.00113  2.789375e-09  0.000134     16.283991               9   \n",
       "...         ...           ...       ...           ...             ...   \n",
       "110301  0.00113  1.155229e-16  0.000134      0.101769               5   \n",
       "259756  0.00009  3.038467e-06  0.000003      0.209169               1   \n",
       "367242  0.00009  2.543596e-12  0.000003      1.365718               1   \n",
       "131978  0.00113  1.522446e-07  0.000134      2.197188              10   \n",
       "121998  0.00113  5.108950e-11  0.000134      0.000009               1   \n",
       "\n",
       "        total_bpackets  total_fpktl  total_bpktl  min_fpktl  min_bpktl  \\\n",
       "360095               3          224         1213         72        147   \n",
       "519307               1           74           74         74         74   \n",
       "267399               1           67           67         67         67   \n",
       "278703               1           87          458         87        458   \n",
       "165020              10         1298         6100         60         54   \n",
       "...                ...          ...          ...        ...        ...   \n",
       "110301               5          736          509         60         54   \n",
       "259756               1           72           72         72         72   \n",
       "367242               1           77           77         77         77   \n",
       "131978               9          971         6995         66         66   \n",
       "121998               1           60           54         60         54   \n",
       "\n",
       "        max_fpktl  max_bpktl  mean_fpktl  mean_bpktl   std_fpktl   std_bpktl  \\\n",
       "360095         76        533   74.666664  404.333344    2.309401  222.857210   \n",
       "519307         74         74   74.000000   74.000000    0.000000    0.000000   \n",
       "267399         67         67   67.000000   67.000000    0.000000    0.000000   \n",
       "278703         87        458   87.000000  458.000000    0.000000    0.000000   \n",
       "165020        436       1434  144.222229  610.000000  165.434107  640.384780   \n",
       "...           ...        ...         ...         ...         ...         ...   \n",
       "110301        494        285  147.199997  101.800003  193.869023  102.470483   \n",
       "259756         72         72   72.000000   72.000000    0.000000    0.000000   \n",
       "367242         77         77   77.000000   77.000000    0.000000    0.000000   \n",
       "131978        369       1434   97.099998  777.222229   95.568997  686.858385   \n",
       "121998         60         54   60.000000   54.000000    0.000000    0.000000   \n",
       "\n",
       "        total_fipt  total_bipt  min_fipt  min_bipt  max_fipt  max_bipt  \\\n",
       "360095    5.467604    5.465035  0.000066  0.000366  5.467538  5.464669   \n",
       "519307    0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "267399    0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "278703    0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "165020   16.283980   16.283965  0.205139  0.000008  7.884252  8.960174   \n",
       "...            ...         ...       ...       ...       ...       ...   \n",
       "110301    0.101763    0.101745  0.002004  0.000064  0.055367  0.053541   \n",
       "259756    0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "367242    0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "131978    2.197188    2.131603  0.000365  0.000009  1.174286  1.109786   \n",
       "121998    0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "        mean_fipt  mean_bipt  std_fipt  std_bipt  fpsh_cnt  bpsh_cnt  \\\n",
       "360095   2.733802   2.732518  3.866086  3.863846         0         0   \n",
       "519307   0.000000   0.000000  0.000000  0.000000         0         0   \n",
       "267399   0.000000   0.000000  0.000000  0.000000         0         0   \n",
       "278703   0.000000   0.000000  0.000000  0.000000         0         0   \n",
       "165020   2.035497   1.809329  2.918911  3.135475         2         2   \n",
       "...           ...        ...       ...       ...       ...       ...   \n",
       "110301   0.025441   0.025436  0.023072  0.027463         1         1   \n",
       "259756   0.000000   0.000000  0.000000  0.000000         0         0   \n",
       "367242   0.000000   0.000000  0.000000  0.000000         0         0   \n",
       "131978   0.244132   0.266450  0.438293  0.457806         1         2   \n",
       "121998   0.000000   0.000000  0.000000  0.000000         0         0   \n",
       "\n",
       "        furg_cnt  burg_cnt  total_fhlen  total_bhlen  fPktsPerSecond  \\\n",
       "360095         0         0          122         1111        0.539011   \n",
       "519307         0         0           40           40        2.884190   \n",
       "267399         0         0           33           33        2.827648   \n",
       "278703         0         0           53          424        8.238179   \n",
       "165020         0         0          192          212        0.552690   \n",
       "...          ...       ...          ...          ...             ...   \n",
       "110301         0         0          108          108       49.130890   \n",
       "259756         0         0           38           38        4.780820   \n",
       "367242         0         0           43           43        0.732216   \n",
       "131978         0         0          328          300        4.551272   \n",
       "121998         0         0           20           20   110376.421875   \n",
       "\n",
       "        bPktsPerSecond  flowPktsPerSecond  flowBytesPerSecond  mean_flowpktl  \\\n",
       "360095        0.539011           1.078021        2.581861e+02     239.500000   \n",
       "519307        2.884190           5.768379        4.268601e+02      74.000000   \n",
       "267399        2.827648           5.655296        3.789048e+02      67.000000   \n",
       "278703        8.238179          16.476358        4.489808e+03     272.500000   \n",
       "165020        0.614100           1.166790        4.543112e+02     389.368421   \n",
       "...                ...                ...                 ...            ...   \n",
       "110301       49.130890          98.261780        1.223359e+04     124.500000   \n",
       "259756        4.780820           9.561640        6.884380e+02      72.000000   \n",
       "367242        0.732216           1.464431        1.127612e+02      77.000000   \n",
       "131978        4.096145           8.647417        3.625543e+03     419.263158   \n",
       "121998   110376.421875      220752.843750        1.258291e+07      57.000000   \n",
       "\n",
       "        std_flowpktl  mean_flowipt  std_flowipt  flow_fin  flow_syn  flow_rst  \\\n",
       "360095    229.068329      1.133354     2.423390         0         0         0   \n",
       "519307      0.000000      0.346718     0.000000         0         0         0   \n",
       "267399      0.000000      0.353651     0.000000         0         0         0   \n",
       "278703    262.336609      0.121386     0.000000         0         0         0   \n",
       "165020    523.738403      1.143414     2.270825         2         2         0   \n",
       "...              ...           ...          ...       ...       ...       ...   \n",
       "110301    148.134506      0.011737     0.019236         2         2         0   \n",
       "259756      0.000000      0.209169     0.000000         0         0         0   \n",
       "367242      0.000000      1.365718     0.000000         0         0         0   \n",
       "131978    579.631104      0.183730     0.398321         2         2         0   \n",
       "121998      4.242640      0.000009     0.000000         1         0         0   \n",
       "\n",
       "        flow_ack  flow_urg  flow_cwr  flow_ece  downUpRatio  \n",
       "360095         0         0         0         0     5.415179  \n",
       "519307         0         0         0         0     1.000000  \n",
       "267399         0         0         0         0     1.000000  \n",
       "278703         0         0         0         0     5.264368  \n",
       "165020        18         0         0         0     4.699538  \n",
       "...          ...       ...       ...       ...          ...  \n",
       "110301         9         0         0         0     0.691576  \n",
       "259756         0         0         0         0     1.000000  \n",
       "367242         0         0         0         0     1.000000  \n",
       "131978        18         0         0         0     7.203914  \n",
       "121998         2         0         0         0     0.900000  \n",
       "\n",
       "[442744 rows x 48 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show trainning dataset\n",
    "training_numeric_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proto</th>\n",
       "      <th>srcPrt</th>\n",
       "      <th>dstPrt</th>\n",
       "      <th>flowduration</th>\n",
       "      <th>total_fpackets</th>\n",
       "      <th>total_bpackets</th>\n",
       "      <th>total_fpktl</th>\n",
       "      <th>total_bpktl</th>\n",
       "      <th>min_fpktl</th>\n",
       "      <th>min_bpktl</th>\n",
       "      <th>max_fpktl</th>\n",
       "      <th>max_bpktl</th>\n",
       "      <th>mean_fpktl</th>\n",
       "      <th>mean_bpktl</th>\n",
       "      <th>std_fpktl</th>\n",
       "      <th>std_bpktl</th>\n",
       "      <th>total_fipt</th>\n",
       "      <th>total_bipt</th>\n",
       "      <th>min_fipt</th>\n",
       "      <th>min_bipt</th>\n",
       "      <th>max_fipt</th>\n",
       "      <th>max_bipt</th>\n",
       "      <th>mean_fipt</th>\n",
       "      <th>mean_bipt</th>\n",
       "      <th>std_fipt</th>\n",
       "      <th>std_bipt</th>\n",
       "      <th>fpsh_cnt</th>\n",
       "      <th>bpsh_cnt</th>\n",
       "      <th>furg_cnt</th>\n",
       "      <th>burg_cnt</th>\n",
       "      <th>total_fhlen</th>\n",
       "      <th>total_bhlen</th>\n",
       "      <th>fPktsPerSecond</th>\n",
       "      <th>bPktsPerSecond</th>\n",
       "      <th>flowPktsPerSecond</th>\n",
       "      <th>flowBytesPerSecond</th>\n",
       "      <th>mean_flowpktl</th>\n",
       "      <th>std_flowpktl</th>\n",
       "      <th>mean_flowipt</th>\n",
       "      <th>std_flowipt</th>\n",
       "      <th>flow_fin</th>\n",
       "      <th>flow_syn</th>\n",
       "      <th>flow_rst</th>\n",
       "      <th>flow_ack</th>\n",
       "      <th>flow_urg</th>\n",
       "      <th>flow_cwr</th>\n",
       "      <th>flow_ece</th>\n",
       "      <th>downUpRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152931</th>\n",
       "      <td>0.00113</td>\n",
       "      <td>1.388756e-10</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>7.632909</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>3617</td>\n",
       "      <td>12915</td>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>492</td>\n",
       "      <td>1434</td>\n",
       "      <td>200.944443</td>\n",
       "      <td>645.750000</td>\n",
       "      <td>205.071423</td>\n",
       "      <td>549.995012</td>\n",
       "      <td>7.632909</td>\n",
       "      <td>7.632890</td>\n",
       "      <td>0.003804</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>4.873890</td>\n",
       "      <td>5.019010</td>\n",
       "      <td>0.448995</td>\n",
       "      <td>0.401731</td>\n",
       "      <td>1.179573</td>\n",
       "      <td>1.167867</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>368</td>\n",
       "      <td>408</td>\n",
       "      <td>2.358210</td>\n",
       "      <td>2.620233</td>\n",
       "      <td>4.978443</td>\n",
       "      <td>2.165885e+03</td>\n",
       "      <td>435.052632</td>\n",
       "      <td>474.675018</td>\n",
       "      <td>0.369113</td>\n",
       "      <td>1.118798</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.570639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194329</th>\n",
       "      <td>0.00009</td>\n",
       "      <td>1.522446e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>2577.937256</td>\n",
       "      <td>2577.937256</td>\n",
       "      <td>5155.874512</td>\n",
       "      <td>4.124700e+05</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15357</th>\n",
       "      <td>0.00113</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>8.865616</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>1286</td>\n",
       "      <td>6457</td>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>436</td>\n",
       "      <td>1434</td>\n",
       "      <td>142.888885</td>\n",
       "      <td>645.700012</td>\n",
       "      <td>162.816189</td>\n",
       "      <td>670.975088</td>\n",
       "      <td>8.865598</td>\n",
       "      <td>8.865604</td>\n",
       "      <td>0.015440</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>4.266813</td>\n",
       "      <td>5.013681</td>\n",
       "      <td>1.108200</td>\n",
       "      <td>0.985067</td>\n",
       "      <td>1.603005</td>\n",
       "      <td>1.803837</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "      <td>212</td>\n",
       "      <td>1.015158</td>\n",
       "      <td>1.127953</td>\n",
       "      <td>2.143111</td>\n",
       "      <td>8.733742e+02</td>\n",
       "      <td>407.526316</td>\n",
       "      <td>550.832947</td>\n",
       "      <td>0.726835</td>\n",
       "      <td>1.455952</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.020995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523465</th>\n",
       "      <td>0.00009</td>\n",
       "      <td>2.061004e-08</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>3622.024170</td>\n",
       "      <td>3622.024170</td>\n",
       "      <td>7244.048340</td>\n",
       "      <td>4.925953e+05</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292825</th>\n",
       "      <td>0.00009</td>\n",
       "      <td>1.522446e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.060473</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>16.536314</td>\n",
       "      <td>16.536314</td>\n",
       "      <td>33.072628</td>\n",
       "      <td>2.711956e+03</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060473</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255516</th>\n",
       "      <td>0.00009</td>\n",
       "      <td>3.038467e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>24.786140</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>0.040345</td>\n",
       "      <td>0.040345</td>\n",
       "      <td>0.080690</td>\n",
       "      <td>5.648318e+00</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.786140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247429</th>\n",
       "      <td>0.00009</td>\n",
       "      <td>7.582228e-09</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.209571</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>4.771650</td>\n",
       "      <td>4.771650</td>\n",
       "      <td>9.543300</td>\n",
       "      <td>7.252908e+02</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.209571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366817</th>\n",
       "      <td>0.00009</td>\n",
       "      <td>1.026158e-09</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>137</td>\n",
       "      <td>86</td>\n",
       "      <td>137</td>\n",
       "      <td>86</td>\n",
       "      <td>137</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>103</td>\n",
       "      <td>4650.004395</td>\n",
       "      <td>4650.004395</td>\n",
       "      <td>9300.008789</td>\n",
       "      <td>1.036951e+06</td>\n",
       "      <td>111.500000</td>\n",
       "      <td>36.062447</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.593023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237638</th>\n",
       "      <td>0.00009</td>\n",
       "      <td>4.136054e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.521785</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>1.916498</td>\n",
       "      <td>1.916498</td>\n",
       "      <td>3.832996</td>\n",
       "      <td>2.874747e+02</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.521785</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266457</th>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.068005</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>712</td>\n",
       "      <td>2290</td>\n",
       "      <td>89</td>\n",
       "      <td>173</td>\n",
       "      <td>89</td>\n",
       "      <td>332</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>286.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>70.095343</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>440</td>\n",
       "      <td>2018</td>\n",
       "      <td>117.638260</td>\n",
       "      <td>117.638260</td>\n",
       "      <td>235.276520</td>\n",
       "      <td>4.414376e+04</td>\n",
       "      <td>187.625000</td>\n",
       "      <td>112.553322</td>\n",
       "      <td>0.004534</td>\n",
       "      <td>0.017191</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.216292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110686 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          proto        srcPrt    dstPrt  flowduration  total_fpackets  \\\n",
       "152931  0.00113  1.388756e-10  0.000134      7.632909              18   \n",
       "194329  0.00009  1.522446e-07  0.000003      0.000388               1   \n",
       "15357   0.00113  0.000000e+00  0.000134      8.865616               9   \n",
       "523465  0.00009  2.061004e-08  0.000003      0.000276               1   \n",
       "292825  0.00009  1.522446e-07  0.000003      0.060473               1   \n",
       "...         ...           ...       ...           ...             ...   \n",
       "255516  0.00009  3.038467e-06  0.000003     24.786140               1   \n",
       "247429  0.00009  7.582228e-09  0.000003      0.209571               1   \n",
       "366817  0.00009  1.026158e-09  0.000003      0.000215               1   \n",
       "237638  0.00009  4.136054e-07  0.000003      0.521785               1   \n",
       "266457  0.00009  0.000000e+00  0.000003      0.068005               8   \n",
       "\n",
       "        total_bpackets  total_fpktl  total_bpktl  min_fpktl  min_bpktl  \\\n",
       "152931              20         3617        12915         60         54   \n",
       "194329               1           80           80         80         80   \n",
       "15357               10         1286         6457         60         54   \n",
       "523465               1           68           68         68         68   \n",
       "292825               1           82           82         82         82   \n",
       "...                ...          ...          ...        ...        ...   \n",
       "255516               1           70           70         70         70   \n",
       "247429               1           76           76         76         76   \n",
       "366817               1           86          137         86        137   \n",
       "237638               1           75           75         75         75   \n",
       "266457               8          712         2290         89        173   \n",
       "\n",
       "        max_fpktl  max_bpktl  mean_fpktl  mean_bpktl   std_fpktl   std_bpktl  \\\n",
       "152931        492       1434  200.944443  645.750000  205.071423  549.995012   \n",
       "194329         80         80   80.000000   80.000000    0.000000    0.000000   \n",
       "15357         436       1434  142.888885  645.700012  162.816189  670.975088   \n",
       "523465         68         68   68.000000   68.000000    0.000000    0.000000   \n",
       "292825         82         82   82.000000   82.000000    0.000000    0.000000   \n",
       "...           ...        ...         ...         ...         ...         ...   \n",
       "255516         70         70   70.000000   70.000000    0.000000    0.000000   \n",
       "247429         76         76   76.000000   76.000000    0.000000    0.000000   \n",
       "366817         86        137   86.000000  137.000000    0.000000    0.000000   \n",
       "237638         75         75   75.000000   75.000000    0.000000    0.000000   \n",
       "266457         89        332   89.000000  286.250000    0.000000   70.095343   \n",
       "\n",
       "        total_fipt  total_bipt  min_fipt  min_bipt  max_fipt  max_bipt  \\\n",
       "152931    7.632909    7.632890  0.003804  0.000010  4.873890  5.019010   \n",
       "194329    0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "15357     8.865598    8.865604  0.015440  0.000005  4.266813  5.013681   \n",
       "523465    0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "292825    0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "...            ...         ...       ...       ...       ...       ...   \n",
       "255516    0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "247429    0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "366817    0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "237638    0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "266457    0.001144    0.000187  0.000075  0.000017  0.000242  0.000068   \n",
       "\n",
       "        mean_fipt  mean_bipt  std_fipt  std_bipt  fpsh_cnt  bpsh_cnt  \\\n",
       "152931   0.448995   0.401731  1.179573  1.167867         6        11   \n",
       "194329   0.000000   0.000000  0.000000  0.000000         0         0   \n",
       "15357    1.108200   0.985067  1.603005  1.803837         2         2   \n",
       "523465   0.000000   0.000000  0.000000  0.000000         0         0   \n",
       "292825   0.000000   0.000000  0.000000  0.000000         0         0   \n",
       "...           ...        ...       ...       ...       ...       ...   \n",
       "255516   0.000000   0.000000  0.000000  0.000000         0         0   \n",
       "247429   0.000000   0.000000  0.000000  0.000000         0         0   \n",
       "366817   0.000000   0.000000  0.000000  0.000000         0         0   \n",
       "237638   0.000000   0.000000  0.000000  0.000000         0         0   \n",
       "266457   0.000163   0.000027  0.000058  0.000018         0         0   \n",
       "\n",
       "        furg_cnt  burg_cnt  total_fhlen  total_bhlen  fPktsPerSecond  \\\n",
       "152931         0         0          368          408        2.358210   \n",
       "194329         0         0           46           46     2577.937256   \n",
       "15357          0         0          192          212        1.015158   \n",
       "523465         0         0           34           34     3622.024170   \n",
       "292825         0         0           48           48       16.536314   \n",
       "...          ...       ...          ...          ...             ...   \n",
       "255516         0         0           36           36        0.040345   \n",
       "247429         0         0           42           42        4.771650   \n",
       "366817         0         0           52          103     4650.004395   \n",
       "237638         0         0           41           41        1.916498   \n",
       "266457         0         0          440         2018      117.638260   \n",
       "\n",
       "        bPktsPerSecond  flowPktsPerSecond  flowBytesPerSecond  mean_flowpktl  \\\n",
       "152931        2.620233           4.978443        2.165885e+03     435.052632   \n",
       "194329     2577.937256        5155.874512        4.124700e+05      80.000000   \n",
       "15357         1.127953           2.143111        8.733742e+02     407.526316   \n",
       "523465     3622.024170        7244.048340        4.925953e+05      68.000000   \n",
       "292825       16.536314          33.072628        2.711956e+03      82.000000   \n",
       "...                ...                ...                 ...            ...   \n",
       "255516        0.040345           0.080690        5.648318e+00      70.000000   \n",
       "247429        4.771650           9.543300        7.252908e+02      76.000000   \n",
       "366817     4650.004395        9300.008789        1.036951e+06     111.500000   \n",
       "237638        1.916498           3.832996        2.874747e+02      75.000000   \n",
       "266457      117.638260         235.276520        4.414376e+04     187.625000   \n",
       "\n",
       "        std_flowpktl  mean_flowipt  std_flowipt  flow_fin  flow_syn  flow_rst  \\\n",
       "152931    474.675018      0.369113     1.118798         2         2         0   \n",
       "194329      0.000000      0.000388     0.000000         0         0         0   \n",
       "15357     550.832947      0.726835     1.455952         2         2         0   \n",
       "523465      0.000000      0.000276     0.000000         0         0         0   \n",
       "292825      0.000000      0.060473     0.000000         0         0         0   \n",
       "...              ...           ...          ...       ...       ...       ...   \n",
       "255516      0.000000     24.786140     0.000000         0         0         0   \n",
       "247429      0.000000      0.209571     0.000000         0         0         0   \n",
       "366817     36.062447      0.000215     0.000000         0         0         0   \n",
       "237638      0.000000      0.521785     0.000000         0         0         0   \n",
       "266457    112.553322      0.004534     0.017191         0         0         0   \n",
       "\n",
       "        flow_ack  flow_urg  flow_cwr  flow_ece  downUpRatio  \n",
       "152931        37         0         0         0     3.570639  \n",
       "194329         0         0         0         0     1.000000  \n",
       "15357         18         0         0         0     5.020995  \n",
       "523465         0         0         0         0     1.000000  \n",
       "292825         0         0         0         0     1.000000  \n",
       "...          ...       ...       ...       ...          ...  \n",
       "255516         0         0         0         0     1.000000  \n",
       "247429         0         0         0         0     1.000000  \n",
       "366817         0         0         0         0     1.593023  \n",
       "237638         0         0         0         0     1.000000  \n",
       "266457         0         0         0         0     3.216292  \n",
       "\n",
       "[110686 rows x 48 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show testing dataset\n",
    "testing_numeric_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardization and scaling of numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_cols = training_numeric_dataset.select_dtypes(include=['float64', 'int']).columns.to_list()\n",
    "preprocessor = ColumnTransformer([('scale', StandardScaler(), numeric_cols)], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit on the trainning dataset\n",
    "preprocessor.fit_transform(training_numeric_dataset)\n",
    "X_train_stand = preprocessor.transform(training_numeric_dataset)\n",
    "X_test_stand  = preprocessor.transform(testing_numeric_dataset)\n",
    "#The result returned by ColumnTransformer is a numpy array, so the column names are lost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-generate the dataset as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=list(training_numeric_dataset.columns.values.tolist())\n",
    "df_X_train_stand=pd.DataFrame(X_train_stand,columns=labels)\n",
    "df_X_test_stand=pd.DataFrame(X_test_stand,columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proto</th>\n",
       "      <th>srcPrt</th>\n",
       "      <th>dstPrt</th>\n",
       "      <th>flowduration</th>\n",
       "      <th>total_fpackets</th>\n",
       "      <th>total_bpackets</th>\n",
       "      <th>total_fpktl</th>\n",
       "      <th>total_bpktl</th>\n",
       "      <th>min_fpktl</th>\n",
       "      <th>min_bpktl</th>\n",
       "      <th>max_fpktl</th>\n",
       "      <th>max_bpktl</th>\n",
       "      <th>mean_fpktl</th>\n",
       "      <th>mean_bpktl</th>\n",
       "      <th>std_fpktl</th>\n",
       "      <th>std_bpktl</th>\n",
       "      <th>total_fipt</th>\n",
       "      <th>total_bipt</th>\n",
       "      <th>min_fipt</th>\n",
       "      <th>min_bipt</th>\n",
       "      <th>max_fipt</th>\n",
       "      <th>max_bipt</th>\n",
       "      <th>mean_fipt</th>\n",
       "      <th>mean_bipt</th>\n",
       "      <th>std_fipt</th>\n",
       "      <th>std_bipt</th>\n",
       "      <th>fpsh_cnt</th>\n",
       "      <th>bpsh_cnt</th>\n",
       "      <th>furg_cnt</th>\n",
       "      <th>burg_cnt</th>\n",
       "      <th>total_fhlen</th>\n",
       "      <th>total_bhlen</th>\n",
       "      <th>fPktsPerSecond</th>\n",
       "      <th>bPktsPerSecond</th>\n",
       "      <th>flowPktsPerSecond</th>\n",
       "      <th>flowBytesPerSecond</th>\n",
       "      <th>mean_flowpktl</th>\n",
       "      <th>std_flowpktl</th>\n",
       "      <th>mean_flowipt</th>\n",
       "      <th>std_flowipt</th>\n",
       "      <th>flow_fin</th>\n",
       "      <th>flow_syn</th>\n",
       "      <th>flow_rst</th>\n",
       "      <th>flow_ack</th>\n",
       "      <th>flow_urg</th>\n",
       "      <th>flow_cwr</th>\n",
       "      <th>flow_ece</th>\n",
       "      <th>downUpRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.733612</td>\n",
       "      <td>-0.052933</td>\n",
       "      <td>-0.024120</td>\n",
       "      <td>-0.079243</td>\n",
       "      <td>-0.048035</td>\n",
       "      <td>-0.041497</td>\n",
       "      <td>-0.055559</td>\n",
       "      <td>-0.036163</td>\n",
       "      <td>-0.093317</td>\n",
       "      <td>0.738297</td>\n",
       "      <td>-0.574907</td>\n",
       "      <td>0.195184</td>\n",
       "      <td>-0.493421</td>\n",
       "      <td>0.340353</td>\n",
       "      <td>-0.529730</td>\n",
       "      <td>0.373654</td>\n",
       "      <td>-0.055130</td>\n",
       "      <td>-0.032651</td>\n",
       "      <td>-0.192824</td>\n",
       "      <td>-0.074806</td>\n",
       "      <td>0.012855</td>\n",
       "      <td>0.100829</td>\n",
       "      <td>0.129570</td>\n",
       "      <td>0.305365</td>\n",
       "      <td>0.480648</td>\n",
       "      <td>0.470165</td>\n",
       "      <td>-0.021948</td>\n",
       "      <td>-0.032431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.040528</td>\n",
       "      <td>0.176356</td>\n",
       "      <td>-0.170286</td>\n",
       "      <td>-0.177908</td>\n",
       "      <td>-0.177969</td>\n",
       "      <td>-0.163608</td>\n",
       "      <td>0.167291</td>\n",
       "      <td>0.283909</td>\n",
       "      <td>-0.265448</td>\n",
       "      <td>0.181161</td>\n",
       "      <td>-0.639758</td>\n",
       "      <td>-0.693391</td>\n",
       "      <td>-0.188781</td>\n",
       "      <td>-0.052303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010372</td>\n",
       "      <td>-0.009624</td>\n",
       "      <td>0.295660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.733612</td>\n",
       "      <td>-0.052933</td>\n",
       "      <td>-0.024120</td>\n",
       "      <td>-0.139326</td>\n",
       "      <td>-0.065035</td>\n",
       "      <td>-0.051378</td>\n",
       "      <td>-0.066879</td>\n",
       "      <td>-0.040244</td>\n",
       "      <td>0.014901</td>\n",
       "      <td>-0.273656</td>\n",
       "      <td>-0.583239</td>\n",
       "      <td>-0.642877</td>\n",
       "      <td>-0.508179</td>\n",
       "      <td>-0.582405</td>\n",
       "      <td>-0.554938</td>\n",
       "      <td>-0.577831</td>\n",
       "      <td>-0.118903</td>\n",
       "      <td>-0.127790</td>\n",
       "      <td>-0.192837</td>\n",
       "      <td>-0.074908</td>\n",
       "      <td>-0.415211</td>\n",
       "      <td>-0.341399</td>\n",
       "      <td>-0.324482</td>\n",
       "      <td>-0.243767</td>\n",
       "      <td>-0.358496</td>\n",
       "      <td>-0.326396</td>\n",
       "      <td>-0.021948</td>\n",
       "      <td>-0.032431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.066131</td>\n",
       "      <td>-0.076984</td>\n",
       "      <td>-0.169990</td>\n",
       "      <td>-0.177584</td>\n",
       "      <td>-0.177652</td>\n",
       "      <td>-0.163491</td>\n",
       "      <td>-0.592999</td>\n",
       "      <td>-0.685160</td>\n",
       "      <td>-0.386753</td>\n",
       "      <td>-0.398125</td>\n",
       "      <td>-0.639758</td>\n",
       "      <td>-0.693391</td>\n",
       "      <td>-0.188781</td>\n",
       "      <td>-0.052303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010372</td>\n",
       "      <td>-0.009624</td>\n",
       "      <td>-0.409783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.733612</td>\n",
       "      <td>-0.052806</td>\n",
       "      <td>-0.024120</td>\n",
       "      <td>-0.139246</td>\n",
       "      <td>-0.065035</td>\n",
       "      <td>-0.051378</td>\n",
       "      <td>-0.067407</td>\n",
       "      <td>-0.040269</td>\n",
       "      <td>-0.363863</td>\n",
       "      <td>-0.370692</td>\n",
       "      <td>-0.612402</td>\n",
       "      <td>-0.655658</td>\n",
       "      <td>-0.663131</td>\n",
       "      <td>-0.601959</td>\n",
       "      <td>-0.554938</td>\n",
       "      <td>-0.577831</td>\n",
       "      <td>-0.118903</td>\n",
       "      <td>-0.127790</td>\n",
       "      <td>-0.192837</td>\n",
       "      <td>-0.074908</td>\n",
       "      <td>-0.415211</td>\n",
       "      <td>-0.341399</td>\n",
       "      <td>-0.324482</td>\n",
       "      <td>-0.243767</td>\n",
       "      <td>-0.358496</td>\n",
       "      <td>-0.326396</td>\n",
       "      <td>-0.021948</td>\n",
       "      <td>-0.032431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.068317</td>\n",
       "      <td>-0.078640</td>\n",
       "      <td>-0.169997</td>\n",
       "      <td>-0.177592</td>\n",
       "      <td>-0.177660</td>\n",
       "      <td>-0.163524</td>\n",
       "      <td>-0.625156</td>\n",
       "      <td>-0.685160</td>\n",
       "      <td>-0.385684</td>\n",
       "      <td>-0.398125</td>\n",
       "      <td>-0.639758</td>\n",
       "      <td>-0.693391</td>\n",
       "      <td>-0.188781</td>\n",
       "      <td>-0.052303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010372</td>\n",
       "      <td>-0.009624</td>\n",
       "      <td>-0.409783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.733612</td>\n",
       "      <td>-0.052886</td>\n",
       "      <td>-0.024120</td>\n",
       "      <td>-0.141920</td>\n",
       "      <td>-0.065035</td>\n",
       "      <td>-0.051378</td>\n",
       "      <td>-0.065898</td>\n",
       "      <td>-0.038868</td>\n",
       "      <td>0.718320</td>\n",
       "      <td>5.049495</td>\n",
       "      <td>-0.529081</td>\n",
       "      <td>0.058246</td>\n",
       "      <td>-0.220409</td>\n",
       "      <td>0.490266</td>\n",
       "      <td>-0.554938</td>\n",
       "      <td>-0.577831</td>\n",
       "      <td>-0.118903</td>\n",
       "      <td>-0.127790</td>\n",
       "      <td>-0.192837</td>\n",
       "      <td>-0.074908</td>\n",
       "      <td>-0.415211</td>\n",
       "      <td>-0.341399</td>\n",
       "      <td>-0.324482</td>\n",
       "      <td>-0.243767</td>\n",
       "      <td>-0.358496</td>\n",
       "      <td>-0.326396</td>\n",
       "      <td>-0.021948</td>\n",
       "      <td>-0.032431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.062072</td>\n",
       "      <td>0.013849</td>\n",
       "      <td>-0.169314</td>\n",
       "      <td>-0.176843</td>\n",
       "      <td>-0.176929</td>\n",
       "      <td>-0.160670</td>\n",
       "      <td>0.318890</td>\n",
       "      <td>0.424649</td>\n",
       "      <td>-0.421501</td>\n",
       "      <td>-0.398125</td>\n",
       "      <td>-0.639758</td>\n",
       "      <td>-0.693391</td>\n",
       "      <td>-0.188781</td>\n",
       "      <td>-0.052303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010372</td>\n",
       "      <td>-0.009624</td>\n",
       "      <td>0.271564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.363118</td>\n",
       "      <td>-0.052933</td>\n",
       "      <td>-0.016809</td>\n",
       "      <td>0.044147</td>\n",
       "      <td>0.002967</td>\n",
       "      <td>-0.006915</td>\n",
       "      <td>0.025488</td>\n",
       "      <td>-0.018653</td>\n",
       "      <td>-0.742627</td>\n",
       "      <td>-0.550903</td>\n",
       "      <td>0.924868</td>\n",
       "      <td>1.840267</td>\n",
       "      <td>1.046267</td>\n",
       "      <td>0.914865</td>\n",
       "      <td>1.250861</td>\n",
       "      <td>2.156282</td>\n",
       "      <td>0.071029</td>\n",
       "      <td>0.155692</td>\n",
       "      <td>-0.152990</td>\n",
       "      <td>-0.074906</td>\n",
       "      <td>0.202066</td>\n",
       "      <td>0.383703</td>\n",
       "      <td>0.013590</td>\n",
       "      <td>0.119839</td>\n",
       "      <td>0.275061</td>\n",
       "      <td>0.320006</td>\n",
       "      <td>0.016329</td>\n",
       "      <td>-0.013101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.018672</td>\n",
       "      <td>-0.036299</td>\n",
       "      <td>-0.170284</td>\n",
       "      <td>-0.177898</td>\n",
       "      <td>-0.177963</td>\n",
       "      <td>-0.163472</td>\n",
       "      <td>0.855772</td>\n",
       "      <td>1.530503</td>\n",
       "      <td>-0.263896</td>\n",
       "      <td>0.144692</td>\n",
       "      <td>1.444986</td>\n",
       "      <td>1.290624</td>\n",
       "      <td>-0.188781</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010372</td>\n",
       "      <td>-0.009624</td>\n",
       "      <td>0.181317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442739</th>\n",
       "      <td>1.363118</td>\n",
       "      <td>-0.052933</td>\n",
       "      <td>-0.016809</td>\n",
       "      <td>-0.142145</td>\n",
       "      <td>-0.031034</td>\n",
       "      <td>-0.031617</td>\n",
       "      <td>-0.016922</td>\n",
       "      <td>-0.038685</td>\n",
       "      <td>-0.742627</td>\n",
       "      <td>-0.550903</td>\n",
       "      <td>1.166498</td>\n",
       "      <td>-0.257624</td>\n",
       "      <td>1.112183</td>\n",
       "      <td>-0.504748</td>\n",
       "      <td>1.561243</td>\n",
       "      <td>-0.140335</td>\n",
       "      <td>-0.117716</td>\n",
       "      <td>-0.126019</td>\n",
       "      <td>-0.192447</td>\n",
       "      <td>-0.074890</td>\n",
       "      <td>-0.410876</td>\n",
       "      <td>-0.337066</td>\n",
       "      <td>-0.320257</td>\n",
       "      <td>-0.238655</td>\n",
       "      <td>-0.353488</td>\n",
       "      <td>-0.320734</td>\n",
       "      <td>-0.002810</td>\n",
       "      <td>-0.022766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.044899</td>\n",
       "      <td>-0.060899</td>\n",
       "      <td>-0.164156</td>\n",
       "      <td>-0.171183</td>\n",
       "      <td>-0.171406</td>\n",
       "      <td>-0.155293</td>\n",
       "      <td>-0.361007</td>\n",
       "      <td>-0.058480</td>\n",
       "      <td>-0.438410</td>\n",
       "      <td>-0.393527</td>\n",
       "      <td>1.444986</td>\n",
       "      <td>1.290624</td>\n",
       "      <td>-0.188781</td>\n",
       "      <td>-0.023926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010372</td>\n",
       "      <td>-0.009624</td>\n",
       "      <td>-0.459062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442740</th>\n",
       "      <td>-0.733612</td>\n",
       "      <td>-0.052587</td>\n",
       "      <td>-0.024120</td>\n",
       "      <td>-0.140909</td>\n",
       "      <td>-0.065035</td>\n",
       "      <td>-0.051378</td>\n",
       "      <td>-0.067030</td>\n",
       "      <td>-0.040251</td>\n",
       "      <td>-0.093317</td>\n",
       "      <td>-0.301380</td>\n",
       "      <td>-0.591571</td>\n",
       "      <td>-0.646528</td>\n",
       "      <td>-0.552451</td>\n",
       "      <td>-0.587992</td>\n",
       "      <td>-0.554938</td>\n",
       "      <td>-0.577831</td>\n",
       "      <td>-0.118903</td>\n",
       "      <td>-0.127790</td>\n",
       "      <td>-0.192837</td>\n",
       "      <td>-0.074908</td>\n",
       "      <td>-0.415211</td>\n",
       "      <td>-0.341399</td>\n",
       "      <td>-0.324482</td>\n",
       "      <td>-0.243767</td>\n",
       "      <td>-0.358496</td>\n",
       "      <td>-0.326396</td>\n",
       "      <td>-0.021948</td>\n",
       "      <td>-0.032431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.066756</td>\n",
       "      <td>-0.077458</td>\n",
       "      <td>-0.169751</td>\n",
       "      <td>-0.177321</td>\n",
       "      <td>-0.177396</td>\n",
       "      <td>-0.163309</td>\n",
       "      <td>-0.602187</td>\n",
       "      <td>-0.685160</td>\n",
       "      <td>-0.407964</td>\n",
       "      <td>-0.398125</td>\n",
       "      <td>-0.639758</td>\n",
       "      <td>-0.693391</td>\n",
       "      <td>-0.188781</td>\n",
       "      <td>-0.052303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010372</td>\n",
       "      <td>-0.009624</td>\n",
       "      <td>-0.409783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442741</th>\n",
       "      <td>-0.733612</td>\n",
       "      <td>-0.052933</td>\n",
       "      <td>-0.024120</td>\n",
       "      <td>-0.127595</td>\n",
       "      <td>-0.065035</td>\n",
       "      <td>-0.051378</td>\n",
       "      <td>-0.066652</td>\n",
       "      <td>-0.040233</td>\n",
       "      <td>0.177228</td>\n",
       "      <td>-0.232069</td>\n",
       "      <td>-0.570741</td>\n",
       "      <td>-0.637399</td>\n",
       "      <td>-0.441770</td>\n",
       "      <td>-0.574025</td>\n",
       "      <td>-0.554938</td>\n",
       "      <td>-0.577831</td>\n",
       "      <td>-0.118903</td>\n",
       "      <td>-0.127790</td>\n",
       "      <td>-0.192837</td>\n",
       "      <td>-0.074908</td>\n",
       "      <td>-0.415211</td>\n",
       "      <td>-0.341399</td>\n",
       "      <td>-0.324482</td>\n",
       "      <td>-0.243767</td>\n",
       "      <td>-0.358496</td>\n",
       "      <td>-0.326396</td>\n",
       "      <td>-0.021948</td>\n",
       "      <td>-0.032431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.065194</td>\n",
       "      <td>-0.076275</td>\n",
       "      <td>-0.170261</td>\n",
       "      <td>-0.177882</td>\n",
       "      <td>-0.177943</td>\n",
       "      <td>-0.163709</td>\n",
       "      <td>-0.579217</td>\n",
       "      <td>-0.685160</td>\n",
       "      <td>-0.229615</td>\n",
       "      <td>-0.398125</td>\n",
       "      <td>-0.639758</td>\n",
       "      <td>-0.693391</td>\n",
       "      <td>-0.188781</td>\n",
       "      <td>-0.052303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010372</td>\n",
       "      <td>-0.009624</td>\n",
       "      <td>-0.409783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442742</th>\n",
       "      <td>1.363118</td>\n",
       "      <td>-0.052916</td>\n",
       "      <td>-0.016809</td>\n",
       "      <td>-0.118023</td>\n",
       "      <td>0.011467</td>\n",
       "      <td>-0.011855</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>-0.015446</td>\n",
       "      <td>-0.417972</td>\n",
       "      <td>-0.384555</td>\n",
       "      <td>0.645743</td>\n",
       "      <td>1.840267</td>\n",
       "      <td>0.003165</td>\n",
       "      <td>1.381986</td>\n",
       "      <td>0.488247</td>\n",
       "      <td>2.354700</td>\n",
       "      <td>-0.093275</td>\n",
       "      <td>-0.090681</td>\n",
       "      <td>-0.192766</td>\n",
       "      <td>-0.074905</td>\n",
       "      <td>-0.323273</td>\n",
       "      <td>-0.251589</td>\n",
       "      <td>-0.283935</td>\n",
       "      <td>-0.190221</td>\n",
       "      <td>-0.263363</td>\n",
       "      <td>-0.232016</td>\n",
       "      <td>-0.002810</td>\n",
       "      <td>-0.013101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023792</td>\n",
       "      <td>-0.015483</td>\n",
       "      <td>-0.169779</td>\n",
       "      <td>-0.177416</td>\n",
       "      <td>-0.177458</td>\n",
       "      <td>-0.161270</td>\n",
       "      <td>0.993105</td>\n",
       "      <td>1.766956</td>\n",
       "      <td>-0.411887</td>\n",
       "      <td>-0.302911</td>\n",
       "      <td>1.444986</td>\n",
       "      <td>1.290624</td>\n",
       "      <td>-0.188781</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010372</td>\n",
       "      <td>-0.009624</td>\n",
       "      <td>0.581458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442743</th>\n",
       "      <td>1.363118</td>\n",
       "      <td>-0.052933</td>\n",
       "      <td>-0.016809</td>\n",
       "      <td>-0.143317</td>\n",
       "      <td>-0.065035</td>\n",
       "      <td>-0.051378</td>\n",
       "      <td>-0.067935</td>\n",
       "      <td>-0.040315</td>\n",
       "      <td>-0.742627</td>\n",
       "      <td>-0.550903</td>\n",
       "      <td>-0.641564</td>\n",
       "      <td>-0.679394</td>\n",
       "      <td>-0.818084</td>\n",
       "      <td>-0.638273</td>\n",
       "      <td>-0.554938</td>\n",
       "      <td>-0.577831</td>\n",
       "      <td>-0.118903</td>\n",
       "      <td>-0.127790</td>\n",
       "      <td>-0.192837</td>\n",
       "      <td>-0.074908</td>\n",
       "      <td>-0.415211</td>\n",
       "      <td>-0.341399</td>\n",
       "      <td>-0.324482</td>\n",
       "      <td>-0.243767</td>\n",
       "      <td>-0.358496</td>\n",
       "      <td>-0.326396</td>\n",
       "      <td>-0.021948</td>\n",
       "      <td>-0.032431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.072376</td>\n",
       "      <td>-0.081715</td>\n",
       "      <td>13.752129</td>\n",
       "      <td>15.098929</td>\n",
       "      <td>14.729403</td>\n",
       "      <td>8.572502</td>\n",
       "      <td>-0.671095</td>\n",
       "      <td>-0.667211</td>\n",
       "      <td>-0.440218</td>\n",
       "      <td>-0.398125</td>\n",
       "      <td>0.402614</td>\n",
       "      <td>-0.693391</td>\n",
       "      <td>-0.188781</td>\n",
       "      <td>-0.045997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010372</td>\n",
       "      <td>-0.009624</td>\n",
       "      <td>-0.425760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>442744 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           proto    srcPrt    dstPrt  flowduration  total_fpackets  \\\n",
       "0      -0.733612 -0.052933 -0.024120     -0.079243       -0.048035   \n",
       "1      -0.733612 -0.052933 -0.024120     -0.139326       -0.065035   \n",
       "2      -0.733612 -0.052806 -0.024120     -0.139246       -0.065035   \n",
       "3      -0.733612 -0.052886 -0.024120     -0.141920       -0.065035   \n",
       "4       1.363118 -0.052933 -0.016809      0.044147        0.002967   \n",
       "...          ...       ...       ...           ...             ...   \n",
       "442739  1.363118 -0.052933 -0.016809     -0.142145       -0.031034   \n",
       "442740 -0.733612 -0.052587 -0.024120     -0.140909       -0.065035   \n",
       "442741 -0.733612 -0.052933 -0.024120     -0.127595       -0.065035   \n",
       "442742  1.363118 -0.052916 -0.016809     -0.118023        0.011467   \n",
       "442743  1.363118 -0.052933 -0.016809     -0.143317       -0.065035   \n",
       "\n",
       "        total_bpackets  total_fpktl  total_bpktl  min_fpktl  min_bpktl  \\\n",
       "0            -0.041497    -0.055559    -0.036163  -0.093317   0.738297   \n",
       "1            -0.051378    -0.066879    -0.040244   0.014901  -0.273656   \n",
       "2            -0.051378    -0.067407    -0.040269  -0.363863  -0.370692   \n",
       "3            -0.051378    -0.065898    -0.038868   0.718320   5.049495   \n",
       "4            -0.006915     0.025488    -0.018653  -0.742627  -0.550903   \n",
       "...                ...          ...          ...        ...        ...   \n",
       "442739       -0.031617    -0.016922    -0.038685  -0.742627  -0.550903   \n",
       "442740       -0.051378    -0.067030    -0.040251  -0.093317  -0.301380   \n",
       "442741       -0.051378    -0.066652    -0.040233   0.177228  -0.232069   \n",
       "442742       -0.011855     0.000812    -0.015446  -0.417972  -0.384555   \n",
       "442743       -0.051378    -0.067935    -0.040315  -0.742627  -0.550903   \n",
       "\n",
       "        max_fpktl  max_bpktl  mean_fpktl  mean_bpktl  std_fpktl  std_bpktl  \\\n",
       "0       -0.574907   0.195184   -0.493421    0.340353  -0.529730   0.373654   \n",
       "1       -0.583239  -0.642877   -0.508179   -0.582405  -0.554938  -0.577831   \n",
       "2       -0.612402  -0.655658   -0.663131   -0.601959  -0.554938  -0.577831   \n",
       "3       -0.529081   0.058246   -0.220409    0.490266  -0.554938  -0.577831   \n",
       "4        0.924868   1.840267    1.046267    0.914865   1.250861   2.156282   \n",
       "...           ...        ...         ...         ...        ...        ...   \n",
       "442739   1.166498  -0.257624    1.112183   -0.504748   1.561243  -0.140335   \n",
       "442740  -0.591571  -0.646528   -0.552451   -0.587992  -0.554938  -0.577831   \n",
       "442741  -0.570741  -0.637399   -0.441770   -0.574025  -0.554938  -0.577831   \n",
       "442742   0.645743   1.840267    0.003165    1.381986   0.488247   2.354700   \n",
       "442743  -0.641564  -0.679394   -0.818084   -0.638273  -0.554938  -0.577831   \n",
       "\n",
       "        total_fipt  total_bipt  min_fipt  min_bipt  max_fipt  max_bipt  \\\n",
       "0        -0.055130   -0.032651 -0.192824 -0.074806  0.012855  0.100829   \n",
       "1        -0.118903   -0.127790 -0.192837 -0.074908 -0.415211 -0.341399   \n",
       "2        -0.118903   -0.127790 -0.192837 -0.074908 -0.415211 -0.341399   \n",
       "3        -0.118903   -0.127790 -0.192837 -0.074908 -0.415211 -0.341399   \n",
       "4         0.071029    0.155692 -0.152990 -0.074906  0.202066  0.383703   \n",
       "...            ...         ...       ...       ...       ...       ...   \n",
       "442739   -0.117716   -0.126019 -0.192447 -0.074890 -0.410876 -0.337066   \n",
       "442740   -0.118903   -0.127790 -0.192837 -0.074908 -0.415211 -0.341399   \n",
       "442741   -0.118903   -0.127790 -0.192837 -0.074908 -0.415211 -0.341399   \n",
       "442742   -0.093275   -0.090681 -0.192766 -0.074905 -0.323273 -0.251589   \n",
       "442743   -0.118903   -0.127790 -0.192837 -0.074908 -0.415211 -0.341399   \n",
       "\n",
       "        mean_fipt  mean_bipt  std_fipt  std_bipt  fpsh_cnt  bpsh_cnt  \\\n",
       "0        0.129570   0.305365  0.480648  0.470165 -0.021948 -0.032431   \n",
       "1       -0.324482  -0.243767 -0.358496 -0.326396 -0.021948 -0.032431   \n",
       "2       -0.324482  -0.243767 -0.358496 -0.326396 -0.021948 -0.032431   \n",
       "3       -0.324482  -0.243767 -0.358496 -0.326396 -0.021948 -0.032431   \n",
       "4        0.013590   0.119839  0.275061  0.320006  0.016329 -0.013101   \n",
       "...           ...        ...       ...       ...       ...       ...   \n",
       "442739  -0.320257  -0.238655 -0.353488 -0.320734 -0.002810 -0.022766   \n",
       "442740  -0.324482  -0.243767 -0.358496 -0.326396 -0.021948 -0.032431   \n",
       "442741  -0.324482  -0.243767 -0.358496 -0.326396 -0.021948 -0.032431   \n",
       "442742  -0.283935  -0.190221 -0.263363 -0.232016 -0.002810 -0.013101   \n",
       "442743  -0.324482  -0.243767 -0.358496 -0.326396 -0.021948 -0.032431   \n",
       "\n",
       "        furg_cnt  burg_cnt  total_fhlen  total_bhlen  fPktsPerSecond  \\\n",
       "0            0.0       0.0    -0.040528     0.176356       -0.170286   \n",
       "1            0.0       0.0    -0.066131    -0.076984       -0.169990   \n",
       "2            0.0       0.0    -0.068317    -0.078640       -0.169997   \n",
       "3            0.0       0.0    -0.062072     0.013849       -0.169314   \n",
       "4            0.0       0.0    -0.018672    -0.036299       -0.170284   \n",
       "...          ...       ...          ...          ...             ...   \n",
       "442739       0.0       0.0    -0.044899    -0.060899       -0.164156   \n",
       "442740       0.0       0.0    -0.066756    -0.077458       -0.169751   \n",
       "442741       0.0       0.0    -0.065194    -0.076275       -0.170261   \n",
       "442742       0.0       0.0     0.023792    -0.015483       -0.169779   \n",
       "442743       0.0       0.0    -0.072376    -0.081715       13.752129   \n",
       "\n",
       "        bPktsPerSecond  flowPktsPerSecond  flowBytesPerSecond  mean_flowpktl  \\\n",
       "0            -0.177908          -0.177969           -0.163608       0.167291   \n",
       "1            -0.177584          -0.177652           -0.163491      -0.592999   \n",
       "2            -0.177592          -0.177660           -0.163524      -0.625156   \n",
       "3            -0.176843          -0.176929           -0.160670       0.318890   \n",
       "4            -0.177898          -0.177963           -0.163472       0.855772   \n",
       "...                ...                ...                 ...            ...   \n",
       "442739       -0.171183          -0.171406           -0.155293      -0.361007   \n",
       "442740       -0.177321          -0.177396           -0.163309      -0.602187   \n",
       "442741       -0.177882          -0.177943           -0.163709      -0.579217   \n",
       "442742       -0.177416          -0.177458           -0.161270       0.993105   \n",
       "442743       15.098929          14.729403            8.572502      -0.671095   \n",
       "\n",
       "        std_flowpktl  mean_flowipt  std_flowipt  flow_fin  flow_syn  flow_rst  \\\n",
       "0           0.283909     -0.265448     0.181161 -0.639758 -0.693391 -0.188781   \n",
       "1          -0.685160     -0.386753    -0.398125 -0.639758 -0.693391 -0.188781   \n",
       "2          -0.685160     -0.385684    -0.398125 -0.639758 -0.693391 -0.188781   \n",
       "3           0.424649     -0.421501    -0.398125 -0.639758 -0.693391 -0.188781   \n",
       "4           1.530503     -0.263896     0.144692  1.444986  1.290624 -0.188781   \n",
       "...              ...           ...          ...       ...       ...       ...   \n",
       "442739     -0.058480     -0.438410    -0.393527  1.444986  1.290624 -0.188781   \n",
       "442740     -0.685160     -0.407964    -0.398125 -0.639758 -0.693391 -0.188781   \n",
       "442741     -0.685160     -0.229615    -0.398125 -0.639758 -0.693391 -0.188781   \n",
       "442742      1.766956     -0.411887    -0.302911  1.444986  1.290624 -0.188781   \n",
       "442743     -0.667211     -0.440218    -0.398125  0.402614 -0.693391 -0.188781   \n",
       "\n",
       "        flow_ack  flow_urg  flow_cwr  flow_ece  downUpRatio  \n",
       "0      -0.052303       0.0 -0.010372 -0.009624     0.295660  \n",
       "1      -0.052303       0.0 -0.010372 -0.009624    -0.409783  \n",
       "2      -0.052303       0.0 -0.010372 -0.009624    -0.409783  \n",
       "3      -0.052303       0.0 -0.010372 -0.009624     0.271564  \n",
       "4       0.004451       0.0 -0.010372 -0.009624     0.181317  \n",
       "...          ...       ...       ...       ...          ...  \n",
       "442739 -0.023926       0.0 -0.010372 -0.009624    -0.459062  \n",
       "442740 -0.052303       0.0 -0.010372 -0.009624    -0.409783  \n",
       "442741 -0.052303       0.0 -0.010372 -0.009624    -0.409783  \n",
       "442742  0.004451       0.0 -0.010372 -0.009624     0.581458  \n",
       "442743 -0.045997       0.0 -0.010372 -0.009624    -0.425760  \n",
       "\n",
       "[442744 rows x 48 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_train_stand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proto</th>\n",
       "      <th>srcPrt</th>\n",
       "      <th>dstPrt</th>\n",
       "      <th>flowduration</th>\n",
       "      <th>total_fpackets</th>\n",
       "      <th>total_bpackets</th>\n",
       "      <th>total_fpktl</th>\n",
       "      <th>total_bpktl</th>\n",
       "      <th>min_fpktl</th>\n",
       "      <th>min_bpktl</th>\n",
       "      <th>max_fpktl</th>\n",
       "      <th>max_bpktl</th>\n",
       "      <th>mean_fpktl</th>\n",
       "      <th>mean_bpktl</th>\n",
       "      <th>std_fpktl</th>\n",
       "      <th>std_bpktl</th>\n",
       "      <th>total_fipt</th>\n",
       "      <th>total_bipt</th>\n",
       "      <th>min_fipt</th>\n",
       "      <th>min_bipt</th>\n",
       "      <th>max_fipt</th>\n",
       "      <th>max_bipt</th>\n",
       "      <th>mean_fipt</th>\n",
       "      <th>mean_bipt</th>\n",
       "      <th>std_fipt</th>\n",
       "      <th>std_bipt</th>\n",
       "      <th>fpsh_cnt</th>\n",
       "      <th>bpsh_cnt</th>\n",
       "      <th>furg_cnt</th>\n",
       "      <th>burg_cnt</th>\n",
       "      <th>total_fhlen</th>\n",
       "      <th>total_bhlen</th>\n",
       "      <th>fPktsPerSecond</th>\n",
       "      <th>bPktsPerSecond</th>\n",
       "      <th>flowPktsPerSecond</th>\n",
       "      <th>flowBytesPerSecond</th>\n",
       "      <th>mean_flowpktl</th>\n",
       "      <th>std_flowpktl</th>\n",
       "      <th>mean_flowipt</th>\n",
       "      <th>std_flowipt</th>\n",
       "      <th>flow_fin</th>\n",
       "      <th>flow_syn</th>\n",
       "      <th>flow_rst</th>\n",
       "      <th>flow_ack</th>\n",
       "      <th>flow_urg</th>\n",
       "      <th>flow_cwr</th>\n",
       "      <th>flow_ece</th>\n",
       "      <th>downUpRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.363118</td>\n",
       "      <td>-0.052933</td>\n",
       "      <td>-0.016809</td>\n",
       "      <td>-0.055446</td>\n",
       "      <td>0.079470</td>\n",
       "      <td>0.042488</td>\n",
       "      <td>0.200487</td>\n",
       "      <td>0.005764</td>\n",
       "      <td>-0.742627</td>\n",
       "      <td>-0.550903</td>\n",
       "      <td>1.158166</td>\n",
       "      <td>1.840267</td>\n",
       "      <td>2.301876</td>\n",
       "      <td>1.014729</td>\n",
       "      <td>1.683523</td>\n",
       "      <td>1.770364</td>\n",
       "      <td>-0.029874</td>\n",
       "      <td>0.005089</td>\n",
       "      <td>-0.192098</td>\n",
       "      <td>-0.074905</td>\n",
       "      <td>-0.033623</td>\n",
       "      <td>0.064764</td>\n",
       "      <td>-0.249909</td>\n",
       "      <td>-0.163034</td>\n",
       "      <td>-0.102467</td>\n",
       "      <td>-0.085631</td>\n",
       "      <td>0.092882</td>\n",
       "      <td>0.073885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036281</td>\n",
       "      <td>0.010064</td>\n",
       "      <td>-0.170056</td>\n",
       "      <td>-0.177620</td>\n",
       "      <td>-0.177706</td>\n",
       "      <td>-0.162283</td>\n",
       "      <td>1.065640</td>\n",
       "      <td>1.322942</td>\n",
       "      <td>-0.383299</td>\n",
       "      <td>-0.130688</td>\n",
       "      <td>1.444986</td>\n",
       "      <td>1.290624</td>\n",
       "      <td>-0.188781</td>\n",
       "      <td>0.064359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010372</td>\n",
       "      <td>-0.009624</td>\n",
       "      <td>0.000945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.733612</td>\n",
       "      <td>-0.052916</td>\n",
       "      <td>-0.024120</td>\n",
       "      <td>-0.143313</td>\n",
       "      <td>-0.065035</td>\n",
       "      <td>-0.051378</td>\n",
       "      <td>-0.066426</td>\n",
       "      <td>-0.040222</td>\n",
       "      <td>0.339556</td>\n",
       "      <td>-0.190481</td>\n",
       "      <td>-0.558243</td>\n",
       "      <td>-0.631922</td>\n",
       "      <td>-0.375362</td>\n",
       "      <td>-0.565644</td>\n",
       "      <td>-0.554938</td>\n",
       "      <td>-0.577831</td>\n",
       "      <td>-0.118903</td>\n",
       "      <td>-0.127790</td>\n",
       "      <td>-0.192837</td>\n",
       "      <td>-0.074908</td>\n",
       "      <td>-0.415211</td>\n",
       "      <td>-0.341399</td>\n",
       "      <td>-0.324482</td>\n",
       "      <td>-0.243767</td>\n",
       "      <td>-0.358496</td>\n",
       "      <td>-0.326396</td>\n",
       "      <td>-0.021948</td>\n",
       "      <td>-0.032431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.064258</td>\n",
       "      <td>-0.075565</td>\n",
       "      <td>0.154818</td>\n",
       "      <td>0.178823</td>\n",
       "      <td>0.170134</td>\n",
       "      <td>0.122590</td>\n",
       "      <td>-0.565435</td>\n",
       "      <td>-0.685160</td>\n",
       "      <td>-0.440160</td>\n",
       "      <td>-0.398125</td>\n",
       "      <td>-0.639758</td>\n",
       "      <td>-0.693391</td>\n",
       "      <td>-0.188781</td>\n",
       "      <td>-0.052303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010372</td>\n",
       "      <td>-0.009624</td>\n",
       "      <td>-0.409783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.363118</td>\n",
       "      <td>-0.052933</td>\n",
       "      <td>-0.016809</td>\n",
       "      <td>-0.041254</td>\n",
       "      <td>0.002967</td>\n",
       "      <td>-0.006915</td>\n",
       "      <td>0.024583</td>\n",
       "      <td>-0.017374</td>\n",
       "      <td>-0.742627</td>\n",
       "      <td>-0.550903</td>\n",
       "      <td>0.924868</td>\n",
       "      <td>1.840267</td>\n",
       "      <td>1.016752</td>\n",
       "      <td>1.014590</td>\n",
       "      <td>1.222285</td>\n",
       "      <td>2.286886</td>\n",
       "      <td>-0.015497</td>\n",
       "      <td>0.026549</td>\n",
       "      <td>-0.189838</td>\n",
       "      <td>-0.074907</td>\n",
       "      <td>-0.081152</td>\n",
       "      <td>0.064333</td>\n",
       "      <td>-0.140423</td>\n",
       "      <td>-0.045806</td>\n",
       "      <td>-0.010560</td>\n",
       "      <td>0.045479</td>\n",
       "      <td>0.016329</td>\n",
       "      <td>-0.013101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.018672</td>\n",
       "      <td>-0.036299</td>\n",
       "      <td>-0.170226</td>\n",
       "      <td>-0.177827</td>\n",
       "      <td>-0.177897</td>\n",
       "      <td>-0.163181</td>\n",
       "      <td>0.939187</td>\n",
       "      <td>1.645126</td>\n",
       "      <td>-0.328136</td>\n",
       "      <td>-0.050095</td>\n",
       "      <td>1.444986</td>\n",
       "      <td>1.290624</td>\n",
       "      <td>-0.188781</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010372</td>\n",
       "      <td>-0.009624</td>\n",
       "      <td>0.232678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.733612</td>\n",
       "      <td>-0.052931</td>\n",
       "      <td>-0.024120</td>\n",
       "      <td>-0.143314</td>\n",
       "      <td>-0.065035</td>\n",
       "      <td>-0.051378</td>\n",
       "      <td>-0.067332</td>\n",
       "      <td>-0.040265</td>\n",
       "      <td>-0.309754</td>\n",
       "      <td>-0.356830</td>\n",
       "      <td>-0.608236</td>\n",
       "      <td>-0.653832</td>\n",
       "      <td>-0.640995</td>\n",
       "      <td>-0.599165</td>\n",
       "      <td>-0.554938</td>\n",
       "      <td>-0.577831</td>\n",
       "      <td>-0.118903</td>\n",
       "      <td>-0.127790</td>\n",
       "      <td>-0.192837</td>\n",
       "      <td>-0.074908</td>\n",
       "      <td>-0.415211</td>\n",
       "      <td>-0.341399</td>\n",
       "      <td>-0.324482</td>\n",
       "      <td>-0.243767</td>\n",
       "      <td>-0.358496</td>\n",
       "      <td>-0.326396</td>\n",
       "      <td>-0.021948</td>\n",
       "      <td>-0.032431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.068004</td>\n",
       "      <td>-0.078404</td>\n",
       "      <td>0.286515</td>\n",
       "      <td>0.323332</td>\n",
       "      <td>0.311149</td>\n",
       "      <td>0.178221</td>\n",
       "      <td>-0.620562</td>\n",
       "      <td>-0.685160</td>\n",
       "      <td>-0.440177</td>\n",
       "      <td>-0.398125</td>\n",
       "      <td>-0.639758</td>\n",
       "      <td>-0.693391</td>\n",
       "      <td>-0.188781</td>\n",
       "      <td>-0.052303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010372</td>\n",
       "      <td>-0.009624</td>\n",
       "      <td>-0.409783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.733612</td>\n",
       "      <td>-0.052916</td>\n",
       "      <td>-0.024120</td>\n",
       "      <td>-0.142621</td>\n",
       "      <td>-0.065035</td>\n",
       "      <td>-0.051378</td>\n",
       "      <td>-0.066275</td>\n",
       "      <td>-0.040215</td>\n",
       "      <td>0.447774</td>\n",
       "      <td>-0.162757</td>\n",
       "      <td>-0.549911</td>\n",
       "      <td>-0.628270</td>\n",
       "      <td>-0.331090</td>\n",
       "      <td>-0.560058</td>\n",
       "      <td>-0.554938</td>\n",
       "      <td>-0.577831</td>\n",
       "      <td>-0.118903</td>\n",
       "      <td>-0.127790</td>\n",
       "      <td>-0.192837</td>\n",
       "      <td>-0.074908</td>\n",
       "      <td>-0.415211</td>\n",
       "      <td>-0.341399</td>\n",
       "      <td>-0.324482</td>\n",
       "      <td>-0.243767</td>\n",
       "      <td>-0.358496</td>\n",
       "      <td>-0.326396</td>\n",
       "      <td>-0.021948</td>\n",
       "      <td>-0.032431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.063633</td>\n",
       "      <td>-0.075092</td>\n",
       "      <td>-0.168268</td>\n",
       "      <td>-0.175694</td>\n",
       "      <td>-0.175809</td>\n",
       "      <td>-0.161904</td>\n",
       "      <td>-0.556248</td>\n",
       "      <td>-0.685160</td>\n",
       "      <td>-0.430894</td>\n",
       "      <td>-0.398125</td>\n",
       "      <td>-0.639758</td>\n",
       "      <td>-0.693391</td>\n",
       "      <td>-0.188781</td>\n",
       "      <td>-0.052303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010372</td>\n",
       "      <td>-0.009624</td>\n",
       "      <td>-0.409783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110681</th>\n",
       "      <td>-0.733612</td>\n",
       "      <td>-0.052587</td>\n",
       "      <td>-0.024120</td>\n",
       "      <td>0.142026</td>\n",
       "      <td>-0.065035</td>\n",
       "      <td>-0.051378</td>\n",
       "      <td>-0.067181</td>\n",
       "      <td>-0.040258</td>\n",
       "      <td>-0.201536</td>\n",
       "      <td>-0.329105</td>\n",
       "      <td>-0.599903</td>\n",
       "      <td>-0.650180</td>\n",
       "      <td>-0.596723</td>\n",
       "      <td>-0.593579</td>\n",
       "      <td>-0.554938</td>\n",
       "      <td>-0.577831</td>\n",
       "      <td>-0.118903</td>\n",
       "      <td>-0.127790</td>\n",
       "      <td>-0.192837</td>\n",
       "      <td>-0.074908</td>\n",
       "      <td>-0.415211</td>\n",
       "      <td>-0.341399</td>\n",
       "      <td>-0.324482</td>\n",
       "      <td>-0.243767</td>\n",
       "      <td>-0.358496</td>\n",
       "      <td>-0.326396</td>\n",
       "      <td>-0.021948</td>\n",
       "      <td>-0.032431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.067380</td>\n",
       "      <td>-0.077931</td>\n",
       "      <td>-0.170348</td>\n",
       "      <td>-0.177977</td>\n",
       "      <td>-0.178037</td>\n",
       "      <td>-0.163783</td>\n",
       "      <td>-0.611374</td>\n",
       "      <td>-0.685160</td>\n",
       "      <td>3.381993</td>\n",
       "      <td>-0.398125</td>\n",
       "      <td>-0.639758</td>\n",
       "      <td>-0.693391</td>\n",
       "      <td>-0.188781</td>\n",
       "      <td>-0.052303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010372</td>\n",
       "      <td>-0.009624</td>\n",
       "      <td>-0.409783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110682</th>\n",
       "      <td>-0.733612</td>\n",
       "      <td>-0.052933</td>\n",
       "      <td>-0.024120</td>\n",
       "      <td>-0.140904</td>\n",
       "      <td>-0.065035</td>\n",
       "      <td>-0.051378</td>\n",
       "      <td>-0.066728</td>\n",
       "      <td>-0.040237</td>\n",
       "      <td>0.123119</td>\n",
       "      <td>-0.245931</td>\n",
       "      <td>-0.574907</td>\n",
       "      <td>-0.639225</td>\n",
       "      <td>-0.463907</td>\n",
       "      <td>-0.576818</td>\n",
       "      <td>-0.554938</td>\n",
       "      <td>-0.577831</td>\n",
       "      <td>-0.118903</td>\n",
       "      <td>-0.127790</td>\n",
       "      <td>-0.192837</td>\n",
       "      <td>-0.074908</td>\n",
       "      <td>-0.415211</td>\n",
       "      <td>-0.341399</td>\n",
       "      <td>-0.324482</td>\n",
       "      <td>-0.243767</td>\n",
       "      <td>-0.358496</td>\n",
       "      <td>-0.326396</td>\n",
       "      <td>-0.021948</td>\n",
       "      <td>-0.032431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.065507</td>\n",
       "      <td>-0.076511</td>\n",
       "      <td>-0.169752</td>\n",
       "      <td>-0.177323</td>\n",
       "      <td>-0.177398</td>\n",
       "      <td>-0.163284</td>\n",
       "      <td>-0.583811</td>\n",
       "      <td>-0.685160</td>\n",
       "      <td>-0.407902</td>\n",
       "      <td>-0.398125</td>\n",
       "      <td>-0.639758</td>\n",
       "      <td>-0.693391</td>\n",
       "      <td>-0.188781</td>\n",
       "      <td>-0.052303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010372</td>\n",
       "      <td>-0.009624</td>\n",
       "      <td>-0.409783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110683</th>\n",
       "      <td>-0.733612</td>\n",
       "      <td>-0.052933</td>\n",
       "      <td>-0.024120</td>\n",
       "      <td>-0.143315</td>\n",
       "      <td>-0.065035</td>\n",
       "      <td>-0.051378</td>\n",
       "      <td>-0.065973</td>\n",
       "      <td>-0.040018</td>\n",
       "      <td>0.664211</td>\n",
       "      <td>0.599674</td>\n",
       "      <td>-0.533247</td>\n",
       "      <td>-0.527849</td>\n",
       "      <td>-0.242546</td>\n",
       "      <td>-0.406420</td>\n",
       "      <td>-0.554938</td>\n",
       "      <td>-0.577831</td>\n",
       "      <td>-0.118903</td>\n",
       "      <td>-0.127790</td>\n",
       "      <td>-0.192837</td>\n",
       "      <td>-0.074908</td>\n",
       "      <td>-0.415211</td>\n",
       "      <td>-0.341399</td>\n",
       "      <td>-0.324482</td>\n",
       "      <td>-0.243767</td>\n",
       "      <td>-0.358496</td>\n",
       "      <td>-0.326396</td>\n",
       "      <td>-0.021948</td>\n",
       "      <td>-0.032431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.062384</td>\n",
       "      <td>-0.062082</td>\n",
       "      <td>0.416181</td>\n",
       "      <td>0.465612</td>\n",
       "      <td>0.449988</td>\n",
       "      <td>0.556166</td>\n",
       "      <td>-0.420728</td>\n",
       "      <td>-0.532598</td>\n",
       "      <td>-0.440186</td>\n",
       "      <td>-0.398125</td>\n",
       "      <td>-0.639758</td>\n",
       "      <td>-0.693391</td>\n",
       "      <td>-0.188781</td>\n",
       "      <td>-0.052303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010372</td>\n",
       "      <td>-0.009624</td>\n",
       "      <td>-0.315031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110684</th>\n",
       "      <td>-0.733612</td>\n",
       "      <td>-0.052886</td>\n",
       "      <td>-0.024120</td>\n",
       "      <td>-0.137310</td>\n",
       "      <td>-0.065035</td>\n",
       "      <td>-0.051378</td>\n",
       "      <td>-0.066803</td>\n",
       "      <td>-0.040240</td>\n",
       "      <td>0.069010</td>\n",
       "      <td>-0.259793</td>\n",
       "      <td>-0.579073</td>\n",
       "      <td>-0.641051</td>\n",
       "      <td>-0.486043</td>\n",
       "      <td>-0.579612</td>\n",
       "      <td>-0.554938</td>\n",
       "      <td>-0.577831</td>\n",
       "      <td>-0.118903</td>\n",
       "      <td>-0.127790</td>\n",
       "      <td>-0.192837</td>\n",
       "      <td>-0.074908</td>\n",
       "      <td>-0.415211</td>\n",
       "      <td>-0.341399</td>\n",
       "      <td>-0.324482</td>\n",
       "      <td>-0.243767</td>\n",
       "      <td>-0.358496</td>\n",
       "      <td>-0.326396</td>\n",
       "      <td>-0.021948</td>\n",
       "      <td>-0.032431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.065819</td>\n",
       "      <td>-0.076748</td>\n",
       "      <td>-0.170112</td>\n",
       "      <td>-0.177718</td>\n",
       "      <td>-0.177783</td>\n",
       "      <td>-0.163588</td>\n",
       "      <td>-0.588405</td>\n",
       "      <td>-0.685160</td>\n",
       "      <td>-0.359756</td>\n",
       "      <td>-0.398125</td>\n",
       "      <td>-0.639758</td>\n",
       "      <td>-0.693391</td>\n",
       "      <td>-0.188781</td>\n",
       "      <td>-0.052303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010372</td>\n",
       "      <td>-0.009624</td>\n",
       "      <td>-0.409783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110685</th>\n",
       "      <td>-0.733612</td>\n",
       "      <td>-0.052933</td>\n",
       "      <td>-0.024120</td>\n",
       "      <td>-0.142534</td>\n",
       "      <td>-0.005533</td>\n",
       "      <td>-0.016796</td>\n",
       "      <td>-0.018733</td>\n",
       "      <td>-0.032304</td>\n",
       "      <td>0.826539</td>\n",
       "      <td>1.098719</td>\n",
       "      <td>-0.520749</td>\n",
       "      <td>-0.171810</td>\n",
       "      <td>-0.176137</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>-0.554938</td>\n",
       "      <td>-0.278560</td>\n",
       "      <td>-0.118889</td>\n",
       "      <td>-0.127786</td>\n",
       "      <td>-0.192822</td>\n",
       "      <td>-0.074903</td>\n",
       "      <td>-0.415192</td>\n",
       "      <td>-0.341393</td>\n",
       "      <td>-0.324455</td>\n",
       "      <td>-0.243762</td>\n",
       "      <td>-0.358483</td>\n",
       "      <td>-0.326392</td>\n",
       "      <td>-0.021948</td>\n",
       "      <td>-0.032431</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058762</td>\n",
       "      <td>0.390902</td>\n",
       "      <td>-0.155515</td>\n",
       "      <td>-0.161701</td>\n",
       "      <td>-0.162154</td>\n",
       "      <td>-0.133138</td>\n",
       "      <td>-0.071017</td>\n",
       "      <td>-0.209005</td>\n",
       "      <td>-0.439520</td>\n",
       "      <td>-0.394016</td>\n",
       "      <td>-0.639758</td>\n",
       "      <td>-0.693391</td>\n",
       "      <td>-0.188781</td>\n",
       "      <td>-0.052303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010372</td>\n",
       "      <td>-0.009624</td>\n",
       "      <td>-0.055671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110686 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           proto    srcPrt    dstPrt  flowduration  total_fpackets  \\\n",
       "0       1.363118 -0.052933 -0.016809     -0.055446        0.079470   \n",
       "1      -0.733612 -0.052916 -0.024120     -0.143313       -0.065035   \n",
       "2       1.363118 -0.052933 -0.016809     -0.041254        0.002967   \n",
       "3      -0.733612 -0.052931 -0.024120     -0.143314       -0.065035   \n",
       "4      -0.733612 -0.052916 -0.024120     -0.142621       -0.065035   \n",
       "...          ...       ...       ...           ...             ...   \n",
       "110681 -0.733612 -0.052587 -0.024120      0.142026       -0.065035   \n",
       "110682 -0.733612 -0.052933 -0.024120     -0.140904       -0.065035   \n",
       "110683 -0.733612 -0.052933 -0.024120     -0.143315       -0.065035   \n",
       "110684 -0.733612 -0.052886 -0.024120     -0.137310       -0.065035   \n",
       "110685 -0.733612 -0.052933 -0.024120     -0.142534       -0.005533   \n",
       "\n",
       "        total_bpackets  total_fpktl  total_bpktl  min_fpktl  min_bpktl  \\\n",
       "0             0.042488     0.200487     0.005764  -0.742627  -0.550903   \n",
       "1            -0.051378    -0.066426    -0.040222   0.339556  -0.190481   \n",
       "2            -0.006915     0.024583    -0.017374  -0.742627  -0.550903   \n",
       "3            -0.051378    -0.067332    -0.040265  -0.309754  -0.356830   \n",
       "4            -0.051378    -0.066275    -0.040215   0.447774  -0.162757   \n",
       "...                ...          ...          ...        ...        ...   \n",
       "110681       -0.051378    -0.067181    -0.040258  -0.201536  -0.329105   \n",
       "110682       -0.051378    -0.066728    -0.040237   0.123119  -0.245931   \n",
       "110683       -0.051378    -0.065973    -0.040018   0.664211   0.599674   \n",
       "110684       -0.051378    -0.066803    -0.040240   0.069010  -0.259793   \n",
       "110685       -0.016796    -0.018733    -0.032304   0.826539   1.098719   \n",
       "\n",
       "        max_fpktl  max_bpktl  mean_fpktl  mean_bpktl  std_fpktl  std_bpktl  \\\n",
       "0        1.158166   1.840267    2.301876    1.014729   1.683523   1.770364   \n",
       "1       -0.558243  -0.631922   -0.375362   -0.565644  -0.554938  -0.577831   \n",
       "2        0.924868   1.840267    1.016752    1.014590   1.222285   2.286886   \n",
       "3       -0.608236  -0.653832   -0.640995   -0.599165  -0.554938  -0.577831   \n",
       "4       -0.549911  -0.628270   -0.331090   -0.560058  -0.554938  -0.577831   \n",
       "...           ...        ...         ...         ...        ...        ...   \n",
       "110681  -0.599903  -0.650180   -0.596723   -0.593579  -0.554938  -0.577831   \n",
       "110682  -0.574907  -0.639225   -0.463907   -0.576818  -0.554938  -0.577831   \n",
       "110683  -0.533247  -0.527849   -0.242546   -0.406420  -0.554938  -0.577831   \n",
       "110684  -0.579073  -0.641051   -0.486043   -0.579612  -0.554938  -0.577831   \n",
       "110685  -0.520749  -0.171810   -0.176137    0.010497  -0.554938  -0.278560   \n",
       "\n",
       "        total_fipt  total_bipt  min_fipt  min_bipt  max_fipt  max_bipt  \\\n",
       "0        -0.029874    0.005089 -0.192098 -0.074905 -0.033623  0.064764   \n",
       "1        -0.118903   -0.127790 -0.192837 -0.074908 -0.415211 -0.341399   \n",
       "2        -0.015497    0.026549 -0.189838 -0.074907 -0.081152  0.064333   \n",
       "3        -0.118903   -0.127790 -0.192837 -0.074908 -0.415211 -0.341399   \n",
       "4        -0.118903   -0.127790 -0.192837 -0.074908 -0.415211 -0.341399   \n",
       "...            ...         ...       ...       ...       ...       ...   \n",
       "110681   -0.118903   -0.127790 -0.192837 -0.074908 -0.415211 -0.341399   \n",
       "110682   -0.118903   -0.127790 -0.192837 -0.074908 -0.415211 -0.341399   \n",
       "110683   -0.118903   -0.127790 -0.192837 -0.074908 -0.415211 -0.341399   \n",
       "110684   -0.118903   -0.127790 -0.192837 -0.074908 -0.415211 -0.341399   \n",
       "110685   -0.118889   -0.127786 -0.192822 -0.074903 -0.415192 -0.341393   \n",
       "\n",
       "        mean_fipt  mean_bipt  std_fipt  std_bipt  fpsh_cnt  bpsh_cnt  \\\n",
       "0       -0.249909  -0.163034 -0.102467 -0.085631  0.092882  0.073885   \n",
       "1       -0.324482  -0.243767 -0.358496 -0.326396 -0.021948 -0.032431   \n",
       "2       -0.140423  -0.045806 -0.010560  0.045479  0.016329 -0.013101   \n",
       "3       -0.324482  -0.243767 -0.358496 -0.326396 -0.021948 -0.032431   \n",
       "4       -0.324482  -0.243767 -0.358496 -0.326396 -0.021948 -0.032431   \n",
       "...           ...        ...       ...       ...       ...       ...   \n",
       "110681  -0.324482  -0.243767 -0.358496 -0.326396 -0.021948 -0.032431   \n",
       "110682  -0.324482  -0.243767 -0.358496 -0.326396 -0.021948 -0.032431   \n",
       "110683  -0.324482  -0.243767 -0.358496 -0.326396 -0.021948 -0.032431   \n",
       "110684  -0.324482  -0.243767 -0.358496 -0.326396 -0.021948 -0.032431   \n",
       "110685  -0.324455  -0.243762 -0.358483 -0.326392 -0.021948 -0.032431   \n",
       "\n",
       "        furg_cnt  burg_cnt  total_fhlen  total_bhlen  fPktsPerSecond  \\\n",
       "0            0.0       0.0     0.036281     0.010064       -0.170056   \n",
       "1            0.0       0.0    -0.064258    -0.075565        0.154818   \n",
       "2            0.0       0.0    -0.018672    -0.036299       -0.170226   \n",
       "3            0.0       0.0    -0.068004    -0.078404        0.286515   \n",
       "4            0.0       0.0    -0.063633    -0.075092       -0.168268   \n",
       "...          ...       ...          ...          ...             ...   \n",
       "110681       0.0       0.0    -0.067380    -0.077931       -0.170348   \n",
       "110682       0.0       0.0    -0.065507    -0.076511       -0.169752   \n",
       "110683       0.0       0.0    -0.062384    -0.062082        0.416181   \n",
       "110684       0.0       0.0    -0.065819    -0.076748       -0.170112   \n",
       "110685       0.0       0.0     0.058762     0.390902       -0.155515   \n",
       "\n",
       "        bPktsPerSecond  flowPktsPerSecond  flowBytesPerSecond  mean_flowpktl  \\\n",
       "0            -0.177620          -0.177706           -0.162283       1.065640   \n",
       "1             0.178823           0.170134            0.122590      -0.565435   \n",
       "2            -0.177827          -0.177897           -0.163181       0.939187   \n",
       "3             0.323332           0.311149            0.178221      -0.620562   \n",
       "4            -0.175694          -0.175809           -0.161904      -0.556248   \n",
       "...                ...                ...                 ...            ...   \n",
       "110681       -0.177977          -0.178037           -0.163783      -0.611374   \n",
       "110682       -0.177323          -0.177398           -0.163284      -0.583811   \n",
       "110683        0.465612           0.449988            0.556166      -0.420728   \n",
       "110684       -0.177718          -0.177783           -0.163588      -0.588405   \n",
       "110685       -0.161701          -0.162154           -0.133138      -0.071017   \n",
       "\n",
       "        std_flowpktl  mean_flowipt  std_flowipt  flow_fin  flow_syn  flow_rst  \\\n",
       "0           1.322942     -0.383299    -0.130688  1.444986  1.290624 -0.188781   \n",
       "1          -0.685160     -0.440160    -0.398125 -0.639758 -0.693391 -0.188781   \n",
       "2           1.645126     -0.328136    -0.050095  1.444986  1.290624 -0.188781   \n",
       "3          -0.685160     -0.440177    -0.398125 -0.639758 -0.693391 -0.188781   \n",
       "4          -0.685160     -0.430894    -0.398125 -0.639758 -0.693391 -0.188781   \n",
       "...              ...           ...          ...       ...       ...       ...   \n",
       "110681     -0.685160      3.381993    -0.398125 -0.639758 -0.693391 -0.188781   \n",
       "110682     -0.685160     -0.407902    -0.398125 -0.639758 -0.693391 -0.188781   \n",
       "110683     -0.532598     -0.440186    -0.398125 -0.639758 -0.693391 -0.188781   \n",
       "110684     -0.685160     -0.359756    -0.398125 -0.639758 -0.693391 -0.188781   \n",
       "110685     -0.209005     -0.439520    -0.394016 -0.639758 -0.693391 -0.188781   \n",
       "\n",
       "        flow_ack  flow_urg  flow_cwr  flow_ece  downUpRatio  \n",
       "0       0.064359       0.0 -0.010372 -0.009624     0.000945  \n",
       "1      -0.052303       0.0 -0.010372 -0.009624    -0.409783  \n",
       "2       0.004451       0.0 -0.010372 -0.009624     0.232678  \n",
       "3      -0.052303       0.0 -0.010372 -0.009624    -0.409783  \n",
       "4      -0.052303       0.0 -0.010372 -0.009624    -0.409783  \n",
       "...          ...       ...       ...       ...          ...  \n",
       "110681 -0.052303       0.0 -0.010372 -0.009624    -0.409783  \n",
       "110682 -0.052303       0.0 -0.010372 -0.009624    -0.409783  \n",
       "110683 -0.052303       0.0 -0.010372 -0.009624    -0.315031  \n",
       "110684 -0.052303       0.0 -0.010372 -0.009624    -0.409783  \n",
       "110685 -0.052303       0.0 -0.010372 -0.009624    -0.055671  \n",
       "\n",
       "[110686 rows x 48 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_test_stand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection\n",
    "`VarianceThreshold` is a simple baseline approach to feature selection. It removes all features whose variance doesn’t meet some threshold. Defining and Fiting Threshold\n",
    "For quasi-constant features, that have the same value for a very large subset, i.e. using threshold as 0.01 would mean dropping the column where 99% of the values are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True,  True,  True])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the VarianceThreshold class from sklearn support a type of feature selection\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "var_thr = VarianceThreshold(threshold = 0.25) #.25 would mean dropping the column where 75% of the values are similar.\n",
    "# fit on the trainning dataset\n",
    "var_thr.fit(df_X_train_stand)\n",
    "# Get a mask of the selected features \n",
    "var_thr.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "furg_cnt\n",
      "burg_cnt\n",
      "flow_urg\n"
     ]
    }
   ],
   "source": [
    "#Show features that do not meet the threshold\n",
    "concol = [column for column in df_X_train_stand.columns \n",
    "          if column not in df_X_train_stand.columns[var_thr.get_support()]]\n",
    "\n",
    "for features in concol:\n",
    "    print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping Low Variance Columns:\n",
    "df_X_train_stand.drop(concol,axis=1,inplace=True)\n",
    "df_X_test_stand.drop(concol,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['proto', 'srcPrt', 'dstPrt', 'flowduration', 'total_fpackets',\n",
       "       'total_bpackets', 'total_fpktl', 'total_bpktl', 'min_fpktl',\n",
       "       'min_bpktl', 'max_fpktl', 'max_bpktl', 'mean_fpktl', 'mean_bpktl',\n",
       "       'std_fpktl', 'std_bpktl', 'total_fipt', 'total_bipt', 'min_fipt',\n",
       "       'min_bipt', 'max_fipt', 'max_bipt', 'mean_fipt', 'mean_bipt',\n",
       "       'std_fipt', 'std_bipt', 'fpsh_cnt', 'bpsh_cnt', 'total_fhlen',\n",
       "       'total_bhlen', 'fPktsPerSecond', 'bPktsPerSecond', 'flowPktsPerSecond',\n",
       "       'flowBytesPerSecond', 'mean_flowpktl', 'std_flowpktl', 'mean_flowipt',\n",
       "       'std_flowipt', 'flow_fin', 'flow_syn', 'flow_rst', 'flow_ack',\n",
       "       'flow_cwr', 'flow_ece', 'downUpRatio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show selected features\n",
    "df_X_train_stand.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((442744, 45), (110686, 45))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##final dataset dimensions\n",
    "df_X_train_stand.shape,df_X_test_stand.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Weighted Logistic Regression (W-LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run grid search only on training set using cross-validation\n",
    "parameters={'C':np.logspace(-3,3,7), 'penalty':[\"l1\",\"l2\"]}# l1 lasso l2 ridge\n",
    "model1=GridSearchCV(LogisticRegression(class_weight='balanced', solver='saga' ,max_iter=1000),parameters,cv=5, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "[CV 1/5] END ...............C=0.001, penalty=l1;, score=0.996 total time= 4.4min\n",
      "[CV 2/5] END ...............C=0.001, penalty=l1;, score=0.997 total time= 3.8min\n",
      "[CV 3/5] END ...............C=0.001, penalty=l1;, score=0.996 total time= 4.2min\n",
      "[CV 4/5] END ...............C=0.001, penalty=l1;, score=0.997 total time= 4.3min\n",
      "[CV 5/5] END ...............C=0.001, penalty=l1;, score=0.996 total time= 3.9min\n",
      "[CV 1/5] END ...............C=0.001, penalty=l2;, score=0.997 total time= 4.1min\n",
      "[CV 2/5] END ...............C=0.001, penalty=l2;, score=0.997 total time= 4.1min\n",
      "[CV 3/5] END ...............C=0.001, penalty=l2;, score=0.997 total time= 4.1min\n",
      "[CV 4/5] END ...............C=0.001, penalty=l2;, score=0.998 total time= 4.1min\n",
      "[CV 5/5] END ...............C=0.001, penalty=l2;, score=0.997 total time= 4.1min\n",
      "[CV 1/5] END ................C=0.01, penalty=l1;, score=0.997 total time= 4.5min\n",
      "[CV 2/5] END ................C=0.01, penalty=l1;, score=0.997 total time= 4.6min\n",
      "[CV 3/5] END ................C=0.01, penalty=l1;, score=0.997 total time= 5.1min\n",
      "[CV 4/5] END ................C=0.01, penalty=l1;, score=0.998 total time= 5.1min\n",
      "[CV 5/5] END ................C=0.01, penalty=l1;, score=0.997 total time= 5.0min\n",
      "[CV 1/5] END ................C=0.01, penalty=l2;, score=0.997 total time= 4.5min\n",
      "[CV 2/5] END ................C=0.01, penalty=l2;, score=0.998 total time= 4.5min\n",
      "[CV 3/5] END ................C=0.01, penalty=l2;, score=0.997 total time= 4.4min\n",
      "[CV 4/5] END ................C=0.01, penalty=l2;, score=0.998 total time= 4.4min\n",
      "[CV 5/5] END ................C=0.01, penalty=l2;, score=0.997 total time= 4.4min\n",
      "[CV 1/5] END .................C=0.1, penalty=l1;, score=0.997 total time= 5.0min\n",
      "[CV 2/5] END .................C=0.1, penalty=l1;, score=0.998 total time= 5.0min\n",
      "[CV 3/5] END .................C=0.1, penalty=l1;, score=0.997 total time= 4.9min\n",
      "[CV 4/5] END .................C=0.1, penalty=l1;, score=0.998 total time= 4.8min\n",
      "[CV 5/5] END .................C=0.1, penalty=l1;, score=0.997 total time= 4.6min\n",
      "[CV 1/5] END .................C=0.1, penalty=l2;, score=0.997 total time= 4.1min\n",
      "[CV 2/5] END .................C=0.1, penalty=l2;, score=0.998 total time= 4.1min\n",
      "[CV 3/5] END .................C=0.1, penalty=l2;, score=0.997 total time= 4.1min\n",
      "[CV 4/5] END .................C=0.1, penalty=l2;, score=0.998 total time= 4.1min\n",
      "[CV 5/5] END .................C=0.1, penalty=l2;, score=0.997 total time= 4.1min\n",
      "[CV 1/5] END .................C=1.0, penalty=l1;, score=0.997 total time= 4.7min\n",
      "[CV 2/5] END .................C=1.0, penalty=l1;, score=0.998 total time= 4.7min\n",
      "[CV 3/5] END .................C=1.0, penalty=l1;, score=0.997 total time= 4.7min\n",
      "[CV 4/5] END .................C=1.0, penalty=l1;, score=0.998 total time= 4.7min\n",
      "[CV 5/5] END .................C=1.0, penalty=l1;, score=0.997 total time= 4.7min\n",
      "[CV 1/5] END .................C=1.0, penalty=l2;, score=0.997 total time= 4.1min\n",
      "[CV 2/5] END .................C=1.0, penalty=l2;, score=0.998 total time= 4.1min\n",
      "[CV 3/5] END .................C=1.0, penalty=l2;, score=0.997 total time= 4.2min\n",
      "[CV 4/5] END .................C=1.0, penalty=l2;, score=0.998 total time= 4.2min\n",
      "[CV 5/5] END .................C=1.0, penalty=l2;, score=0.997 total time= 4.2min\n",
      "[CV 1/5] END ................C=10.0, penalty=l1;, score=0.997 total time= 4.7min\n",
      "[CV 2/5] END ................C=10.0, penalty=l1;, score=0.998 total time= 4.7min\n",
      "[CV 3/5] END ................C=10.0, penalty=l1;, score=0.997 total time= 4.8min\n",
      "[CV 4/5] END ................C=10.0, penalty=l1;, score=0.998 total time= 4.8min\n",
      "[CV 5/5] END ................C=10.0, penalty=l1;, score=0.997 total time= 4.7min\n",
      "[CV 1/5] END ................C=10.0, penalty=l2;, score=0.997 total time= 4.2min\n",
      "[CV 2/5] END ................C=10.0, penalty=l2;, score=0.998 total time= 4.2min\n",
      "[CV 3/5] END ................C=10.0, penalty=l2;, score=0.997 total time= 4.2min\n",
      "[CV 4/5] END ................C=10.0, penalty=l2;, score=0.998 total time= 4.1min\n",
      "[CV 5/5] END ................C=10.0, penalty=l2;, score=0.997 total time= 4.1min\n",
      "[CV 1/5] END ...............C=100.0, penalty=l1;, score=0.997 total time= 4.6min\n",
      "[CV 2/5] END ...............C=100.0, penalty=l1;, score=0.998 total time= 4.7min\n",
      "[CV 3/5] END ...............C=100.0, penalty=l1;, score=0.997 total time= 4.7min\n",
      "[CV 4/5] END ...............C=100.0, penalty=l1;, score=0.998 total time= 4.7min\n",
      "[CV 5/5] END ...............C=100.0, penalty=l1;, score=0.997 total time= 4.7min\n",
      "[CV 1/5] END ...............C=100.0, penalty=l2;, score=0.997 total time= 4.1min\n",
      "[CV 2/5] END ...............C=100.0, penalty=l2;, score=0.998 total time= 4.1min\n",
      "[CV 3/5] END ...............C=100.0, penalty=l2;, score=0.997 total time= 4.1min\n",
      "[CV 4/5] END ...............C=100.0, penalty=l2;, score=0.998 total time= 4.1min\n",
      "[CV 5/5] END ...............C=100.0, penalty=l2;, score=0.997 total time= 4.1min\n",
      "[CV 1/5] END ..............C=1000.0, penalty=l1;, score=0.997 total time= 4.6min\n",
      "[CV 2/5] END ..............C=1000.0, penalty=l1;, score=0.998 total time= 4.7min\n",
      "[CV 3/5] END ..............C=1000.0, penalty=l1;, score=0.997 total time= 4.7min\n",
      "[CV 4/5] END ..............C=1000.0, penalty=l1;, score=0.998 total time= 4.7min\n",
      "[CV 5/5] END ..............C=1000.0, penalty=l1;, score=0.997 total time= 4.7min\n",
      "[CV 1/5] END ..............C=1000.0, penalty=l2;, score=0.997 total time= 4.1min\n",
      "[CV 2/5] END ..............C=1000.0, penalty=l2;, score=0.998 total time= 4.1min\n",
      "[CV 3/5] END ..............C=1000.0, penalty=l2;, score=0.997 total time= 4.1min\n",
      "[CV 4/5] END ..............C=1000.0, penalty=l2;, score=0.998 total time= 4.1min\n",
      "[CV 5/5] END ..............C=1000.0, penalty=l2;, score=0.997 total time= 4.1min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=LogisticRegression(class_weight='balanced',\n",
       "                                          max_iter=1000, solver='saga'),\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit on the trainning dataset\n",
    "model1.fit(df_X_train_stand,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'C': 1000.0, 'penalty': 'l2'}\n",
      "accuracy : 0.9973460957557494\n"
     ]
    }
   ],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",model1.best_params_)\n",
    "print(\"accuracy :\",model1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = model1.predict(df_X_test_stand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      1.00      1.00    110630\n",
      "     class 1       0.11      0.77      0.19        56\n",
      "\n",
      "    accuracy                           1.00    110686\n",
      "   macro avg       0.56      0.88      0.60    110686\n",
      "weighted avg       1.00      1.00      1.00    110686\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#performance results\n",
    "print(classification_report(y_test, y_pred1, target_names=target_names))\n",
    "plot_confusion_matrix(model1, df_X_test_stand, y_test, display_labels=target_names,cmap=plt.cm.Blues);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Over-sampling with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origianl dataset shape: Counter({0: 442543, 1: 201})\n",
      "Resample dataset shape: Counter({0: 442543, 1: 442543})\n"
     ]
    }
   ],
   "source": [
    "# load library\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE()\n",
    "\n",
    "# fit on the trainning dataset\n",
    "X_smote , y_smote = smote.fit_resample(df_X_train_stand, y_train)\n",
    "\n",
    "print('Origianl dataset shape:', Counter(y_train))\n",
    "print('Resample dataset shape:', Counter(y_smote))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### b) Logistic Regression with Synthetic minority over-sampling technique (LR+SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "[CV 1/5] END ...............C=0.001, penalty=l1;, score=0.998 total time= 9.5min\n",
      "[CV 2/5] END ...............C=0.001, penalty=l1;, score=0.998 total time= 9.4min\n",
      "[CV 3/5] END ...............C=0.001, penalty=l1;, score=0.998 total time= 9.4min\n",
      "[CV 4/5] END ...............C=0.001, penalty=l1;, score=0.998 total time= 9.4min\n",
      "[CV 5/5] END ...............C=0.001, penalty=l1;, score=0.997 total time= 9.4min\n",
      "[CV 1/5] END ...............C=0.001, penalty=l2;, score=0.998 total time= 8.8min\n",
      "[CV 2/5] END ...............C=0.001, penalty=l2;, score=0.998 total time= 8.8min\n",
      "[CV 3/5] END ...............C=0.001, penalty=l2;, score=0.998 total time= 8.8min\n",
      "[CV 4/5] END ...............C=0.001, penalty=l2;, score=0.998 total time= 8.8min\n",
      "[CV 5/5] END ...............C=0.001, penalty=l2;, score=0.998 total time= 8.8min\n",
      "[CV 1/5] END ................C=0.01, penalty=l1;, score=0.998 total time= 9.6min\n",
      "[CV 2/5] END ................C=0.01, penalty=l1;, score=0.998 total time= 9.6min\n",
      "[CV 3/5] END ................C=0.01, penalty=l1;, score=0.998 total time= 9.6min\n",
      "[CV 4/5] END ................C=0.01, penalty=l1;, score=0.998 total time= 9.6min\n",
      "[CV 5/5] END ................C=0.01, penalty=l1;, score=0.998 total time= 9.6min\n",
      "[CV 1/5] END ................C=0.01, penalty=l2;, score=0.998 total time= 8.8min\n",
      "[CV 2/5] END ................C=0.01, penalty=l2;, score=0.998 total time= 8.8min\n",
      "[CV 3/5] END ................C=0.01, penalty=l2;, score=0.998 total time= 8.8min\n",
      "[CV 4/5] END ................C=0.01, penalty=l2;, score=0.998 total time= 8.8min\n",
      "[CV 5/5] END ................C=0.01, penalty=l2;, score=0.998 total time= 8.8min\n",
      "[CV 1/5] END .................C=0.1, penalty=l1;, score=0.998 total time= 9.8min\n",
      "[CV 2/5] END .................C=0.1, penalty=l1;, score=0.998 total time= 9.8min\n",
      "[CV 3/5] END .................C=0.1, penalty=l1;, score=0.998 total time= 9.8min\n",
      "[CV 4/5] END .................C=0.1, penalty=l1;, score=0.998 total time= 9.8min\n",
      "[CV 5/5] END .................C=0.1, penalty=l1;, score=0.998 total time= 9.9min\n",
      "[CV 1/5] END .................C=0.1, penalty=l2;, score=0.998 total time= 8.8min\n",
      "[CV 2/5] END .................C=0.1, penalty=l2;, score=0.998 total time= 8.8min\n",
      "[CV 3/5] END .................C=0.1, penalty=l2;, score=0.998 total time= 8.8min\n",
      "[CV 4/5] END .................C=0.1, penalty=l2;, score=0.998 total time= 8.8min\n",
      "[CV 5/5] END .................C=0.1, penalty=l2;, score=0.998 total time= 8.8min\n",
      "[CV 1/5] END .................C=1.0, penalty=l1;, score=0.998 total time= 9.8min\n",
      "[CV 2/5] END .................C=1.0, penalty=l1;, score=0.998 total time= 9.9min\n",
      "[CV 3/5] END .................C=1.0, penalty=l1;, score=0.998 total time= 9.8min\n",
      "[CV 4/5] END .................C=1.0, penalty=l1;, score=0.998 total time= 9.8min\n",
      "[CV 5/5] END .................C=1.0, penalty=l1;, score=0.998 total time= 9.9min\n",
      "[CV 1/5] END .................C=1.0, penalty=l2;, score=0.998 total time= 8.8min\n",
      "[CV 2/5] END .................C=1.0, penalty=l2;, score=0.998 total time= 8.8min\n",
      "[CV 3/5] END .................C=1.0, penalty=l2;, score=0.998 total time= 8.8min\n",
      "[CV 4/5] END .................C=1.0, penalty=l2;, score=0.998 total time= 8.8min\n",
      "[CV 5/5] END .................C=1.0, penalty=l2;, score=0.998 total time= 8.8min\n",
      "[CV 1/5] END ................C=10.0, penalty=l1;, score=0.998 total time= 9.9min\n",
      "[CV 2/5] END ................C=10.0, penalty=l1;, score=0.998 total time= 9.9min\n",
      "[CV 3/5] END ................C=10.0, penalty=l1;, score=0.998 total time= 9.9min\n",
      "[CV 4/5] END ................C=10.0, penalty=l1;, score=0.998 total time= 9.9min\n",
      "[CV 5/5] END ................C=10.0, penalty=l1;, score=0.998 total time= 9.9min\n",
      "[CV 1/5] END ................C=10.0, penalty=l2;, score=0.998 total time= 8.8min\n",
      "[CV 2/5] END ................C=10.0, penalty=l2;, score=0.998 total time= 8.9min\n",
      "[CV 3/5] END ................C=10.0, penalty=l2;, score=0.998 total time= 8.8min\n",
      "[CV 4/5] END ................C=10.0, penalty=l2;, score=0.998 total time= 8.8min\n",
      "[CV 5/5] END ................C=10.0, penalty=l2;, score=0.998 total time= 8.9min\n",
      "[CV 1/5] END ...............C=100.0, penalty=l1;, score=0.998 total time= 9.9min\n",
      "[CV 2/5] END ...............C=100.0, penalty=l1;, score=0.998 total time= 9.9min\n",
      "[CV 3/5] END ...............C=100.0, penalty=l1;, score=0.998 total time= 9.9min\n",
      "[CV 4/5] END ...............C=100.0, penalty=l1;, score=0.998 total time=11.9min\n",
      "[CV 5/5] END ...............C=100.0, penalty=l1;, score=0.998 total time=10.3min\n",
      "[CV 1/5] END ...............C=100.0, penalty=l2;, score=0.998 total time= 8.3min\n",
      "[CV 2/5] END ...............C=100.0, penalty=l2;, score=0.998 total time= 8.2min\n",
      "[CV 3/5] END ...............C=100.0, penalty=l2;, score=0.998 total time= 8.1min\n",
      "[CV 4/5] END ...............C=100.0, penalty=l2;, score=0.998 total time= 8.1min\n",
      "[CV 5/5] END ...............C=100.0, penalty=l2;, score=0.998 total time= 8.1min\n",
      "[CV 1/5] END ..............C=1000.0, penalty=l1;, score=0.998 total time= 9.3min\n",
      "[CV 2/5] END ..............C=1000.0, penalty=l1;, score=0.998 total time= 9.5min\n",
      "[CV 3/5] END ..............C=1000.0, penalty=l1;, score=0.998 total time= 9.4min\n",
      "[CV 4/5] END ..............C=1000.0, penalty=l1;, score=0.998 total time= 9.4min\n",
      "[CV 5/5] END ..............C=1000.0, penalty=l1;, score=0.998 total time= 9.4min\n",
      "[CV 1/5] END ..............C=1000.0, penalty=l2;, score=0.998 total time= 8.3min\n",
      "[CV 2/5] END ..............C=1000.0, penalty=l2;, score=0.998 total time= 8.4min\n",
      "[CV 3/5] END ..............C=1000.0, penalty=l2;, score=0.998 total time= 8.4min\n",
      "[CV 4/5] END ..............C=1000.0, penalty=l2;, score=0.998 total time= 8.3min\n",
      "[CV 5/5] END ..............C=1000.0, penalty=l2;, score=0.998 total time= 8.3min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=1000, solver='saga'),\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run grid search only on training set using cross-validation\n",
    "parameters={'C':np.logspace(-3,3,7), 'penalty':[\"l1\",\"l2\"]}# l1 lasso l2 ridge\n",
    "model2=GridSearchCV(LogisticRegression(solver='saga' ,max_iter=1000),parameters,cv=5, verbose=3)\n",
    "model2.fit(X_smote,y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'C': 10.0, 'penalty': 'l2'}\n",
      "accuracy : 0.9982487577159127\n",
      "Best Model: LogisticRegression(C=10.0, max_iter=1000, solver='saga')\n"
     ]
    }
   ],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",model2.best_params_)\n",
    "print(\"accuracy :\",model2.best_score_)\n",
    "print('Best Model:',model2.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2=model2.predict(df_X_test_stand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      1.00      1.00    110630\n",
      "     class 1       0.14      0.77      0.24        56\n",
      "\n",
      "    accuracy                           1.00    110686\n",
      "   macro avg       0.57      0.88      0.62    110686\n",
      "weighted avg       1.00      1.00      1.00    110686\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#performance results\n",
    "print(classification_report(y_test, y_pred2, target_names=target_names))\n",
    "plot_confusion_matrix(model2, df_X_test_stand, y_test, display_labels=target_names,cmap=plt.cm.Blues); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Weighted Decision Tree (W-DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 1/5] END .......criterion=gini, max_depth=2;, score=0.996 total time=   0.9s\n",
      "[CV 2/5] END .......criterion=gini, max_depth=2;, score=0.997 total time=   0.8s\n",
      "[CV 3/5] END .......criterion=gini, max_depth=2;, score=0.996 total time=   0.7s\n",
      "[CV 4/5] END .......criterion=gini, max_depth=2;, score=0.999 total time=   0.7s\n",
      "[CV 5/5] END .......criterion=gini, max_depth=2;, score=0.997 total time=   0.7s\n",
      "[CV 1/5] END .......criterion=gini, max_depth=4;, score=1.000 total time=   0.8s\n",
      "[CV 2/5] END .......criterion=gini, max_depth=4;, score=1.000 total time=   0.7s\n",
      "[CV 3/5] END .......criterion=gini, max_depth=4;, score=1.000 total time=   0.8s\n",
      "[CV 4/5] END .......criterion=gini, max_depth=4;, score=1.000 total time=   0.7s\n",
      "[CV 5/5] END .......criterion=gini, max_depth=4;, score=0.998 total time=   0.7s\n",
      "[CV 1/5] END .......criterion=gini, max_depth=6;, score=1.000 total time=   0.7s\n",
      "[CV 2/5] END .......criterion=gini, max_depth=6;, score=1.000 total time=   0.7s\n",
      "[CV 3/5] END .......criterion=gini, max_depth=6;, score=1.000 total time=   0.7s\n",
      "[CV 4/5] END .......criterion=gini, max_depth=6;, score=1.000 total time=   0.7s\n",
      "[CV 5/5] END .......criterion=gini, max_depth=6;, score=1.000 total time=   0.7s\n",
      "[CV 1/5] END .......criterion=gini, max_depth=8;, score=1.000 total time=   0.7s\n",
      "[CV 2/5] END .......criterion=gini, max_depth=8;, score=1.000 total time=   0.7s\n",
      "[CV 3/5] END .......criterion=gini, max_depth=8;, score=1.000 total time=   0.8s\n",
      "[CV 4/5] END .......criterion=gini, max_depth=8;, score=1.000 total time=   0.7s\n",
      "[CV 5/5] END .......criterion=gini, max_depth=8;, score=1.000 total time=   0.7s\n",
      "[CV 1/5] END ......criterion=gini, max_depth=10;, score=1.000 total time=   0.8s\n",
      "[CV 2/5] END ......criterion=gini, max_depth=10;, score=1.000 total time=   0.7s\n",
      "[CV 3/5] END ......criterion=gini, max_depth=10;, score=1.000 total time=   0.8s\n",
      "[CV 4/5] END ......criterion=gini, max_depth=10;, score=1.000 total time=   0.7s\n",
      "[CV 5/5] END ......criterion=gini, max_depth=10;, score=1.000 total time=   0.8s\n",
      "[CV 1/5] END ......criterion=gini, max_depth=12;, score=1.000 total time=   0.7s\n",
      "[CV 2/5] END ......criterion=gini, max_depth=12;, score=1.000 total time=   0.7s\n",
      "[CV 3/5] END ......criterion=gini, max_depth=12;, score=1.000 total time=   0.7s\n",
      "[CV 4/5] END ......criterion=gini, max_depth=12;, score=1.000 total time=   0.7s\n",
      "[CV 5/5] END ......criterion=gini, max_depth=12;, score=1.000 total time=   0.7s\n",
      "[CV 1/5] END ....criterion=entropy, max_depth=2;, score=0.996 total time=   0.9s\n",
      "[CV 2/5] END ....criterion=entropy, max_depth=2;, score=0.997 total time=   0.9s\n",
      "[CV 3/5] END ....criterion=entropy, max_depth=2;, score=0.996 total time=   0.9s\n",
      "[CV 4/5] END ....criterion=entropy, max_depth=2;, score=0.999 total time=   0.9s\n",
      "[CV 5/5] END ....criterion=entropy, max_depth=2;, score=0.996 total time=   0.9s\n",
      "[CV 1/5] END ....criterion=entropy, max_depth=4;, score=1.000 total time=   0.9s\n",
      "[CV 2/5] END ....criterion=entropy, max_depth=4;, score=1.000 total time=   0.9s\n",
      "[CV 3/5] END ....criterion=entropy, max_depth=4;, score=1.000 total time=   0.9s\n",
      "[CV 4/5] END ....criterion=entropy, max_depth=4;, score=0.999 total time=   0.9s\n",
      "[CV 5/5] END ....criterion=entropy, max_depth=4;, score=0.999 total time=   0.9s\n",
      "[CV 1/5] END ....criterion=entropy, max_depth=6;, score=1.000 total time=   0.9s\n",
      "[CV 2/5] END ....criterion=entropy, max_depth=6;, score=1.000 total time=   0.9s\n",
      "[CV 3/5] END ....criterion=entropy, max_depth=6;, score=1.000 total time=   0.9s\n",
      "[CV 4/5] END ....criterion=entropy, max_depth=6;, score=1.000 total time=   0.8s\n",
      "[CV 5/5] END ....criterion=entropy, max_depth=6;, score=1.000 total time=   0.8s\n",
      "[CV 1/5] END ....criterion=entropy, max_depth=8;, score=1.000 total time=   0.9s\n",
      "[CV 2/5] END ....criterion=entropy, max_depth=8;, score=1.000 total time=   0.9s\n",
      "[CV 3/5] END ....criterion=entropy, max_depth=8;, score=1.000 total time=   0.9s\n",
      "[CV 4/5] END ....criterion=entropy, max_depth=8;, score=1.000 total time=   0.8s\n",
      "[CV 5/5] END ....criterion=entropy, max_depth=8;, score=1.000 total time=   0.8s\n",
      "[CV 1/5] END ...criterion=entropy, max_depth=10;, score=1.000 total time=   0.9s\n",
      "[CV 2/5] END ...criterion=entropy, max_depth=10;, score=1.000 total time=   0.8s\n",
      "[CV 3/5] END ...criterion=entropy, max_depth=10;, score=1.000 total time=   0.8s\n",
      "[CV 4/5] END ...criterion=entropy, max_depth=10;, score=1.000 total time=   0.9s\n",
      "[CV 5/5] END ...criterion=entropy, max_depth=10;, score=1.000 total time=   0.8s\n",
      "[CV 1/5] END ...criterion=entropy, max_depth=12;, score=1.000 total time=   0.8s\n",
      "[CV 2/5] END ...criterion=entropy, max_depth=12;, score=1.000 total time=   0.9s\n",
      "[CV 3/5] END ...criterion=entropy, max_depth=12;, score=1.000 total time=   0.9s\n",
      "[CV 4/5] END ...criterion=entropy, max_depth=12;, score=1.000 total time=   0.8s\n",
      "[CV 5/5] END ...criterion=entropy, max_depth=12;, score=1.000 total time=   0.9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(class_weight='balanced'),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [2, 4, 6, 8, 10, 12]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run grid search only on training set using cross-validation\n",
    "parameters = {'criterion':['gini','entropy'], 'max_depth' : [2,4,6,8,10,12]}\n",
    "model3 = GridSearchCV(DecisionTreeClassifier(class_weight='balanced'), parameters, cv=5, verbose=3)\n",
    "# fit on the trainning dataset\n",
    "model3.fit(df_X_train_stand, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'criterion': 'entropy', 'max_depth': 8}\n",
      "accuracy : 0.9999706377004973\n",
      "Best Model: DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=8)\n"
     ]
    }
   ],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",model3.best_params_)\n",
    "print(\"accuracy :\",model3.best_score_)\n",
    "print('Best Model:',model3.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = model3.predict(df_X_test_stand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      1.00      1.00    110630\n",
      "     class 1       0.90      0.16      0.27        56\n",
      "\n",
      "    accuracy                           1.00    110686\n",
      "   macro avg       0.95      0.58      0.64    110686\n",
      "weighted avg       1.00      1.00      1.00    110686\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#performance results\n",
    "print(classification_report(y_test, y_pred3, target_names=target_names))\n",
    "plot_confusion_matrix(model3, df_X_test_stand, y_test, display_labels=target_names,cmap=plt.cm.Blues);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling using OSS\n",
    "OneSidedSelection (OSS) is an undersampling technique that combines Tomek Links and the Condensed Nearest Neighbor (CNN) Rule. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "from imblearn.under_sampling import OneSidedSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 51052, 1: 201})\n"
     ]
    }
   ],
   "source": [
    "# define the undersampling method\n",
    "oss = OneSidedSelection(random_state=0)\n",
    "# fit on the trainning dataset\n",
    "X_oss, y_oss = oss.fit_resample(df_X_train_stand, y_train)\n",
    "# summarize the new class distribution\n",
    "counter = Counter(y_oss)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Weighted Support Vector Machine with One Sided Selection (SVM+OSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END ...............................C=1;, score=0.999 total time=   2.0s\n",
      "[CV 2/5] END ...............................C=1;, score=0.999 total time=   2.1s\n",
      "[CV 3/5] END ...............................C=1;, score=0.999 total time=   2.2s\n",
      "[CV 4/5] END ...............................C=1;, score=0.999 total time=   1.2s\n",
      "[CV 5/5] END ...............................C=1;, score=0.998 total time=   2.2s\n",
      "[CV 1/5] END ...............................C=5;, score=0.999 total time=   1.0s\n",
      "[CV 2/5] END ...............................C=5;, score=1.000 total time=   1.0s\n",
      "[CV 3/5] END ...............................C=5;, score=0.999 total time=   0.7s\n",
      "[CV 4/5] END ...............................C=5;, score=0.999 total time=   0.8s\n",
      "[CV 5/5] END ...............................C=5;, score=0.999 total time=   0.8s\n",
      "[CV 1/5] END ..............................C=10;, score=0.999 total time=   0.8s\n",
      "[CV 2/5] END ..............................C=10;, score=1.000 total time=   0.8s\n",
      "[CV 3/5] END ..............................C=10;, score=0.999 total time=   0.5s\n",
      "[CV 4/5] END ..............................C=10;, score=0.999 total time=   0.7s\n",
      "[CV 5/5] END ..............................C=10;, score=0.999 total time=   0.6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(class_weight='balanced'),\n",
       "             param_grid={'C': [1, 5, 10]}, verbose=3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run grid search only on training set using cross-validation\n",
    "parameters = {'C':[1, 5, 10] }\n",
    "model4 = GridSearchCV(SVC(class_weight='balanced', kernel='rbf'), parameters, cv=5, verbose=3)\n",
    "model4.fit(X_oss, y_oss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'C': 10}\n",
      "accuracy : 0.9993756421146301\n",
      "Best Model: SVC(C=10, class_weight='balanced')\n"
     ]
    }
   ],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",model4.best_params_)\n",
    "print(\"accuracy :\",model4.best_score_)\n",
    "print('Best Model:',model4.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred4 = model4.predict(df_X_test_stand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      1.00      1.00    110630\n",
      "     class 1       0.90      0.77      0.83        56\n",
      "\n",
      "    accuracy                           1.00    110686\n",
      "   macro avg       0.95      0.88      0.91    110686\n",
      "weighted avg       1.00      1.00      1.00    110686\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#performance results\n",
    "print(classification_report(y_test, y_pred4, target_names=target_names))\n",
    "plot_confusion_matrix(model4, df_X_test_stand, y_test, display_labels=target_names,cmap=plt.cm.Blues);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e)  XG Boost, Extreme Gradient Boosting (XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=1.000 total time=   6.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=1.000 total time=   6.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=1.000 total time=   6.0s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=1.000 total time=   6.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=1.000 total time=   6.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=150;, score=1.000 total time=   7.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=150;, score=1.000 total time=   7.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=150;, score=1.000 total time=   7.9s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=150;, score=1.000 total time=   7.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=150;, score=1.000 total time=   7.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=100;, score=1.000 total time=   6.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=100;, score=1.000 total time=   6.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=100;, score=1.000 total time=   6.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=100;, score=1.000 total time=   6.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=100;, score=1.000 total time=   6.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=150;, score=1.000 total time=   8.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=150;, score=1.000 total time=   8.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=150;, score=1.000 total time=   8.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=150;, score=1.000 total time=   8.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=150;, score=1.000 total time=   8.3s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=1.000 total time=   4.8s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=1.000 total time=   4.7s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=1.000 total time=   4.8s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=1.000 total time=   4.7s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=1.000 total time=   4.8s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=150;, score=1.000 total time=   6.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=150;, score=1.000 total time=   6.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=150;, score=1.000 total time=   6.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=150;, score=1.000 total time=   5.7s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=150;, score=1.000 total time=   5.9s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=100;, score=1.000 total time=   5.0s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=100;, score=1.000 total time=   5.0s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=100;, score=1.000 total time=   4.8s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=100;, score=1.000 total time=   4.7s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=100;, score=1.000 total time=   5.0s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=150;, score=1.000 total time=   6.3s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=150;, score=1.000 total time=   6.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=150;, score=1.000 total time=   6.2s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=150;, score=1.000 total time=   6.1s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=150;, score=1.000 total time=   6.3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     eval_metric='logloss', gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, random_state=None,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, subsample=None,\n",
       "                                     tree_method=None, use_label_encoder=False,\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             param_grid={'learning_rate': [0.1, 0.2], 'max_depth': [5, 10],\n",
       "                         'n_estimators': [100, 150]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run grid search only on training set using cross-validation\n",
    "parameters = {'max_depth': [5, 10],'n_estimators': [100, 150], 'learning_rate': [0.1, 0.2]}\n",
    "model5 = GridSearchCV(XGBClassifier(eval_metric='logloss',use_label_encoder =False), parameters, cv=5, verbose=3)\n",
    "model5.fit(df_X_train_stand, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 150}\n",
      "accuracy : 0.9999796722463419\n",
      "Best Model: XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, eval_metric='logloss',\n",
      "              gamma=0, gpu_id=-1, importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.1, max_delta_step=0,\n",
      "              max_depth=5, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=150, n_jobs=32,\n",
      "              num_parallel_tree=1, random_state=0, reg_alpha=0, reg_lambda=1,\n",
      "              scale_pos_weight=1, subsample=1, tree_method='exact',\n",
      "              use_label_encoder=False, validate_parameters=1, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",model5.best_params_)\n",
    "print(\"accuracy :\",model5.best_score_)\n",
    "print('Best Model:',model5.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred5 = model5.predict(df_X_test_stand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      1.00      1.00    110630\n",
      "     class 1       1.00      0.11      0.19        56\n",
      "\n",
      "    accuracy                           1.00    110686\n",
      "   macro avg       1.00      0.55      0.60    110686\n",
      "weighted avg       1.00      1.00      1.00    110686\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#performance results\n",
    "print(classification_report(y_test, y_pred5, target_names=target_names))\n",
    "plot_confusion_matrix(model5, df_X_test_stand, y_test, display_labels=target_names,cmap=plt.cm.Blues);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save notebook session\n",
    "import dill\n",
    "dill.dump_session('session_esc-11.db')\n",
    "#to restore a notebook session\n",
    "#dill.load_session('session_esc-11.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
