{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupiter's Notebook for Scenario 04\n",
    "Requieres: [CategoryEncoders](http://contrib.scikit-learn.org/category_encoders/), [imbalanced-learn](https://imbalanced-learn.org/stable/), [XGBoost](https://pypi.org/project/xgboost/), and [dill](https://pypi.org/project/dill/)<br>\n",
    "`pip install category_encoders`<br>\n",
    "`pip install imbalanced-learn`<br>\n",
    "`pip install xgboost`<br>\n",
    "`pip install dill`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To identify class 0 and 1, respectively\n",
    "target_names = ['class 0', 'class 1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "df=pd.read_csv('esc-04-Mixed-traffic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No trunkated \n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(306189, 52)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataset dimensions, number of sessions and features\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 305991, 1: 198})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#counting classes\n",
    "collections.Counter(df.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proto                 0\n",
      "ts                    0\n",
      "srcIP                 0\n",
      "srcPrt                0\n",
      "dstIP                 0\n",
      "dstPrt                0\n",
      "flowduration          0\n",
      "total_fpackets        0\n",
      "total_bpackets        0\n",
      "total_fpktl           0\n",
      "total_bpktl           0\n",
      "min_fpktl             0\n",
      "min_bpktl             0\n",
      "max_fpktl             0\n",
      "max_bpktl             0\n",
      "mean_fpktl            0\n",
      "mean_bpktl            0\n",
      "std_fpktl             0\n",
      "std_bpktl             0\n",
      "total_fipt            0\n",
      "total_bipt            0\n",
      "min_fipt              0\n",
      "min_bipt              0\n",
      "max_fipt              0\n",
      "max_bipt              0\n",
      "mean_fipt             0\n",
      "mean_bipt             0\n",
      "std_fipt              0\n",
      "std_bipt              0\n",
      "fpsh_cnt              0\n",
      "bpsh_cnt              0\n",
      "furg_cnt              0\n",
      "burg_cnt              0\n",
      "total_fhlen           0\n",
      "total_bhlen           0\n",
      "fPktsPerSecond        0\n",
      "bPktsPerSecond        0\n",
      "flowPktsPerSecond     0\n",
      "flowBytesPerSecond    0\n",
      "mean_flowpktl         0\n",
      "std_flowpktl          0\n",
      "mean_flowipt          0\n",
      "std_flowipt           0\n",
      "flow_fin              0\n",
      "flow_syn              0\n",
      "flow_rst              0\n",
      "flow_ack              0\n",
      "flow_urg              0\n",
      "flow_cwr              0\n",
      "flow_ece              0\n",
      "downUpRatio           0\n",
      "label                 0\n",
      "dtype: int64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#check the number of null values\n",
    "print(df.isnull().sum())\n",
    "print(df.isnull().values.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping Rows with NA inplace\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proto                      2\n",
      "ts                    306189\n",
      "srcIP                  11689\n",
      "srcPrt                 55439\n",
      "dstIP                  10472\n",
      "dstPrt                   253\n",
      "flowduration          187275\n",
      "total_fpackets           757\n",
      "total_bpackets           955\n",
      "total_fpktl             8786\n",
      "total_bpktl            17519\n",
      "min_fpktl                129\n",
      "min_bpktl                496\n",
      "max_fpktl               1295\n",
      "max_bpktl                952\n",
      "mean_fpktl             16481\n",
      "mean_bpktl             20690\n",
      "std_fpktl              27150\n",
      "std_bpktl              25898\n",
      "total_fipt             76284\n",
      "total_bipt             59794\n",
      "min_fipt               41025\n",
      "min_bipt               20208\n",
      "max_fipt               74006\n",
      "max_bipt               54941\n",
      "mean_fipt              73547\n",
      "mean_bipt              58506\n",
      "std_fipt               60371\n",
      "std_bipt               52206\n",
      "fpsh_cnt                 152\n",
      "bpsh_cnt                 396\n",
      "furg_cnt                   1\n",
      "burg_cnt                   1\n",
      "total_fhlen             3197\n",
      "total_bhlen             4339\n",
      "fPktsPerSecond        172894\n",
      "bPktsPerSecond        169790\n",
      "flowPktsPerSecond     176347\n",
      "flowBytesPerSecond    221167\n",
      "mean_flowpktl          29061\n",
      "std_flowpktl           42534\n",
      "mean_flowipt          182102\n",
      "std_flowipt            78131\n",
      "flow_fin                  18\n",
      "flow_syn                  13\n",
      "flow_rst                  20\n",
      "flow_ack                1218\n",
      "flow_urg                   1\n",
      "flow_cwr                   2\n",
      "flow_ece                   2\n",
      "downUpRatio            45307\n",
      "label                      2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#sumarize the number of unique values for each column \n",
    "print(df.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete time stamp (ts), srcIP and dstIP features\n",
    "# Models do not learn with IP addresses\n",
    "df.drop(['ts','srcIP','dstIP'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306189, 49)\n"
     ]
    }
   ],
   "source": [
    "#Dataset dimensions, number of sessions and features\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306189, 49)\n",
      "(303784, 49)\n"
     ]
    }
   ],
   "source": [
    "#Delete Rows That Contain Duplicate Data\n",
    "print(df.shape)\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proto</th>\n",
       "      <th>srcPrt</th>\n",
       "      <th>dstPrt</th>\n",
       "      <th>flowduration</th>\n",
       "      <th>total_fpackets</th>\n",
       "      <th>total_bpackets</th>\n",
       "      <th>total_fpktl</th>\n",
       "      <th>total_bpktl</th>\n",
       "      <th>min_fpktl</th>\n",
       "      <th>min_bpktl</th>\n",
       "      <th>max_fpktl</th>\n",
       "      <th>max_bpktl</th>\n",
       "      <th>mean_fpktl</th>\n",
       "      <th>mean_bpktl</th>\n",
       "      <th>std_fpktl</th>\n",
       "      <th>std_bpktl</th>\n",
       "      <th>total_fipt</th>\n",
       "      <th>total_bipt</th>\n",
       "      <th>min_fipt</th>\n",
       "      <th>min_bipt</th>\n",
       "      <th>max_fipt</th>\n",
       "      <th>max_bipt</th>\n",
       "      <th>mean_fipt</th>\n",
       "      <th>mean_bipt</th>\n",
       "      <th>std_fipt</th>\n",
       "      <th>std_bipt</th>\n",
       "      <th>fpsh_cnt</th>\n",
       "      <th>bpsh_cnt</th>\n",
       "      <th>furg_cnt</th>\n",
       "      <th>burg_cnt</th>\n",
       "      <th>total_fhlen</th>\n",
       "      <th>total_bhlen</th>\n",
       "      <th>fPktsPerSecond</th>\n",
       "      <th>bPktsPerSecond</th>\n",
       "      <th>flowPktsPerSecond</th>\n",
       "      <th>flowBytesPerSecond</th>\n",
       "      <th>mean_flowpktl</th>\n",
       "      <th>std_flowpktl</th>\n",
       "      <th>mean_flowipt</th>\n",
       "      <th>std_flowipt</th>\n",
       "      <th>flow_fin</th>\n",
       "      <th>flow_syn</th>\n",
       "      <th>flow_rst</th>\n",
       "      <th>flow_ack</th>\n",
       "      <th>flow_urg</th>\n",
       "      <th>flow_cwr</th>\n",
       "      <th>flow_ece</th>\n",
       "      <th>downUpRatio</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCP</td>\n",
       "      <td>12686</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>54</td>\n",
       "      <td>62</td>\n",
       "      <td>54</td>\n",
       "      <td>62</td>\n",
       "      <td>54</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>71089.898438</td>\n",
       "      <td>71089.898438</td>\n",
       "      <td>142179.796875</td>\n",
       "      <td>8.246428e+06</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCP</td>\n",
       "      <td>59694</td>\n",
       "      <td>80</td>\n",
       "      <td>8.593100</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>923</td>\n",
       "      <td>502</td>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>621</td>\n",
       "      <td>278</td>\n",
       "      <td>153.833328</td>\n",
       "      <td>100.400002</td>\n",
       "      <td>228.865398</td>\n",
       "      <td>99.341837</td>\n",
       "      <td>8.593081</td>\n",
       "      <td>8.593082</td>\n",
       "      <td>0.013070</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>4.817206</td>\n",
       "      <td>5.009996</td>\n",
       "      <td>1.718616</td>\n",
       "      <td>2.148271</td>\n",
       "      <td>2.289094</td>\n",
       "      <td>2.529849</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>108</td>\n",
       "      <td>0.698235</td>\n",
       "      <td>0.581862</td>\n",
       "      <td>1.280097</td>\n",
       "      <td>1.658307e+02</td>\n",
       "      <td>129.545455</td>\n",
       "      <td>175.829102</td>\n",
       "      <td>1.340874</td>\n",
       "      <td>2.130220</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.543879</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCP</td>\n",
       "      <td>54641</td>\n",
       "      <td>80</td>\n",
       "      <td>1.518976</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>682</td>\n",
       "      <td>2313</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>278</td>\n",
       "      <td>1434</td>\n",
       "      <td>97.428574</td>\n",
       "      <td>385.500000</td>\n",
       "      <td>79.680313</td>\n",
       "      <td>556.319243</td>\n",
       "      <td>1.518976</td>\n",
       "      <td>1.160217</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.798060</td>\n",
       "      <td>0.440399</td>\n",
       "      <td>0.253163</td>\n",
       "      <td>0.232043</td>\n",
       "      <td>0.319965</td>\n",
       "      <td>0.214336</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>204</td>\n",
       "      <td>4.608368</td>\n",
       "      <td>3.950030</td>\n",
       "      <td>8.558397</td>\n",
       "      <td>1.971723e+03</td>\n",
       "      <td>230.384615</td>\n",
       "      <td>393.028290</td>\n",
       "      <td>0.163290</td>\n",
       "      <td>0.264648</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.391496</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCP</td>\n",
       "      <td>11449</td>\n",
       "      <td>25</td>\n",
       "      <td>1.114772</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>186</td>\n",
       "      <td>162</td>\n",
       "      <td>62</td>\n",
       "      <td>54</td>\n",
       "      <td>62</td>\n",
       "      <td>54</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.114754</td>\n",
       "      <td>1.114762</td>\n",
       "      <td>0.458319</td>\n",
       "      <td>0.458329</td>\n",
       "      <td>0.656435</td>\n",
       "      <td>0.656433</td>\n",
       "      <td>0.557377</td>\n",
       "      <td>0.557381</td>\n",
       "      <td>0.140089</td>\n",
       "      <td>0.140081</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>60</td>\n",
       "      <td>2.691133</td>\n",
       "      <td>2.691133</td>\n",
       "      <td>5.382266</td>\n",
       "      <td>3.121714e+02</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>4.381781</td>\n",
       "      <td>0.222960</td>\n",
       "      <td>0.313212</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TCP</td>\n",
       "      <td>59695</td>\n",
       "      <td>80</td>\n",
       "      <td>14.950082</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1676</td>\n",
       "      <td>1212</td>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>660</td>\n",
       "      <td>710</td>\n",
       "      <td>209.500000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>276.208513</td>\n",
       "      <td>264.254423</td>\n",
       "      <td>14.950082</td>\n",
       "      <td>7.263925</td>\n",
       "      <td>0.012383</td>\n",
       "      <td>0.004338</td>\n",
       "      <td>7.674953</td>\n",
       "      <td>5.003805</td>\n",
       "      <td>2.135726</td>\n",
       "      <td>1.452785</td>\n",
       "      <td>3.010411</td>\n",
       "      <td>2.200873</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>128</td>\n",
       "      <td>0.535114</td>\n",
       "      <td>0.401336</td>\n",
       "      <td>0.936450</td>\n",
       "      <td>1.931762e+02</td>\n",
       "      <td>206.285714</td>\n",
       "      <td>260.677063</td>\n",
       "      <td>1.519740</td>\n",
       "      <td>2.568937</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.723150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306184</th>\n",
       "      <td>UDP</td>\n",
       "      <td>62204</td>\n",
       "      <td>53</td>\n",
       "      <td>0.270114</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>3.702141</td>\n",
       "      <td>3.702141</td>\n",
       "      <td>7.404283</td>\n",
       "      <td>5.775341e+02</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.270114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306185</th>\n",
       "      <td>UDP</td>\n",
       "      <td>28571</td>\n",
       "      <td>53</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>166</td>\n",
       "      <td>74</td>\n",
       "      <td>166</td>\n",
       "      <td>74</td>\n",
       "      <td>166</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>132</td>\n",
       "      <td>3560.529785</td>\n",
       "      <td>3560.529785</td>\n",
       "      <td>7121.059570</td>\n",
       "      <td>8.545271e+05</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>65.053825</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.243243</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306186</th>\n",
       "      <td>UDP</td>\n",
       "      <td>62218</td>\n",
       "      <td>53</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306187</th>\n",
       "      <td>UDP</td>\n",
       "      <td>62219</td>\n",
       "      <td>53</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306188</th>\n",
       "      <td>UDP</td>\n",
       "      <td>62220</td>\n",
       "      <td>53</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303784 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       proto  srcPrt  dstPrt  flowduration  total_fpackets  total_bpackets  \\\n",
       "0        TCP   12686      25      0.000014               1               1   \n",
       "1        TCP   59694      80      8.593100               6               5   \n",
       "2        TCP   54641      80      1.518976               7               6   \n",
       "3        TCP   11449      25      1.114772               3               3   \n",
       "4        TCP   59695      80     14.950082               8               6   \n",
       "...      ...     ...     ...           ...             ...             ...   \n",
       "306184   UDP   62204      53      0.270114               1               1   \n",
       "306185   UDP   28571      53      0.000281               1               1   \n",
       "306186   UDP   62218      53      0.000000               1               0   \n",
       "306187   UDP   62219      53      0.000000               1               0   \n",
       "306188   UDP   62220      53      0.000000               1               0   \n",
       "\n",
       "        total_fpktl  total_bpktl  min_fpktl  min_bpktl  max_fpktl  max_bpktl  \\\n",
       "0                62           54         62         54         62         54   \n",
       "1               923          502         60         54        621        278   \n",
       "2               682         2313         66         66        278       1434   \n",
       "3               186          162         62         54         62         54   \n",
       "4              1676         1212         60         54        660        710   \n",
       "...             ...          ...        ...        ...        ...        ...   \n",
       "306184           78           78         78         78         78         78   \n",
       "306185           74          166         74        166         74        166   \n",
       "306186           72            0         72          0         72          0   \n",
       "306187           78            0         78          0         78          0   \n",
       "306188           72            0         72          0         72          0   \n",
       "\n",
       "        mean_fpktl  mean_bpktl   std_fpktl   std_bpktl  total_fipt  \\\n",
       "0        62.000000   54.000000    0.000000    0.000000    0.000000   \n",
       "1       153.833328  100.400002  228.865398   99.341837    8.593081   \n",
       "2        97.428574  385.500000   79.680313  556.319243    1.518976   \n",
       "3        62.000000   54.000000    0.000000    0.000000    1.114754   \n",
       "4       209.500000  202.000000  276.208513  264.254423   14.950082   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "306184   78.000000   78.000000    0.000000    0.000000    0.000000   \n",
       "306185   74.000000  166.000000    0.000000    0.000000    0.000000   \n",
       "306186   72.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "306187   78.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "306188   72.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "        total_bipt  min_fipt  min_bipt  max_fipt  max_bipt  mean_fipt  \\\n",
       "0         0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
       "1         8.593082  0.013070  0.010200  4.817206  5.009996   1.718616   \n",
       "2         1.160217  0.000023  0.000013  0.798060  0.440399   0.253163   \n",
       "3         1.114762  0.458319  0.458329  0.656435  0.656433   0.557377   \n",
       "4         7.263925  0.012383  0.004338  7.674953  5.003805   2.135726   \n",
       "...            ...       ...       ...       ...       ...        ...   \n",
       "306184    0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
       "306185    0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
       "306186    0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
       "306187    0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
       "306188    0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
       "\n",
       "        mean_bipt  std_fipt  std_bipt  fpsh_cnt  bpsh_cnt  furg_cnt  burg_cnt  \\\n",
       "0        0.000000  0.000000  0.000000         0         0         0         0   \n",
       "1        2.148271  2.289094  2.529849         1         1         0         0   \n",
       "2        0.232043  0.319965  0.214336         1         1         0         0   \n",
       "3        0.557381  0.140089  0.140081         0         0         0         0   \n",
       "4        1.452785  3.010411  2.200873         2         2         0         0   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "306184   0.000000  0.000000  0.000000         0         0         0         0   \n",
       "306185   0.000000  0.000000  0.000000         0         0         0         0   \n",
       "306186   0.000000  0.000000  0.000000         0         0         0         0   \n",
       "306187   0.000000  0.000000  0.000000         0         0         0         0   \n",
       "306188   0.000000  0.000000  0.000000         0         0         0         0   \n",
       "\n",
       "        total_fhlen  total_bhlen  fPktsPerSecond  bPktsPerSecond  \\\n",
       "0                28           20    71089.898438    71089.898438   \n",
       "1               128          108        0.698235        0.581862   \n",
       "2               232          204        4.608368        3.950030   \n",
       "3                84           60        2.691133        2.691133   \n",
       "4               168          128        0.535114        0.401336   \n",
       "...             ...          ...             ...             ...   \n",
       "306184           44           44        3.702141        3.702141   \n",
       "306185           40          132     3560.529785     3560.529785   \n",
       "306186           38            0        0.000000        0.000000   \n",
       "306187           44            0        0.000000        0.000000   \n",
       "306188           38            0        0.000000        0.000000   \n",
       "\n",
       "        flowPktsPerSecond  flowBytesPerSecond  mean_flowpktl  std_flowpktl  \\\n",
       "0           142179.796875        8.246428e+06      58.000000      5.656854   \n",
       "1                1.280097        1.658307e+02     129.545455    175.829102   \n",
       "2                8.558397        1.971723e+03     230.384615    393.028290   \n",
       "3                5.382266        3.121714e+02      58.000000      4.381781   \n",
       "4                0.936450        1.931762e+02     206.285714    260.677063   \n",
       "...                   ...                 ...            ...           ...   \n",
       "306184           7.404283        5.775341e+02      78.000000      0.000000   \n",
       "306185        7121.059570        8.545271e+05     120.000000     65.053825   \n",
       "306186           0.000000        0.000000e+00      72.000000      0.000000   \n",
       "306187           0.000000        0.000000e+00      78.000000      0.000000   \n",
       "306188           0.000000        0.000000e+00      72.000000      0.000000   \n",
       "\n",
       "        mean_flowipt  std_flowipt  flow_fin  flow_syn  flow_rst  flow_ack  \\\n",
       "0           0.000014     0.000000         0         1         1         1   \n",
       "1           1.340874     2.130220         2         2         0        10   \n",
       "2           0.163290     0.264648         2         2         0        12   \n",
       "3           0.222960     0.313212         0         3         3         3   \n",
       "4           1.519740     2.568937         1         2         1        13   \n",
       "...              ...          ...       ...       ...       ...       ...   \n",
       "306184      0.270114     0.000000         0         0         0         0   \n",
       "306185      0.000281     0.000000         0         0         0         0   \n",
       "306186      0.000000     0.000000         0         0         0         0   \n",
       "306187      0.000000     0.000000         0         0         0         0   \n",
       "306188      0.000000     0.000000         0         0         0         0   \n",
       "\n",
       "        flow_urg  flow_cwr  flow_ece  downUpRatio  label  \n",
       "0              0         0         0     0.870968      0  \n",
       "1              0         0         0     0.543879      0  \n",
       "2              0         0         0     3.391496      0  \n",
       "3              0         0         0     0.870968      0  \n",
       "4              0         0         0     0.723150      0  \n",
       "...          ...       ...       ...          ...    ...  \n",
       "306184         0         0         0     1.000000      0  \n",
       "306185         0         0         0     2.243243      0  \n",
       "306186         0         0         0     0.000000      0  \n",
       "306187         0         0         0     0.000000      0  \n",
       "306188         0         0         0     0.000000      0  \n",
       "\n",
       "[303784 rows x 49 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Class 0 : 303587 of 303784 (99.9%)\n",
      "> Class 1 : 197 of 303784 (0.1%)\n"
     ]
    }
   ],
   "source": [
    "#check % class distribution \n",
    "y=df['label'].values #convert to nparray\n",
    "\n",
    "classes=np.unique(y)\n",
    "total=len(y)\n",
    "\n",
    "for c in classes:\n",
    "    n_examples=len(y[y==c])\n",
    "    percent = n_examples/total*100\n",
    "    print('> Class %d : %d of %d (%.1f%%)' % (c, n_examples,total,percent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(df.drop(columns=['label']), df['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((243027, 48), (60757, 48))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Original dataset dimensions\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding of categorical variables\n",
    "[Target encoding](https://contrib.scikit-learn.org/category_encoders/targetencoder.html) for categorical features will be used to encode three nominal categorical variables: protocol, source and destination ports. This method is supervised and requires training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load library for target encoder \n",
    "from category_encoders import TargetEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "proto                  object\n",
       "srcPrt                  int64\n",
       "dstPrt                  int64\n",
       "flowduration          float64\n",
       "total_fpackets          int64\n",
       "total_bpackets          int64\n",
       "total_fpktl             int64\n",
       "total_bpktl             int64\n",
       "min_fpktl               int64\n",
       "min_bpktl               int64\n",
       "max_fpktl               int64\n",
       "max_bpktl               int64\n",
       "mean_fpktl            float64\n",
       "mean_bpktl            float64\n",
       "std_fpktl             float64\n",
       "std_bpktl             float64\n",
       "total_fipt            float64\n",
       "total_bipt            float64\n",
       "min_fipt              float64\n",
       "min_bipt              float64\n",
       "max_fipt              float64\n",
       "max_bipt              float64\n",
       "mean_fipt             float64\n",
       "mean_bipt             float64\n",
       "std_fipt              float64\n",
       "std_bipt              float64\n",
       "fpsh_cnt                int64\n",
       "bpsh_cnt                int64\n",
       "furg_cnt                int64\n",
       "burg_cnt                int64\n",
       "total_fhlen             int64\n",
       "total_bhlen             int64\n",
       "fPktsPerSecond        float64\n",
       "bPktsPerSecond        float64\n",
       "flowPktsPerSecond     float64\n",
       "flowBytesPerSecond    float64\n",
       "mean_flowpktl         float64\n",
       "std_flowpktl          float64\n",
       "mean_flowipt          float64\n",
       "std_flowipt           float64\n",
       "flow_fin                int64\n",
       "flow_syn                int64\n",
       "flow_rst                int64\n",
       "flow_ack                int64\n",
       "flow_urg                int64\n",
       "flow_cwr                int64\n",
       "flow_ece                int64\n",
       "downUpRatio           float64\n",
       "label                   int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check data types for each feature\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the three categorical variables to be coded\n",
    "enc = TargetEncoder(cols=['proto','srcPrt','dstPrt'])\n",
    "# fit on the trainning dataset\n",
    "enc.fit_transform(X_train, y_train)\n",
    "# Coding categorical variables of the trainning dataset\n",
    "training_numeric_dataset=enc.transform(X_train)\n",
    "# Coding categorical variables of the test dataset\n",
    "testing_numeric_dataset = enc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proto</th>\n",
       "      <th>srcPrt</th>\n",
       "      <th>dstPrt</th>\n",
       "      <th>flowduration</th>\n",
       "      <th>total_fpackets</th>\n",
       "      <th>total_bpackets</th>\n",
       "      <th>total_fpktl</th>\n",
       "      <th>total_bpktl</th>\n",
       "      <th>min_fpktl</th>\n",
       "      <th>min_bpktl</th>\n",
       "      <th>max_fpktl</th>\n",
       "      <th>max_bpktl</th>\n",
       "      <th>mean_fpktl</th>\n",
       "      <th>mean_bpktl</th>\n",
       "      <th>std_fpktl</th>\n",
       "      <th>std_bpktl</th>\n",
       "      <th>total_fipt</th>\n",
       "      <th>total_bipt</th>\n",
       "      <th>min_fipt</th>\n",
       "      <th>min_bipt</th>\n",
       "      <th>max_fipt</th>\n",
       "      <th>max_bipt</th>\n",
       "      <th>mean_fipt</th>\n",
       "      <th>mean_bipt</th>\n",
       "      <th>std_fipt</th>\n",
       "      <th>std_bipt</th>\n",
       "      <th>fpsh_cnt</th>\n",
       "      <th>bpsh_cnt</th>\n",
       "      <th>furg_cnt</th>\n",
       "      <th>burg_cnt</th>\n",
       "      <th>total_fhlen</th>\n",
       "      <th>total_bhlen</th>\n",
       "      <th>fPktsPerSecond</th>\n",
       "      <th>bPktsPerSecond</th>\n",
       "      <th>flowPktsPerSecond</th>\n",
       "      <th>flowBytesPerSecond</th>\n",
       "      <th>mean_flowpktl</th>\n",
       "      <th>std_flowpktl</th>\n",
       "      <th>mean_flowipt</th>\n",
       "      <th>std_flowipt</th>\n",
       "      <th>flow_fin</th>\n",
       "      <th>flow_syn</th>\n",
       "      <th>flow_rst</th>\n",
       "      <th>flow_ack</th>\n",
       "      <th>flow_urg</th>\n",
       "      <th>flow_cwr</th>\n",
       "      <th>flow_ece</th>\n",
       "      <th>downUpRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>276663</th>\n",
       "      <td>0.000085</td>\n",
       "      <td>1.110137e-05</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>136</td>\n",
       "      <td>85</td>\n",
       "      <td>136</td>\n",
       "      <td>85</td>\n",
       "      <td>136</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>136.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>102</td>\n",
       "      <td>6364.649414</td>\n",
       "      <td>6364.649414</td>\n",
       "      <td>12729.298828</td>\n",
       "      <td>1.406588e+06</td>\n",
       "      <td>110.500000</td>\n",
       "      <td>36.062447</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>0.004191</td>\n",
       "      <td>2.927198e-05</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>5.179779</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>1973</td>\n",
       "      <td>27273</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>447</td>\n",
       "      <td>1434</td>\n",
       "      <td>82.208336</td>\n",
       "      <td>1136.375</td>\n",
       "      <td>77.717424</td>\n",
       "      <td>547.202274</td>\n",
       "      <td>5.179779</td>\n",
       "      <td>5.179758</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>4.826879</td>\n",
       "      <td>4.833369</td>\n",
       "      <td>0.225208</td>\n",
       "      <td>0.225207</td>\n",
       "      <td>1.003666</td>\n",
       "      <td>1.005084</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>776</td>\n",
       "      <td>780</td>\n",
       "      <td>4.633402</td>\n",
       "      <td>4.633402</td>\n",
       "      <td>9.266805</td>\n",
       "      <td>5.646187e+03</td>\n",
       "      <td>609.291667</td>\n",
       "      <td>658.189392</td>\n",
       "      <td>0.212943</td>\n",
       "      <td>0.974687</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.823112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128139</th>\n",
       "      <td>0.000085</td>\n",
       "      <td>1.526141e-06</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>3.464763</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>165</td>\n",
       "      <td>78</td>\n",
       "      <td>165</td>\n",
       "      <td>78</td>\n",
       "      <td>165</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>165.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>131</td>\n",
       "      <td>0.288620</td>\n",
       "      <td>0.288620</td>\n",
       "      <td>0.577240</td>\n",
       "      <td>7.013467e+01</td>\n",
       "      <td>121.500000</td>\n",
       "      <td>61.518291</td>\n",
       "      <td>3.464763</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.115385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250078</th>\n",
       "      <td>0.000085</td>\n",
       "      <td>2.927198e-05</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>2.492490</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>77.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>0.401205</td>\n",
       "      <td>0.401205</td>\n",
       "      <td>0.802410</td>\n",
       "      <td>6.178560e+01</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.492490</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156656</th>\n",
       "      <td>0.000085</td>\n",
       "      <td>4.130930e-06</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>368</td>\n",
       "      <td>81</td>\n",
       "      <td>368</td>\n",
       "      <td>81</td>\n",
       "      <td>368</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>368.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>334</td>\n",
       "      <td>2222.736572</td>\n",
       "      <td>2222.736572</td>\n",
       "      <td>4445.473145</td>\n",
       "      <td>9.980088e+05</td>\n",
       "      <td>224.500000</td>\n",
       "      <td>202.939651</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.543210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120616</th>\n",
       "      <td>0.000085</td>\n",
       "      <td>1.110137e-05</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>7.491007</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>158</td>\n",
       "      <td>76</td>\n",
       "      <td>158</td>\n",
       "      <td>76</td>\n",
       "      <td>158</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>158.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>124</td>\n",
       "      <td>0.133493</td>\n",
       "      <td>0.133493</td>\n",
       "      <td>0.266987</td>\n",
       "      <td>3.123746e+01</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>57.982758</td>\n",
       "      <td>7.491007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.078947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261043</th>\n",
       "      <td>0.000085</td>\n",
       "      <td>5.623148e-07</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.898636</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>330</td>\n",
       "      <td>83</td>\n",
       "      <td>330</td>\n",
       "      <td>83</td>\n",
       "      <td>330</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>330.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>296</td>\n",
       "      <td>1.112797</td>\n",
       "      <td>1.112797</td>\n",
       "      <td>2.225595</td>\n",
       "      <td>4.595854e+02</td>\n",
       "      <td>206.500000</td>\n",
       "      <td>174.655380</td>\n",
       "      <td>0.898636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.975904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132766</th>\n",
       "      <td>0.000085</td>\n",
       "      <td>5.623148e-07</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>164</td>\n",
       "      <td>72</td>\n",
       "      <td>164</td>\n",
       "      <td>72</td>\n",
       "      <td>164</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>164.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>130</td>\n",
       "      <td>3771.856201</td>\n",
       "      <td>3771.856201</td>\n",
       "      <td>7543.712402</td>\n",
       "      <td>8.901581e+05</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>65.053825</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147818</th>\n",
       "      <td>0.000085</td>\n",
       "      <td>1.110137e-05</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1.584262</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>454</td>\n",
       "      <td>78</td>\n",
       "      <td>454</td>\n",
       "      <td>78</td>\n",
       "      <td>454</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>454.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>420</td>\n",
       "      <td>0.631209</td>\n",
       "      <td>0.631209</td>\n",
       "      <td>1.262418</td>\n",
       "      <td>3.358031e+02</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>265.872162</td>\n",
       "      <td>1.584262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.820513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122713</th>\n",
       "      <td>0.000085</td>\n",
       "      <td>1.030837e-08</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>136</td>\n",
       "      <td>85</td>\n",
       "      <td>136</td>\n",
       "      <td>85</td>\n",
       "      <td>136</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>136.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>102</td>\n",
       "      <td>5497.122070</td>\n",
       "      <td>5497.122070</td>\n",
       "      <td>10994.244141</td>\n",
       "      <td>1.214864e+06</td>\n",
       "      <td>110.500000</td>\n",
       "      <td>36.062447</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243027 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           proto        srcPrt    dstPrt  flowduration  total_fpackets  \\\n",
       "276663  0.000085  1.110137e-05  0.000009      0.000157               1   \n",
       "1742    0.004191  2.927198e-05  0.000370      5.179779              24   \n",
       "128139  0.000085  1.526141e-06  0.000009      3.464763               1   \n",
       "250078  0.000085  2.927198e-05  0.000009      2.492490               1   \n",
       "156656  0.000085  4.130930e-06  0.000009      0.000450               1   \n",
       "...          ...           ...       ...           ...             ...   \n",
       "120616  0.000085  1.110137e-05  0.000009      7.491007               1   \n",
       "261043  0.000085  5.623148e-07  0.000009      0.898636               1   \n",
       "132766  0.000085  5.623148e-07  0.000009      0.000265               1   \n",
       "147818  0.000085  1.110137e-05  0.000009      1.584262               1   \n",
       "122713  0.000085  1.030837e-08  0.000009      0.000182               1   \n",
       "\n",
       "        total_bpackets  total_fpktl  total_bpktl  min_fpktl  min_bpktl  \\\n",
       "276663               1           85          136         85        136   \n",
       "1742                24         1973        27273         66         66   \n",
       "128139               1           78          165         78        165   \n",
       "250078               1           77           77         77         77   \n",
       "156656               1           81          368         81        368   \n",
       "...                ...          ...          ...        ...        ...   \n",
       "120616               1           76          158         76        158   \n",
       "261043               1           83          330         83        330   \n",
       "132766               1           72          164         72        164   \n",
       "147818               1           78          454         78        454   \n",
       "122713               1           85          136         85        136   \n",
       "\n",
       "        max_fpktl  max_bpktl  mean_fpktl  mean_bpktl  std_fpktl   std_bpktl  \\\n",
       "276663         85        136   85.000000     136.000   0.000000    0.000000   \n",
       "1742          447       1434   82.208336    1136.375  77.717424  547.202274   \n",
       "128139         78        165   78.000000     165.000   0.000000    0.000000   \n",
       "250078         77         77   77.000000      77.000   0.000000    0.000000   \n",
       "156656         81        368   81.000000     368.000   0.000000    0.000000   \n",
       "...           ...        ...         ...         ...        ...         ...   \n",
       "120616         76        158   76.000000     158.000   0.000000    0.000000   \n",
       "261043         83        330   83.000000     330.000   0.000000    0.000000   \n",
       "132766         72        164   72.000000     164.000   0.000000    0.000000   \n",
       "147818         78        454   78.000000     454.000   0.000000    0.000000   \n",
       "122713         85        136   85.000000     136.000   0.000000    0.000000   \n",
       "\n",
       "        total_fipt  total_bipt  min_fipt  min_bipt  max_fipt  max_bipt  \\\n",
       "276663    0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1742      5.179779    5.179758  0.000012  0.000008  4.826879  4.833369   \n",
       "128139    0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "250078    0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "156656    0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "...            ...         ...       ...       ...       ...       ...   \n",
       "120616    0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "261043    0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "132766    0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "147818    0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "122713    0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "        mean_fipt  mean_bipt  std_fipt  std_bipt  fpsh_cnt  bpsh_cnt  \\\n",
       "276663   0.000000   0.000000  0.000000  0.000000         0         0   \n",
       "1742     0.225208   0.225207  1.003666  1.005084         1         4   \n",
       "128139   0.000000   0.000000  0.000000  0.000000         0         0   \n",
       "250078   0.000000   0.000000  0.000000  0.000000         0         0   \n",
       "156656   0.000000   0.000000  0.000000  0.000000         0         0   \n",
       "...           ...        ...       ...       ...       ...       ...   \n",
       "120616   0.000000   0.000000  0.000000  0.000000         0         0   \n",
       "261043   0.000000   0.000000  0.000000  0.000000         0         0   \n",
       "132766   0.000000   0.000000  0.000000  0.000000         0         0   \n",
       "147818   0.000000   0.000000  0.000000  0.000000         0         0   \n",
       "122713   0.000000   0.000000  0.000000  0.000000         0         0   \n",
       "\n",
       "        furg_cnt  burg_cnt  total_fhlen  total_bhlen  fPktsPerSecond  \\\n",
       "276663         0         0           51          102     6364.649414   \n",
       "1742           0         0          776          780        4.633402   \n",
       "128139         0         0           44          131        0.288620   \n",
       "250078         0         0           43           43        0.401205   \n",
       "156656         0         0           47          334     2222.736572   \n",
       "...          ...       ...          ...          ...             ...   \n",
       "120616         0         0           42          124        0.133493   \n",
       "261043         0         0           49          296        1.112797   \n",
       "132766         0         0           38          130     3771.856201   \n",
       "147818         0         0           44          420        0.631209   \n",
       "122713         0         0           51          102     5497.122070   \n",
       "\n",
       "        bPktsPerSecond  flowPktsPerSecond  flowBytesPerSecond  mean_flowpktl  \\\n",
       "276663     6364.649414       12729.298828        1.406588e+06     110.500000   \n",
       "1742          4.633402           9.266805        5.646187e+03     609.291667   \n",
       "128139        0.288620           0.577240        7.013467e+01     121.500000   \n",
       "250078        0.401205           0.802410        6.178560e+01      77.000000   \n",
       "156656     2222.736572        4445.473145        9.980088e+05     224.500000   \n",
       "...                ...                ...                 ...            ...   \n",
       "120616        0.133493           0.266987        3.123746e+01     117.000000   \n",
       "261043        1.112797           2.225595        4.595854e+02     206.500000   \n",
       "132766     3771.856201        7543.712402        8.901581e+05     118.000000   \n",
       "147818        0.631209           1.262418        3.358031e+02     266.000000   \n",
       "122713     5497.122070       10994.244141        1.214864e+06     110.500000   \n",
       "\n",
       "        std_flowpktl  mean_flowipt  std_flowipt  flow_fin  flow_syn  flow_rst  \\\n",
       "276663     36.062447      0.000157     0.000000         0         0         0   \n",
       "1742      658.189392      0.212943     0.974687         2         2         0   \n",
       "128139     61.518291      3.464763     0.000000         0         0         0   \n",
       "250078      0.000000      2.492490     0.000000         0         0         0   \n",
       "156656    202.939651      0.000450     0.000000         0         0         0   \n",
       "...              ...           ...          ...       ...       ...       ...   \n",
       "120616     57.982758      7.491007     0.000000         0         0         0   \n",
       "261043    174.655380      0.898636     0.000000         0         0         0   \n",
       "132766     65.053825      0.000265     0.000000         0         0         0   \n",
       "147818    265.872162      1.584262     0.000000         0         0         0   \n",
       "122713     36.062447      0.000182     0.000000         0         0         0   \n",
       "\n",
       "        flow_ack  flow_urg  flow_cwr  flow_ece  downUpRatio  \n",
       "276663         0         0         0         0     1.600000  \n",
       "1742          47         0         0         0    13.823112  \n",
       "128139         0         0         0         0     2.115385  \n",
       "250078         0         0         0         0     1.000000  \n",
       "156656         0         0         0         0     4.543210  \n",
       "...          ...       ...       ...       ...          ...  \n",
       "120616         0         0         0         0     2.078947  \n",
       "261043         0         0         0         0     3.975904  \n",
       "132766         0         0         0         0     2.277778  \n",
       "147818         0         0         0         0     5.820513  \n",
       "122713         0         0         0         0     1.600000  \n",
       "\n",
       "[243027 rows x 48 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show trainning dataset\n",
    "training_numeric_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proto</th>\n",
       "      <th>srcPrt</th>\n",
       "      <th>dstPrt</th>\n",
       "      <th>flowduration</th>\n",
       "      <th>total_fpackets</th>\n",
       "      <th>total_bpackets</th>\n",
       "      <th>total_fpktl</th>\n",
       "      <th>total_bpktl</th>\n",
       "      <th>min_fpktl</th>\n",
       "      <th>min_bpktl</th>\n",
       "      <th>max_fpktl</th>\n",
       "      <th>max_bpktl</th>\n",
       "      <th>mean_fpktl</th>\n",
       "      <th>mean_bpktl</th>\n",
       "      <th>std_fpktl</th>\n",
       "      <th>std_bpktl</th>\n",
       "      <th>total_fipt</th>\n",
       "      <th>total_bipt</th>\n",
       "      <th>min_fipt</th>\n",
       "      <th>min_bipt</th>\n",
       "      <th>max_fipt</th>\n",
       "      <th>max_bipt</th>\n",
       "      <th>mean_fipt</th>\n",
       "      <th>mean_bipt</th>\n",
       "      <th>std_fipt</th>\n",
       "      <th>std_bipt</th>\n",
       "      <th>fpsh_cnt</th>\n",
       "      <th>bpsh_cnt</th>\n",
       "      <th>furg_cnt</th>\n",
       "      <th>burg_cnt</th>\n",
       "      <th>total_fhlen</th>\n",
       "      <th>total_bhlen</th>\n",
       "      <th>fPktsPerSecond</th>\n",
       "      <th>bPktsPerSecond</th>\n",
       "      <th>flowPktsPerSecond</th>\n",
       "      <th>flowBytesPerSecond</th>\n",
       "      <th>mean_flowpktl</th>\n",
       "      <th>std_flowpktl</th>\n",
       "      <th>mean_flowipt</th>\n",
       "      <th>std_flowipt</th>\n",
       "      <th>flow_fin</th>\n",
       "      <th>flow_syn</th>\n",
       "      <th>flow_rst</th>\n",
       "      <th>flow_ack</th>\n",
       "      <th>flow_urg</th>\n",
       "      <th>flow_cwr</th>\n",
       "      <th>flow_ece</th>\n",
       "      <th>downUpRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>184211</th>\n",
       "      <td>0.000085</td>\n",
       "      <td>1.110137e-05</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>8.869140</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>377</td>\n",
       "      <td>65</td>\n",
       "      <td>377</td>\n",
       "      <td>65</td>\n",
       "      <td>377</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>343</td>\n",
       "      <td>0.112751</td>\n",
       "      <td>0.112751</td>\n",
       "      <td>0.225501</td>\n",
       "      <td>4.983572e+01</td>\n",
       "      <td>221.0</td>\n",
       "      <td>220.617310</td>\n",
       "      <td>8.869140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251384</th>\n",
       "      <td>0.000085</td>\n",
       "      <td>1.526141e-06</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>138</td>\n",
       "      <td>74</td>\n",
       "      <td>138</td>\n",
       "      <td>74</td>\n",
       "      <td>138</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>104</td>\n",
       "      <td>4975.449707</td>\n",
       "      <td>4975.449707</td>\n",
       "      <td>9950.899414</td>\n",
       "      <td>1.054795e+06</td>\n",
       "      <td>106.0</td>\n",
       "      <td>45.254833</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.864865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47615</th>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>2.080990</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>176</td>\n",
       "      <td>218</td>\n",
       "      <td>87</td>\n",
       "      <td>94</td>\n",
       "      <td>89</td>\n",
       "      <td>124</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>21.213203</td>\n",
       "      <td>1.885896</td>\n",
       "      <td>1.885538</td>\n",
       "      <td>1.885896</td>\n",
       "      <td>1.885538</td>\n",
       "      <td>1.885896</td>\n",
       "      <td>1.885538</td>\n",
       "      <td>1.885896</td>\n",
       "      <td>1.885538</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>150</td>\n",
       "      <td>0.961081</td>\n",
       "      <td>0.961081</td>\n",
       "      <td>1.922162</td>\n",
       "      <td>1.893330e+02</td>\n",
       "      <td>98.5</td>\n",
       "      <td>17.253019</td>\n",
       "      <td>0.758814</td>\n",
       "      <td>0.976082</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.238636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71252</th>\n",
       "      <td>0.000085</td>\n",
       "      <td>1.659948e-04</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.189192</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>5.285634</td>\n",
       "      <td>5.285634</td>\n",
       "      <td>10.571268</td>\n",
       "      <td>7.822739e+02</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.189192</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80679</th>\n",
       "      <td>0.000085</td>\n",
       "      <td>4.130930e-06</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>189</td>\n",
       "      <td>77</td>\n",
       "      <td>189</td>\n",
       "      <td>77</td>\n",
       "      <td>189</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>155</td>\n",
       "      <td>3472.105957</td>\n",
       "      <td>3472.105957</td>\n",
       "      <td>6944.211914</td>\n",
       "      <td>9.235802e+05</td>\n",
       "      <td>133.0</td>\n",
       "      <td>79.195961</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149416</th>\n",
       "      <td>0.000085</td>\n",
       "      <td>5.623148e-07</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>2.154643</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>0.464114</td>\n",
       "      <td>0.464114</td>\n",
       "      <td>0.928228</td>\n",
       "      <td>7.147356e+01</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.154643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231098</th>\n",
       "      <td>0.000085</td>\n",
       "      <td>2.927198e-05</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>3310.421387</td>\n",
       "      <td>3310.421387</td>\n",
       "      <td>6620.842773</td>\n",
       "      <td>4.369756e+05</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143182</th>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.607321</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>195</td>\n",
       "      <td>93</td>\n",
       "      <td>195</td>\n",
       "      <td>93</td>\n",
       "      <td>195</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>161</td>\n",
       "      <td>1.646576</td>\n",
       "      <td>1.646576</td>\n",
       "      <td>3.293151</td>\n",
       "      <td>4.742138e+02</td>\n",
       "      <td>144.0</td>\n",
       "      <td>72.124893</td>\n",
       "      <td>0.607321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.096774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14919</th>\n",
       "      <td>0.004191</td>\n",
       "      <td>2.802026e-08</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>6.046401</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>1078</td>\n",
       "      <td>8928</td>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>592</td>\n",
       "      <td>1434</td>\n",
       "      <td>119.777779</td>\n",
       "      <td>811.636353</td>\n",
       "      <td>177.094451</td>\n",
       "      <td>715.134000</td>\n",
       "      <td>6.046394</td>\n",
       "      <td>6.046384</td>\n",
       "      <td>0.003346</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>4.316473</td>\n",
       "      <td>4.311941</td>\n",
       "      <td>0.755799</td>\n",
       "      <td>0.604638</td>\n",
       "      <td>1.45309</td>\n",
       "      <td>1.323535</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "      <td>232</td>\n",
       "      <td>1.488489</td>\n",
       "      <td>1.819264</td>\n",
       "      <td>3.307753</td>\n",
       "      <td>1.654869e+03</td>\n",
       "      <td>500.3</td>\n",
       "      <td>638.026306</td>\n",
       "      <td>0.523668</td>\n",
       "      <td>1.274822</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.282003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243587</th>\n",
       "      <td>0.000085</td>\n",
       "      <td>1.659948e-04</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>138</td>\n",
       "      <td>74</td>\n",
       "      <td>138</td>\n",
       "      <td>74</td>\n",
       "      <td>138</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>104</td>\n",
       "      <td>2809.312744</td>\n",
       "      <td>2809.312744</td>\n",
       "      <td>5618.625488</td>\n",
       "      <td>5.955743e+05</td>\n",
       "      <td>106.0</td>\n",
       "      <td>45.254833</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.864865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60757 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           proto        srcPrt    dstPrt  flowduration  total_fpackets  \\\n",
       "184211  0.000085  1.110137e-05  0.000009      8.869140               1   \n",
       "251384  0.000085  1.526141e-06  0.000009      0.000201               1   \n",
       "47615   0.000085  0.000000e+00  0.000009      2.080990               2   \n",
       "71252   0.000085  1.659948e-04  0.000009      0.189192               1   \n",
       "80679   0.000085  4.130930e-06  0.000009      0.000288               1   \n",
       "...          ...           ...       ...           ...             ...   \n",
       "149416  0.000085  5.623148e-07  0.000009      2.154643               1   \n",
       "231098  0.000085  2.927198e-05  0.000009      0.000302               1   \n",
       "143182  0.000085  0.000000e+00  0.000009      0.607321               1   \n",
       "14919   0.004191  2.802026e-08  0.000370      6.046401               9   \n",
       "243587  0.000085  1.659948e-04  0.000009      0.000356               1   \n",
       "\n",
       "        total_bpackets  total_fpktl  total_bpktl  min_fpktl  min_bpktl  \\\n",
       "184211               1           65          377         65        377   \n",
       "251384               1           74          138         74        138   \n",
       "47615                2          176          218         87         94   \n",
       "71252                1           74           74         74         74   \n",
       "80679                1           77          189         77        189   \n",
       "...                ...          ...          ...        ...        ...   \n",
       "149416               1           77           77         77         77   \n",
       "231098               1           66           66         66         66   \n",
       "143182               1           93          195         93        195   \n",
       "14919               11         1078         8928         60         54   \n",
       "243587               1           74          138         74        138   \n",
       "\n",
       "        max_fpktl  max_bpktl  mean_fpktl  mean_bpktl   std_fpktl   std_bpktl  \\\n",
       "184211         65        377   65.000000  377.000000    0.000000    0.000000   \n",
       "251384         74        138   74.000000  138.000000    0.000000    0.000000   \n",
       "47615          89        124   88.000000  109.000000    1.414214   21.213203   \n",
       "71252          74         74   74.000000   74.000000    0.000000    0.000000   \n",
       "80679          77        189   77.000000  189.000000    0.000000    0.000000   \n",
       "...           ...        ...         ...         ...         ...         ...   \n",
       "149416         77         77   77.000000   77.000000    0.000000    0.000000   \n",
       "231098         66         66   66.000000   66.000000    0.000000    0.000000   \n",
       "143182         93        195   93.000000  195.000000    0.000000    0.000000   \n",
       "14919         592       1434  119.777779  811.636353  177.094451  715.134000   \n",
       "243587         74        138   74.000000  138.000000    0.000000    0.000000   \n",
       "\n",
       "        total_fipt  total_bipt  min_fipt  min_bipt  max_fipt  max_bipt  \\\n",
       "184211    0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "251384    0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "47615     1.885896    1.885538  1.885896  1.885538  1.885896  1.885538   \n",
       "71252     0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "80679     0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "...            ...         ...       ...       ...       ...       ...   \n",
       "149416    0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "231098    0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "143182    0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "14919     6.046394    6.046384  0.003346  0.000007  4.316473  4.311941   \n",
       "243587    0.000000    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "        mean_fipt  mean_bipt  std_fipt  std_bipt  fpsh_cnt  bpsh_cnt  \\\n",
       "184211   0.000000   0.000000   0.00000  0.000000         0         0   \n",
       "251384   0.000000   0.000000   0.00000  0.000000         0         0   \n",
       "47615    1.885896   1.885538   0.00000  0.000000         0         0   \n",
       "71252    0.000000   0.000000   0.00000  0.000000         0         0   \n",
       "80679    0.000000   0.000000   0.00000  0.000000         0         0   \n",
       "...           ...        ...       ...       ...       ...       ...   \n",
       "149416   0.000000   0.000000   0.00000  0.000000         0         0   \n",
       "231098   0.000000   0.000000   0.00000  0.000000         0         0   \n",
       "143182   0.000000   0.000000   0.00000  0.000000         0         0   \n",
       "14919    0.755799   0.604638   1.45309  1.323535         1         3   \n",
       "243587   0.000000   0.000000   0.00000  0.000000         0         0   \n",
       "\n",
       "        furg_cnt  burg_cnt  total_fhlen  total_bhlen  fPktsPerSecond  \\\n",
       "184211         0         0           31          343        0.112751   \n",
       "251384         0         0           40          104     4975.449707   \n",
       "47615          0         0          108          150        0.961081   \n",
       "71252          0         0           40           40        5.285634   \n",
       "80679          0         0           43          155     3472.105957   \n",
       "...          ...       ...          ...          ...             ...   \n",
       "149416         0         0           43           43        0.464114   \n",
       "231098         0         0           32           32     3310.421387   \n",
       "143182         0         0           59          161        1.646576   \n",
       "14919          0         0          192          232        1.488489   \n",
       "243587         0         0           40          104     2809.312744   \n",
       "\n",
       "        bPktsPerSecond  flowPktsPerSecond  flowBytesPerSecond  mean_flowpktl  \\\n",
       "184211        0.112751           0.225501        4.983572e+01          221.0   \n",
       "251384     4975.449707        9950.899414        1.054795e+06          106.0   \n",
       "47615         0.961081           1.922162        1.893330e+02           98.5   \n",
       "71252         5.285634          10.571268        7.822739e+02           74.0   \n",
       "80679      3472.105957        6944.211914        9.235802e+05          133.0   \n",
       "...                ...                ...                 ...            ...   \n",
       "149416        0.464114           0.928228        7.147356e+01           77.0   \n",
       "231098     3310.421387        6620.842773        4.369756e+05           66.0   \n",
       "143182        1.646576           3.293151        4.742138e+02          144.0   \n",
       "14919         1.819264           3.307753        1.654869e+03          500.3   \n",
       "243587     2809.312744        5618.625488        5.955743e+05          106.0   \n",
       "\n",
       "        std_flowpktl  mean_flowipt  std_flowipt  flow_fin  flow_syn  flow_rst  \\\n",
       "184211    220.617310      8.869140     0.000000         0         0         0   \n",
       "251384     45.254833      0.000201     0.000000         0         0         0   \n",
       "47615      17.253019      0.758814     0.976082         0         0         0   \n",
       "71252       0.000000      0.189192     0.000000         0         0         0   \n",
       "80679      79.195961      0.000288     0.000000         0         0         0   \n",
       "...              ...           ...          ...       ...       ...       ...   \n",
       "149416      0.000000      2.154643     0.000000         0         0         0   \n",
       "231098      0.000000      0.000302     0.000000         0         0         0   \n",
       "143182     72.124893      0.607321     0.000000         0         0         0   \n",
       "14919     638.026306      0.523668     1.274822         2         2         0   \n",
       "243587     45.254833      0.000356     0.000000         0         0         0   \n",
       "\n",
       "        flow_ack  flow_urg  flow_cwr  flow_ece  downUpRatio  \n",
       "184211         0         0         0         0     5.800000  \n",
       "251384         0         0         0         0     1.864865  \n",
       "47615          0         0         0         0     1.238636  \n",
       "71252          0         0         0         0     1.000000  \n",
       "80679          0         0         0         0     2.454545  \n",
       "...          ...       ...       ...       ...          ...  \n",
       "149416         0         0         0         0     1.000000  \n",
       "231098         0         0         0         0     1.000000  \n",
       "143182         0         0         0         0     2.096774  \n",
       "14919         19         0         0         0     8.282003  \n",
       "243587         0         0         0         0     1.864865  \n",
       "\n",
       "[60757 rows x 48 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show testing dataset\n",
    "testing_numeric_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardization and scaling of numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_cols = training_numeric_dataset.select_dtypes(include=['float64', 'int']).columns.to_list()\n",
    "preprocessor = ColumnTransformer([('scale', StandardScaler(), numeric_cols)], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit on the trainning dataset\n",
    "preprocessor.fit_transform(training_numeric_dataset)\n",
    "X_train_stand = preprocessor.transform(training_numeric_dataset)\n",
    "X_test_stand  = preprocessor.transform(testing_numeric_dataset)\n",
    "#The result returned by ColumnTransformer is a numpy array, so the column names are lost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-generate the dataset as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=list(training_numeric_dataset.columns.values.tolist())\n",
    "df_X_train_stand=pd.DataFrame(X_train_stand,columns=labels)\n",
    "df_X_test_stand=pd.DataFrame(X_test_stand,columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proto</th>\n",
       "      <th>srcPrt</th>\n",
       "      <th>dstPrt</th>\n",
       "      <th>flowduration</th>\n",
       "      <th>total_fpackets</th>\n",
       "      <th>total_bpackets</th>\n",
       "      <th>total_fpktl</th>\n",
       "      <th>total_bpktl</th>\n",
       "      <th>min_fpktl</th>\n",
       "      <th>min_bpktl</th>\n",
       "      <th>max_fpktl</th>\n",
       "      <th>max_bpktl</th>\n",
       "      <th>mean_fpktl</th>\n",
       "      <th>mean_bpktl</th>\n",
       "      <th>std_fpktl</th>\n",
       "      <th>std_bpktl</th>\n",
       "      <th>total_fipt</th>\n",
       "      <th>total_bipt</th>\n",
       "      <th>min_fipt</th>\n",
       "      <th>min_bipt</th>\n",
       "      <th>max_fipt</th>\n",
       "      <th>max_bipt</th>\n",
       "      <th>mean_fipt</th>\n",
       "      <th>mean_bipt</th>\n",
       "      <th>std_fipt</th>\n",
       "      <th>std_bipt</th>\n",
       "      <th>fpsh_cnt</th>\n",
       "      <th>bpsh_cnt</th>\n",
       "      <th>furg_cnt</th>\n",
       "      <th>burg_cnt</th>\n",
       "      <th>total_fhlen</th>\n",
       "      <th>total_bhlen</th>\n",
       "      <th>fPktsPerSecond</th>\n",
       "      <th>bPktsPerSecond</th>\n",
       "      <th>flowPktsPerSecond</th>\n",
       "      <th>flowBytesPerSecond</th>\n",
       "      <th>mean_flowpktl</th>\n",
       "      <th>std_flowpktl</th>\n",
       "      <th>mean_flowipt</th>\n",
       "      <th>std_flowipt</th>\n",
       "      <th>flow_fin</th>\n",
       "      <th>flow_syn</th>\n",
       "      <th>flow_rst</th>\n",
       "      <th>flow_ack</th>\n",
       "      <th>flow_urg</th>\n",
       "      <th>flow_cwr</th>\n",
       "      <th>flow_ece</th>\n",
       "      <th>downUpRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.385884</td>\n",
       "      <td>-0.049618</td>\n",
       "      <td>-0.025982</td>\n",
       "      <td>-0.066477</td>\n",
       "      <td>-0.025686</td>\n",
       "      <td>-0.058288</td>\n",
       "      <td>-0.023434</td>\n",
       "      <td>-0.053674</td>\n",
       "      <td>0.209826</td>\n",
       "      <td>-0.044488</td>\n",
       "      <td>-0.299637</td>\n",
       "      <td>-0.361583</td>\n",
       "      <td>-0.133094</td>\n",
       "      <td>-0.319456</td>\n",
       "      <td>-0.305333</td>\n",
       "      <td>-0.330261</td>\n",
       "      <td>-0.057182</td>\n",
       "      <td>-0.055192</td>\n",
       "      <td>-0.166945</td>\n",
       "      <td>-0.097163</td>\n",
       "      <td>-0.280660</td>\n",
       "      <td>-0.205521</td>\n",
       "      <td>-0.231477</td>\n",
       "      <td>-0.166902</td>\n",
       "      <td>-0.218551</td>\n",
       "      <td>-0.185957</td>\n",
       "      <td>-0.020118</td>\n",
       "      <td>-0.032832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002445</td>\n",
       "      <td>-0.025452</td>\n",
       "      <td>0.621291</td>\n",
       "      <td>0.740230</td>\n",
       "      <td>0.702426</td>\n",
       "      <td>1.067612</td>\n",
       "      <td>-0.317747</td>\n",
       "      <td>-0.412707</td>\n",
       "      <td>-0.388278</td>\n",
       "      <td>-0.257434</td>\n",
       "      <td>-0.338366</td>\n",
       "      <td>-0.361394</td>\n",
       "      <td>-0.157941</td>\n",
       "      <td>-0.054840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.007027</td>\n",
       "      <td>-0.002028</td>\n",
       "      <td>-0.250275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.591454</td>\n",
       "      <td>-0.048176</td>\n",
       "      <td>-0.007942</td>\n",
       "      <td>-0.034685</td>\n",
       "      <td>0.062658</td>\n",
       "      <td>0.104815</td>\n",
       "      <td>0.026961</td>\n",
       "      <td>0.109837</td>\n",
       "      <td>-0.747833</td>\n",
       "      <td>-0.756447</td>\n",
       "      <td>2.017672</td>\n",
       "      <td>3.122572</td>\n",
       "      <td>-0.212926</td>\n",
       "      <td>3.667405</td>\n",
       "      <td>1.004275</td>\n",
       "      <td>3.183606</td>\n",
       "      <td>-0.025350</td>\n",
       "      <td>-0.013902</td>\n",
       "      <td>-0.166943</td>\n",
       "      <td>-0.097162</td>\n",
       "      <td>0.099984</td>\n",
       "      <td>0.147124</td>\n",
       "      <td>-0.200672</td>\n",
       "      <td>-0.133094</td>\n",
       "      <td>0.008510</td>\n",
       "      <td>0.023263</td>\n",
       "      <td>-0.004474</td>\n",
       "      <td>0.021084</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000744</td>\n",
       "      <td>0.034666</td>\n",
       "      <td>-0.284725</td>\n",
       "      <td>-0.317560</td>\n",
       "      <td>-0.311520</td>\n",
       "      <td>-0.449452</td>\n",
       "      <td>2.979958</td>\n",
       "      <td>3.410115</td>\n",
       "      <td>-0.349123</td>\n",
       "      <td>-0.050714</td>\n",
       "      <td>2.821734</td>\n",
       "      <td>2.414344</td>\n",
       "      <td>-0.157941</td>\n",
       "      <td>0.152988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.007027</td>\n",
       "      <td>-0.002028</td>\n",
       "      <td>2.436993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.385884</td>\n",
       "      <td>-0.050379</td>\n",
       "      <td>-0.025982</td>\n",
       "      <td>-0.045212</td>\n",
       "      <td>-0.025686</td>\n",
       "      <td>-0.058288</td>\n",
       "      <td>-0.023621</td>\n",
       "      <td>-0.053499</td>\n",
       "      <td>-0.142996</td>\n",
       "      <td>0.250467</td>\n",
       "      <td>-0.344447</td>\n",
       "      <td>-0.283740</td>\n",
       "      <td>-0.333269</td>\n",
       "      <td>-0.203880</td>\n",
       "      <td>-0.305333</td>\n",
       "      <td>-0.330261</td>\n",
       "      <td>-0.057182</td>\n",
       "      <td>-0.055192</td>\n",
       "      <td>-0.166945</td>\n",
       "      <td>-0.097163</td>\n",
       "      <td>-0.280660</td>\n",
       "      <td>-0.205521</td>\n",
       "      <td>-0.231477</td>\n",
       "      <td>-0.166902</td>\n",
       "      <td>-0.218551</td>\n",
       "      <td>-0.185957</td>\n",
       "      <td>-0.020118</td>\n",
       "      <td>-0.032832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002462</td>\n",
       "      <td>-0.022881</td>\n",
       "      <td>-0.285344</td>\n",
       "      <td>-0.318282</td>\n",
       "      <td>-0.312213</td>\n",
       "      <td>-0.455490</td>\n",
       "      <td>-0.245022</td>\n",
       "      <td>-0.256287</td>\n",
       "      <td>0.249236</td>\n",
       "      <td>-0.257434</td>\n",
       "      <td>-0.338366</td>\n",
       "      <td>-0.361394</td>\n",
       "      <td>-0.157941</td>\n",
       "      <td>-0.054840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.007027</td>\n",
       "      <td>-0.002028</td>\n",
       "      <td>-0.136967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.385884</td>\n",
       "      <td>-0.048176</td>\n",
       "      <td>-0.025982</td>\n",
       "      <td>-0.051179</td>\n",
       "      <td>-0.025686</td>\n",
       "      <td>-0.058288</td>\n",
       "      <td>-0.023647</td>\n",
       "      <td>-0.054030</td>\n",
       "      <td>-0.193399</td>\n",
       "      <td>-0.644567</td>\n",
       "      <td>-0.350849</td>\n",
       "      <td>-0.519953</td>\n",
       "      <td>-0.361865</td>\n",
       "      <td>-0.554593</td>\n",
       "      <td>-0.305333</td>\n",
       "      <td>-0.330261</td>\n",
       "      <td>-0.057182</td>\n",
       "      <td>-0.055192</td>\n",
       "      <td>-0.166945</td>\n",
       "      <td>-0.097163</td>\n",
       "      <td>-0.280660</td>\n",
       "      <td>-0.205521</td>\n",
       "      <td>-0.231477</td>\n",
       "      <td>-0.166902</td>\n",
       "      <td>-0.218551</td>\n",
       "      <td>-0.185957</td>\n",
       "      <td>-0.020118</td>\n",
       "      <td>-0.032832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002464</td>\n",
       "      <td>-0.030684</td>\n",
       "      <td>-0.285328</td>\n",
       "      <td>-0.318264</td>\n",
       "      <td>-0.312195</td>\n",
       "      <td>-0.455499</td>\n",
       "      <td>-0.539229</td>\n",
       "      <td>-0.634302</td>\n",
       "      <td>0.070331</td>\n",
       "      <td>-0.257434</td>\n",
       "      <td>-0.338366</td>\n",
       "      <td>-0.361394</td>\n",
       "      <td>-0.157941</td>\n",
       "      <td>-0.054840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.007027</td>\n",
       "      <td>-0.002028</td>\n",
       "      <td>-0.382186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.385884</td>\n",
       "      <td>-0.050172</td>\n",
       "      <td>-0.025982</td>\n",
       "      <td>-0.066475</td>\n",
       "      <td>-0.025686</td>\n",
       "      <td>-0.058288</td>\n",
       "      <td>-0.023541</td>\n",
       "      <td>-0.052276</td>\n",
       "      <td>0.008213</td>\n",
       "      <td>2.315148</td>\n",
       "      <td>-0.325243</td>\n",
       "      <td>0.261163</td>\n",
       "      <td>-0.247480</td>\n",
       "      <td>0.605149</td>\n",
       "      <td>-0.305333</td>\n",
       "      <td>-0.330261</td>\n",
       "      <td>-0.057182</td>\n",
       "      <td>-0.055192</td>\n",
       "      <td>-0.166945</td>\n",
       "      <td>-0.097163</td>\n",
       "      <td>-0.280660</td>\n",
       "      <td>-0.205521</td>\n",
       "      <td>-0.231477</td>\n",
       "      <td>-0.166902</td>\n",
       "      <td>-0.218551</td>\n",
       "      <td>-0.185957</td>\n",
       "      <td>-0.020118</td>\n",
       "      <td>-0.032832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002455</td>\n",
       "      <td>-0.004881</td>\n",
       "      <td>0.031255</td>\n",
       "      <td>0.051352</td>\n",
       "      <td>0.042101</td>\n",
       "      <td>0.625167</td>\n",
       "      <td>0.435951</td>\n",
       "      <td>0.612714</td>\n",
       "      <td>-0.388224</td>\n",
       "      <td>-0.257434</td>\n",
       "      <td>-0.338366</td>\n",
       "      <td>-0.361394</td>\n",
       "      <td>-0.157941</td>\n",
       "      <td>-0.054840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.007027</td>\n",
       "      <td>-0.002028</td>\n",
       "      <td>0.396794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243022</th>\n",
       "      <td>-0.385884</td>\n",
       "      <td>-0.049618</td>\n",
       "      <td>-0.025982</td>\n",
       "      <td>-0.020499</td>\n",
       "      <td>-0.025686</td>\n",
       "      <td>-0.058288</td>\n",
       "      <td>-0.023674</td>\n",
       "      <td>-0.053542</td>\n",
       "      <td>-0.243802</td>\n",
       "      <td>0.179271</td>\n",
       "      <td>-0.357250</td>\n",
       "      <td>-0.302529</td>\n",
       "      <td>-0.390462</td>\n",
       "      <td>-0.231778</td>\n",
       "      <td>-0.305333</td>\n",
       "      <td>-0.330261</td>\n",
       "      <td>-0.057182</td>\n",
       "      <td>-0.055192</td>\n",
       "      <td>-0.166945</td>\n",
       "      <td>-0.097163</td>\n",
       "      <td>-0.280660</td>\n",
       "      <td>-0.205521</td>\n",
       "      <td>-0.231477</td>\n",
       "      <td>-0.166902</td>\n",
       "      <td>-0.218551</td>\n",
       "      <td>-0.185957</td>\n",
       "      <td>-0.020118</td>\n",
       "      <td>-0.032832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002467</td>\n",
       "      <td>-0.023501</td>\n",
       "      <td>-0.285366</td>\n",
       "      <td>-0.318308</td>\n",
       "      <td>-0.312238</td>\n",
       "      <td>-0.455532</td>\n",
       "      <td>-0.274773</td>\n",
       "      <td>-0.278012</td>\n",
       "      <td>0.990096</td>\n",
       "      <td>-0.257434</td>\n",
       "      <td>-0.338366</td>\n",
       "      <td>-0.361394</td>\n",
       "      <td>-0.157941</td>\n",
       "      <td>-0.054840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.007027</td>\n",
       "      <td>-0.002028</td>\n",
       "      <td>-0.144978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243023</th>\n",
       "      <td>-0.385884</td>\n",
       "      <td>-0.050455</td>\n",
       "      <td>-0.025982</td>\n",
       "      <td>-0.060962</td>\n",
       "      <td>-0.025686</td>\n",
       "      <td>-0.058288</td>\n",
       "      <td>-0.023487</td>\n",
       "      <td>-0.052505</td>\n",
       "      <td>0.109020</td>\n",
       "      <td>1.928656</td>\n",
       "      <td>-0.312440</td>\n",
       "      <td>0.159161</td>\n",
       "      <td>-0.190287</td>\n",
       "      <td>0.453705</td>\n",
       "      <td>-0.305333</td>\n",
       "      <td>-0.330261</td>\n",
       "      <td>-0.057182</td>\n",
       "      <td>-0.055192</td>\n",
       "      <td>-0.166945</td>\n",
       "      <td>-0.097163</td>\n",
       "      <td>-0.280660</td>\n",
       "      <td>-0.205521</td>\n",
       "      <td>-0.231477</td>\n",
       "      <td>-0.166902</td>\n",
       "      <td>-0.218551</td>\n",
       "      <td>-0.185957</td>\n",
       "      <td>-0.020118</td>\n",
       "      <td>-0.032832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002450</td>\n",
       "      <td>-0.008250</td>\n",
       "      <td>-0.285226</td>\n",
       "      <td>-0.318145</td>\n",
       "      <td>-0.312082</td>\n",
       "      <td>-0.455068</td>\n",
       "      <td>0.316946</td>\n",
       "      <td>0.438914</td>\n",
       "      <td>-0.222951</td>\n",
       "      <td>-0.257434</td>\n",
       "      <td>-0.338366</td>\n",
       "      <td>-0.361394</td>\n",
       "      <td>-0.157941</td>\n",
       "      <td>-0.054840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.007027</td>\n",
       "      <td>-0.002028</td>\n",
       "      <td>0.272071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243024</th>\n",
       "      <td>-0.385884</td>\n",
       "      <td>-0.050455</td>\n",
       "      <td>-0.025982</td>\n",
       "      <td>-0.066476</td>\n",
       "      <td>-0.025686</td>\n",
       "      <td>-0.058288</td>\n",
       "      <td>-0.023781</td>\n",
       "      <td>-0.053505</td>\n",
       "      <td>-0.445415</td>\n",
       "      <td>0.240296</td>\n",
       "      <td>-0.382856</td>\n",
       "      <td>-0.286424</td>\n",
       "      <td>-0.504847</td>\n",
       "      <td>-0.207866</td>\n",
       "      <td>-0.305333</td>\n",
       "      <td>-0.330261</td>\n",
       "      <td>-0.057182</td>\n",
       "      <td>-0.055192</td>\n",
       "      <td>-0.166945</td>\n",
       "      <td>-0.097163</td>\n",
       "      <td>-0.280660</td>\n",
       "      <td>-0.205521</td>\n",
       "      <td>-0.231477</td>\n",
       "      <td>-0.166902</td>\n",
       "      <td>-0.218551</td>\n",
       "      <td>-0.185957</td>\n",
       "      <td>-0.020118</td>\n",
       "      <td>-0.032832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002476</td>\n",
       "      <td>-0.022969</td>\n",
       "      <td>0.251935</td>\n",
       "      <td>0.309000</td>\n",
       "      <td>0.289070</td>\n",
       "      <td>0.508377</td>\n",
       "      <td>-0.268162</td>\n",
       "      <td>-0.234562</td>\n",
       "      <td>-0.388258</td>\n",
       "      <td>-0.257434</td>\n",
       "      <td>-0.338366</td>\n",
       "      <td>-0.361394</td>\n",
       "      <td>-0.157941</td>\n",
       "      <td>-0.054840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.007027</td>\n",
       "      <td>-0.002028</td>\n",
       "      <td>-0.101264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243025</th>\n",
       "      <td>-0.385884</td>\n",
       "      <td>-0.049618</td>\n",
       "      <td>-0.025982</td>\n",
       "      <td>-0.056754</td>\n",
       "      <td>-0.025686</td>\n",
       "      <td>-0.058288</td>\n",
       "      <td>-0.023621</td>\n",
       "      <td>-0.051758</td>\n",
       "      <td>-0.142996</td>\n",
       "      <td>3.189841</td>\n",
       "      <td>-0.344447</td>\n",
       "      <td>0.492008</td>\n",
       "      <td>-0.333269</td>\n",
       "      <td>0.947890</td>\n",
       "      <td>-0.305333</td>\n",
       "      <td>-0.330261</td>\n",
       "      <td>-0.057182</td>\n",
       "      <td>-0.055192</td>\n",
       "      <td>-0.166945</td>\n",
       "      <td>-0.097163</td>\n",
       "      <td>-0.280660</td>\n",
       "      <td>-0.205521</td>\n",
       "      <td>-0.231477</td>\n",
       "      <td>-0.166902</td>\n",
       "      <td>-0.218551</td>\n",
       "      <td>-0.185957</td>\n",
       "      <td>-0.020118</td>\n",
       "      <td>-0.032832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002462</td>\n",
       "      <td>0.002745</td>\n",
       "      <td>-0.285295</td>\n",
       "      <td>-0.318225</td>\n",
       "      <td>-0.312158</td>\n",
       "      <td>-0.455202</td>\n",
       "      <td>0.710324</td>\n",
       "      <td>0.999419</td>\n",
       "      <td>-0.096790</td>\n",
       "      <td>-0.257434</td>\n",
       "      <td>-0.338366</td>\n",
       "      <td>-0.361394</td>\n",
       "      <td>-0.157941</td>\n",
       "      <td>-0.054840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.007027</td>\n",
       "      <td>-0.002028</td>\n",
       "      <td>0.677611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243026</th>\n",
       "      <td>-0.385884</td>\n",
       "      <td>-0.050499</td>\n",
       "      <td>-0.025982</td>\n",
       "      <td>-0.066477</td>\n",
       "      <td>-0.025686</td>\n",
       "      <td>-0.058288</td>\n",
       "      <td>-0.023434</td>\n",
       "      <td>-0.053674</td>\n",
       "      <td>0.209826</td>\n",
       "      <td>-0.044488</td>\n",
       "      <td>-0.299637</td>\n",
       "      <td>-0.361583</td>\n",
       "      <td>-0.133094</td>\n",
       "      <td>-0.319456</td>\n",
       "      <td>-0.305333</td>\n",
       "      <td>-0.330261</td>\n",
       "      <td>-0.057182</td>\n",
       "      <td>-0.055192</td>\n",
       "      <td>-0.166945</td>\n",
       "      <td>-0.097163</td>\n",
       "      <td>-0.280660</td>\n",
       "      <td>-0.205521</td>\n",
       "      <td>-0.231477</td>\n",
       "      <td>-0.166902</td>\n",
       "      <td>-0.218551</td>\n",
       "      <td>-0.185957</td>\n",
       "      <td>-0.020118</td>\n",
       "      <td>-0.032832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002445</td>\n",
       "      <td>-0.025452</td>\n",
       "      <td>0.497708</td>\n",
       "      <td>0.595944</td>\n",
       "      <td>0.564121</td>\n",
       "      <td>0.859997</td>\n",
       "      <td>-0.317747</td>\n",
       "      <td>-0.412707</td>\n",
       "      <td>-0.388273</td>\n",
       "      <td>-0.257434</td>\n",
       "      <td>-0.338366</td>\n",
       "      <td>-0.361394</td>\n",
       "      <td>-0.157941</td>\n",
       "      <td>-0.054840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.007027</td>\n",
       "      <td>-0.002028</td>\n",
       "      <td>-0.250275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243027 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           proto    srcPrt    dstPrt  flowduration  total_fpackets  \\\n",
       "0      -0.385884 -0.049618 -0.025982     -0.066477       -0.025686   \n",
       "1       2.591454 -0.048176 -0.007942     -0.034685        0.062658   \n",
       "2      -0.385884 -0.050379 -0.025982     -0.045212       -0.025686   \n",
       "3      -0.385884 -0.048176 -0.025982     -0.051179       -0.025686   \n",
       "4      -0.385884 -0.050172 -0.025982     -0.066475       -0.025686   \n",
       "...          ...       ...       ...           ...             ...   \n",
       "243022 -0.385884 -0.049618 -0.025982     -0.020499       -0.025686   \n",
       "243023 -0.385884 -0.050455 -0.025982     -0.060962       -0.025686   \n",
       "243024 -0.385884 -0.050455 -0.025982     -0.066476       -0.025686   \n",
       "243025 -0.385884 -0.049618 -0.025982     -0.056754       -0.025686   \n",
       "243026 -0.385884 -0.050499 -0.025982     -0.066477       -0.025686   \n",
       "\n",
       "        total_bpackets  total_fpktl  total_bpktl  min_fpktl  min_bpktl  \\\n",
       "0            -0.058288    -0.023434    -0.053674   0.209826  -0.044488   \n",
       "1             0.104815     0.026961     0.109837  -0.747833  -0.756447   \n",
       "2            -0.058288    -0.023621    -0.053499  -0.142996   0.250467   \n",
       "3            -0.058288    -0.023647    -0.054030  -0.193399  -0.644567   \n",
       "4            -0.058288    -0.023541    -0.052276   0.008213   2.315148   \n",
       "...                ...          ...          ...        ...        ...   \n",
       "243022       -0.058288    -0.023674    -0.053542  -0.243802   0.179271   \n",
       "243023       -0.058288    -0.023487    -0.052505   0.109020   1.928656   \n",
       "243024       -0.058288    -0.023781    -0.053505  -0.445415   0.240296   \n",
       "243025       -0.058288    -0.023621    -0.051758  -0.142996   3.189841   \n",
       "243026       -0.058288    -0.023434    -0.053674   0.209826  -0.044488   \n",
       "\n",
       "        max_fpktl  max_bpktl  mean_fpktl  mean_bpktl  std_fpktl  std_bpktl  \\\n",
       "0       -0.299637  -0.361583   -0.133094   -0.319456  -0.305333  -0.330261   \n",
       "1        2.017672   3.122572   -0.212926    3.667405   1.004275   3.183606   \n",
       "2       -0.344447  -0.283740   -0.333269   -0.203880  -0.305333  -0.330261   \n",
       "3       -0.350849  -0.519953   -0.361865   -0.554593  -0.305333  -0.330261   \n",
       "4       -0.325243   0.261163   -0.247480    0.605149  -0.305333  -0.330261   \n",
       "...           ...        ...         ...         ...        ...        ...   \n",
       "243022  -0.357250  -0.302529   -0.390462   -0.231778  -0.305333  -0.330261   \n",
       "243023  -0.312440   0.159161   -0.190287    0.453705  -0.305333  -0.330261   \n",
       "243024  -0.382856  -0.286424   -0.504847   -0.207866  -0.305333  -0.330261   \n",
       "243025  -0.344447   0.492008   -0.333269    0.947890  -0.305333  -0.330261   \n",
       "243026  -0.299637  -0.361583   -0.133094   -0.319456  -0.305333  -0.330261   \n",
       "\n",
       "        total_fipt  total_bipt  min_fipt  min_bipt  max_fipt  max_bipt  \\\n",
       "0        -0.057182   -0.055192 -0.166945 -0.097163 -0.280660 -0.205521   \n",
       "1        -0.025350   -0.013902 -0.166943 -0.097162  0.099984  0.147124   \n",
       "2        -0.057182   -0.055192 -0.166945 -0.097163 -0.280660 -0.205521   \n",
       "3        -0.057182   -0.055192 -0.166945 -0.097163 -0.280660 -0.205521   \n",
       "4        -0.057182   -0.055192 -0.166945 -0.097163 -0.280660 -0.205521   \n",
       "...            ...         ...       ...       ...       ...       ...   \n",
       "243022   -0.057182   -0.055192 -0.166945 -0.097163 -0.280660 -0.205521   \n",
       "243023   -0.057182   -0.055192 -0.166945 -0.097163 -0.280660 -0.205521   \n",
       "243024   -0.057182   -0.055192 -0.166945 -0.097163 -0.280660 -0.205521   \n",
       "243025   -0.057182   -0.055192 -0.166945 -0.097163 -0.280660 -0.205521   \n",
       "243026   -0.057182   -0.055192 -0.166945 -0.097163 -0.280660 -0.205521   \n",
       "\n",
       "        mean_fipt  mean_bipt  std_fipt  std_bipt  fpsh_cnt  bpsh_cnt  \\\n",
       "0       -0.231477  -0.166902 -0.218551 -0.185957 -0.020118 -0.032832   \n",
       "1       -0.200672  -0.133094  0.008510  0.023263 -0.004474  0.021084   \n",
       "2       -0.231477  -0.166902 -0.218551 -0.185957 -0.020118 -0.032832   \n",
       "3       -0.231477  -0.166902 -0.218551 -0.185957 -0.020118 -0.032832   \n",
       "4       -0.231477  -0.166902 -0.218551 -0.185957 -0.020118 -0.032832   \n",
       "...           ...        ...       ...       ...       ...       ...   \n",
       "243022  -0.231477  -0.166902 -0.218551 -0.185957 -0.020118 -0.032832   \n",
       "243023  -0.231477  -0.166902 -0.218551 -0.185957 -0.020118 -0.032832   \n",
       "243024  -0.231477  -0.166902 -0.218551 -0.185957 -0.020118 -0.032832   \n",
       "243025  -0.231477  -0.166902 -0.218551 -0.185957 -0.020118 -0.032832   \n",
       "243026  -0.231477  -0.166902 -0.218551 -0.185957 -0.020118 -0.032832   \n",
       "\n",
       "        furg_cnt  burg_cnt  total_fhlen  total_bhlen  fPktsPerSecond  \\\n",
       "0            0.0       0.0    -0.002445    -0.025452        0.621291   \n",
       "1            0.0       0.0    -0.000744     0.034666       -0.284725   \n",
       "2            0.0       0.0    -0.002462    -0.022881       -0.285344   \n",
       "3            0.0       0.0    -0.002464    -0.030684       -0.285328   \n",
       "4            0.0       0.0    -0.002455    -0.004881        0.031255   \n",
       "...          ...       ...          ...          ...             ...   \n",
       "243022       0.0       0.0    -0.002467    -0.023501       -0.285366   \n",
       "243023       0.0       0.0    -0.002450    -0.008250       -0.285226   \n",
       "243024       0.0       0.0    -0.002476    -0.022969        0.251935   \n",
       "243025       0.0       0.0    -0.002462     0.002745       -0.285295   \n",
       "243026       0.0       0.0    -0.002445    -0.025452        0.497708   \n",
       "\n",
       "        bPktsPerSecond  flowPktsPerSecond  flowBytesPerSecond  mean_flowpktl  \\\n",
       "0             0.740230           0.702426            1.067612      -0.317747   \n",
       "1            -0.317560          -0.311520           -0.449452       2.979958   \n",
       "2            -0.318282          -0.312213           -0.455490      -0.245022   \n",
       "3            -0.318264          -0.312195           -0.455499      -0.539229   \n",
       "4             0.051352           0.042101            0.625167       0.435951   \n",
       "...                ...                ...                 ...            ...   \n",
       "243022       -0.318308          -0.312238           -0.455532      -0.274773   \n",
       "243023       -0.318145          -0.312082           -0.455068       0.316946   \n",
       "243024        0.309000           0.289070            0.508377      -0.268162   \n",
       "243025       -0.318225          -0.312158           -0.455202       0.710324   \n",
       "243026        0.595944           0.564121            0.859997      -0.317747   \n",
       "\n",
       "        std_flowpktl  mean_flowipt  std_flowipt  flow_fin  flow_syn  flow_rst  \\\n",
       "0          -0.412707     -0.388278    -0.257434 -0.338366 -0.361394 -0.157941   \n",
       "1           3.410115     -0.349123    -0.050714  2.821734  2.414344 -0.157941   \n",
       "2          -0.256287      0.249236    -0.257434 -0.338366 -0.361394 -0.157941   \n",
       "3          -0.634302      0.070331    -0.257434 -0.338366 -0.361394 -0.157941   \n",
       "4           0.612714     -0.388224    -0.257434 -0.338366 -0.361394 -0.157941   \n",
       "...              ...           ...          ...       ...       ...       ...   \n",
       "243022     -0.278012      0.990096    -0.257434 -0.338366 -0.361394 -0.157941   \n",
       "243023      0.438914     -0.222951    -0.257434 -0.338366 -0.361394 -0.157941   \n",
       "243024     -0.234562     -0.388258    -0.257434 -0.338366 -0.361394 -0.157941   \n",
       "243025      0.999419     -0.096790    -0.257434 -0.338366 -0.361394 -0.157941   \n",
       "243026     -0.412707     -0.388273    -0.257434 -0.338366 -0.361394 -0.157941   \n",
       "\n",
       "        flow_ack  flow_urg  flow_cwr  flow_ece  downUpRatio  \n",
       "0      -0.054840       0.0 -0.007027 -0.002028    -0.250275  \n",
       "1       0.152988       0.0 -0.007027 -0.002028     2.436993  \n",
       "2      -0.054840       0.0 -0.007027 -0.002028    -0.136967  \n",
       "3      -0.054840       0.0 -0.007027 -0.002028    -0.382186  \n",
       "4      -0.054840       0.0 -0.007027 -0.002028     0.396794  \n",
       "...          ...       ...       ...       ...          ...  \n",
       "243022 -0.054840       0.0 -0.007027 -0.002028    -0.144978  \n",
       "243023 -0.054840       0.0 -0.007027 -0.002028     0.272071  \n",
       "243024 -0.054840       0.0 -0.007027 -0.002028    -0.101264  \n",
       "243025 -0.054840       0.0 -0.007027 -0.002028     0.677611  \n",
       "243026 -0.054840       0.0 -0.007027 -0.002028    -0.250275  \n",
       "\n",
       "[243027 rows x 48 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_train_stand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proto</th>\n",
       "      <th>srcPrt</th>\n",
       "      <th>dstPrt</th>\n",
       "      <th>flowduration</th>\n",
       "      <th>total_fpackets</th>\n",
       "      <th>total_bpackets</th>\n",
       "      <th>total_fpktl</th>\n",
       "      <th>total_bpktl</th>\n",
       "      <th>min_fpktl</th>\n",
       "      <th>min_bpktl</th>\n",
       "      <th>max_fpktl</th>\n",
       "      <th>max_bpktl</th>\n",
       "      <th>mean_fpktl</th>\n",
       "      <th>mean_bpktl</th>\n",
       "      <th>std_fpktl</th>\n",
       "      <th>std_bpktl</th>\n",
       "      <th>total_fipt</th>\n",
       "      <th>total_bipt</th>\n",
       "      <th>min_fipt</th>\n",
       "      <th>min_bipt</th>\n",
       "      <th>max_fipt</th>\n",
       "      <th>max_bipt</th>\n",
       "      <th>mean_fipt</th>\n",
       "      <th>mean_bipt</th>\n",
       "      <th>std_fipt</th>\n",
       "      <th>std_bipt</th>\n",
       "      <th>fpsh_cnt</th>\n",
       "      <th>bpsh_cnt</th>\n",
       "      <th>furg_cnt</th>\n",
       "      <th>burg_cnt</th>\n",
       "      <th>total_fhlen</th>\n",
       "      <th>total_bhlen</th>\n",
       "      <th>fPktsPerSecond</th>\n",
       "      <th>bPktsPerSecond</th>\n",
       "      <th>flowPktsPerSecond</th>\n",
       "      <th>flowBytesPerSecond</th>\n",
       "      <th>mean_flowpktl</th>\n",
       "      <th>std_flowpktl</th>\n",
       "      <th>mean_flowipt</th>\n",
       "      <th>std_flowipt</th>\n",
       "      <th>flow_fin</th>\n",
       "      <th>flow_syn</th>\n",
       "      <th>flow_rst</th>\n",
       "      <th>flow_ack</th>\n",
       "      <th>flow_urg</th>\n",
       "      <th>flow_cwr</th>\n",
       "      <th>flow_ece</th>\n",
       "      <th>downUpRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.385884</td>\n",
       "      <td>-0.049618</td>\n",
       "      <td>-0.025982</td>\n",
       "      <td>-0.012041</td>\n",
       "      <td>-0.025686</td>\n",
       "      <td>-0.058288</td>\n",
       "      <td>-0.023968</td>\n",
       "      <td>-0.052222</td>\n",
       "      <td>-0.798236</td>\n",
       "      <td>2.406686</td>\n",
       "      <td>-0.427666</td>\n",
       "      <td>0.285321</td>\n",
       "      <td>-0.705022</td>\n",
       "      <td>0.641017</td>\n",
       "      <td>-0.305333</td>\n",
       "      <td>-0.330261</td>\n",
       "      <td>-0.057182</td>\n",
       "      <td>-0.055192</td>\n",
       "      <td>-0.166945</td>\n",
       "      <td>-0.097163</td>\n",
       "      <td>-0.280660</td>\n",
       "      <td>-0.205521</td>\n",
       "      <td>-0.231477</td>\n",
       "      <td>-0.166902</td>\n",
       "      <td>-0.218551</td>\n",
       "      <td>-0.185957</td>\n",
       "      <td>-0.020118</td>\n",
       "      <td>-0.032832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002492</td>\n",
       "      <td>-0.004083</td>\n",
       "      <td>-0.285369</td>\n",
       "      <td>-0.318312</td>\n",
       "      <td>-0.312241</td>\n",
       "      <td>-0.455512</td>\n",
       "      <td>0.412811</td>\n",
       "      <td>0.721339</td>\n",
       "      <td>1.243683</td>\n",
       "      <td>-0.257434</td>\n",
       "      <td>-0.338366</td>\n",
       "      <td>-0.361394</td>\n",
       "      <td>-0.157941</td>\n",
       "      <td>-0.054840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.007027</td>\n",
       "      <td>-0.002028</td>\n",
       "      <td>0.673101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.385884</td>\n",
       "      <td>-0.050379</td>\n",
       "      <td>-0.025982</td>\n",
       "      <td>-0.066477</td>\n",
       "      <td>-0.025686</td>\n",
       "      <td>-0.058288</td>\n",
       "      <td>-0.023727</td>\n",
       "      <td>-0.053662</td>\n",
       "      <td>-0.344608</td>\n",
       "      <td>-0.024146</td>\n",
       "      <td>-0.370053</td>\n",
       "      <td>-0.356214</td>\n",
       "      <td>-0.447654</td>\n",
       "      <td>-0.311485</td>\n",
       "      <td>-0.305333</td>\n",
       "      <td>-0.330261</td>\n",
       "      <td>-0.057182</td>\n",
       "      <td>-0.055192</td>\n",
       "      <td>-0.166945</td>\n",
       "      <td>-0.097163</td>\n",
       "      <td>-0.280660</td>\n",
       "      <td>-0.205521</td>\n",
       "      <td>-0.231477</td>\n",
       "      <td>-0.166902</td>\n",
       "      <td>-0.218551</td>\n",
       "      <td>-0.185957</td>\n",
       "      <td>-0.020118</td>\n",
       "      <td>-0.032832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002471</td>\n",
       "      <td>-0.025275</td>\n",
       "      <td>0.423393</td>\n",
       "      <td>0.509180</td>\n",
       "      <td>0.480953</td>\n",
       "      <td>0.686660</td>\n",
       "      <td>-0.347499</td>\n",
       "      <td>-0.356222</td>\n",
       "      <td>-0.388270</td>\n",
       "      <td>-0.257434</td>\n",
       "      <td>-0.338366</td>\n",
       "      <td>-0.361394</td>\n",
       "      <td>-0.157941</td>\n",
       "      <td>-0.054840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.007027</td>\n",
       "      <td>-0.002028</td>\n",
       "      <td>-0.192044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.385884</td>\n",
       "      <td>-0.050500</td>\n",
       "      <td>-0.025982</td>\n",
       "      <td>-0.053705</td>\n",
       "      <td>-0.021845</td>\n",
       "      <td>-0.051196</td>\n",
       "      <td>-0.021005</td>\n",
       "      <td>-0.053180</td>\n",
       "      <td>0.310632</td>\n",
       "      <td>-0.471663</td>\n",
       "      <td>-0.274032</td>\n",
       "      <td>-0.393794</td>\n",
       "      <td>-0.047305</td>\n",
       "      <td>-0.427061</td>\n",
       "      <td>-0.281502</td>\n",
       "      <td>-0.194041</td>\n",
       "      <td>-0.045593</td>\n",
       "      <td>-0.040162</td>\n",
       "      <td>0.134272</td>\n",
       "      <td>0.253915</td>\n",
       "      <td>-0.131940</td>\n",
       "      <td>-0.067951</td>\n",
       "      <td>0.026489</td>\n",
       "      <td>0.116153</td>\n",
       "      <td>-0.218551</td>\n",
       "      <td>-0.185957</td>\n",
       "      <td>-0.020118</td>\n",
       "      <td>-0.032832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002312</td>\n",
       "      <td>-0.021196</td>\n",
       "      <td>-0.285248</td>\n",
       "      <td>-0.318170</td>\n",
       "      <td>-0.312106</td>\n",
       "      <td>-0.455361</td>\n",
       "      <td>-0.397084</td>\n",
       "      <td>-0.528286</td>\n",
       "      <td>-0.248679</td>\n",
       "      <td>-0.050418</td>\n",
       "      <td>-0.338366</td>\n",
       "      <td>-0.361394</td>\n",
       "      <td>-0.157941</td>\n",
       "      <td>-0.054840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.007027</td>\n",
       "      <td>-0.002028</td>\n",
       "      <td>-0.329721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.385884</td>\n",
       "      <td>-0.037321</td>\n",
       "      <td>-0.025982</td>\n",
       "      <td>-0.065317</td>\n",
       "      <td>-0.025686</td>\n",
       "      <td>-0.058288</td>\n",
       "      <td>-0.023727</td>\n",
       "      <td>-0.054048</td>\n",
       "      <td>-0.344608</td>\n",
       "      <td>-0.675080</td>\n",
       "      <td>-0.370053</td>\n",
       "      <td>-0.528006</td>\n",
       "      <td>-0.447654</td>\n",
       "      <td>-0.566549</td>\n",
       "      <td>-0.305333</td>\n",
       "      <td>-0.330261</td>\n",
       "      <td>-0.057182</td>\n",
       "      <td>-0.055192</td>\n",
       "      <td>-0.166945</td>\n",
       "      <td>-0.097163</td>\n",
       "      <td>-0.280660</td>\n",
       "      <td>-0.205521</td>\n",
       "      <td>-0.231477</td>\n",
       "      <td>-0.166902</td>\n",
       "      <td>-0.218551</td>\n",
       "      <td>-0.185957</td>\n",
       "      <td>-0.020118</td>\n",
       "      <td>-0.032832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002471</td>\n",
       "      <td>-0.030950</td>\n",
       "      <td>-0.284632</td>\n",
       "      <td>-0.317451</td>\n",
       "      <td>-0.311416</td>\n",
       "      <td>-0.454719</td>\n",
       "      <td>-0.559063</td>\n",
       "      <td>-0.634302</td>\n",
       "      <td>-0.353494</td>\n",
       "      <td>-0.257434</td>\n",
       "      <td>-0.338366</td>\n",
       "      <td>-0.361394</td>\n",
       "      <td>-0.157941</td>\n",
       "      <td>-0.054840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.007027</td>\n",
       "      <td>-0.002028</td>\n",
       "      <td>-0.382186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.385884</td>\n",
       "      <td>-0.050172</td>\n",
       "      <td>-0.025982</td>\n",
       "      <td>-0.066476</td>\n",
       "      <td>-0.025686</td>\n",
       "      <td>-0.058288</td>\n",
       "      <td>-0.023647</td>\n",
       "      <td>-0.053355</td>\n",
       "      <td>-0.193399</td>\n",
       "      <td>0.494567</td>\n",
       "      <td>-0.350849</td>\n",
       "      <td>-0.219318</td>\n",
       "      <td>-0.361865</td>\n",
       "      <td>-0.108232</td>\n",
       "      <td>-0.305333</td>\n",
       "      <td>-0.330261</td>\n",
       "      <td>-0.057182</td>\n",
       "      <td>-0.055192</td>\n",
       "      <td>-0.166945</td>\n",
       "      <td>-0.097163</td>\n",
       "      <td>-0.280660</td>\n",
       "      <td>-0.205521</td>\n",
       "      <td>-0.231477</td>\n",
       "      <td>-0.166902</td>\n",
       "      <td>-0.218551</td>\n",
       "      <td>-0.185957</td>\n",
       "      <td>-0.020118</td>\n",
       "      <td>-0.032832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002464</td>\n",
       "      <td>-0.020753</td>\n",
       "      <td>0.209234</td>\n",
       "      <td>0.259146</td>\n",
       "      <td>0.241282</td>\n",
       "      <td>0.544569</td>\n",
       "      <td>-0.168991</td>\n",
       "      <td>-0.147662</td>\n",
       "      <td>-0.388254</td>\n",
       "      <td>-0.257434</td>\n",
       "      <td>-0.338366</td>\n",
       "      <td>-0.361394</td>\n",
       "      <td>-0.157941</td>\n",
       "      <td>-0.054840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.007027</td>\n",
       "      <td>-0.002028</td>\n",
       "      <td>-0.062402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60752</th>\n",
       "      <td>-0.385884</td>\n",
       "      <td>-0.050455</td>\n",
       "      <td>-0.025982</td>\n",
       "      <td>-0.053253</td>\n",
       "      <td>-0.025686</td>\n",
       "      <td>-0.058288</td>\n",
       "      <td>-0.023647</td>\n",
       "      <td>-0.054030</td>\n",
       "      <td>-0.193399</td>\n",
       "      <td>-0.644567</td>\n",
       "      <td>-0.350849</td>\n",
       "      <td>-0.519953</td>\n",
       "      <td>-0.361865</td>\n",
       "      <td>-0.554593</td>\n",
       "      <td>-0.305333</td>\n",
       "      <td>-0.330261</td>\n",
       "      <td>-0.057182</td>\n",
       "      <td>-0.055192</td>\n",
       "      <td>-0.166945</td>\n",
       "      <td>-0.097163</td>\n",
       "      <td>-0.280660</td>\n",
       "      <td>-0.205521</td>\n",
       "      <td>-0.231477</td>\n",
       "      <td>-0.166902</td>\n",
       "      <td>-0.218551</td>\n",
       "      <td>-0.185957</td>\n",
       "      <td>-0.020118</td>\n",
       "      <td>-0.032832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002464</td>\n",
       "      <td>-0.030684</td>\n",
       "      <td>-0.285319</td>\n",
       "      <td>-0.318253</td>\n",
       "      <td>-0.312185</td>\n",
       "      <td>-0.455489</td>\n",
       "      <td>-0.539229</td>\n",
       "      <td>-0.634302</td>\n",
       "      <td>0.008164</td>\n",
       "      <td>-0.257434</td>\n",
       "      <td>-0.338366</td>\n",
       "      <td>-0.361394</td>\n",
       "      <td>-0.157941</td>\n",
       "      <td>-0.054840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.007027</td>\n",
       "      <td>-0.002028</td>\n",
       "      <td>-0.382186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60753</th>\n",
       "      <td>-0.385884</td>\n",
       "      <td>-0.048176</td>\n",
       "      <td>-0.025982</td>\n",
       "      <td>-0.066476</td>\n",
       "      <td>-0.025686</td>\n",
       "      <td>-0.058288</td>\n",
       "      <td>-0.023941</td>\n",
       "      <td>-0.054096</td>\n",
       "      <td>-0.747833</td>\n",
       "      <td>-0.756447</td>\n",
       "      <td>-0.421264</td>\n",
       "      <td>-0.549480</td>\n",
       "      <td>-0.676426</td>\n",
       "      <td>-0.598432</td>\n",
       "      <td>-0.305333</td>\n",
       "      <td>-0.330261</td>\n",
       "      <td>-0.057182</td>\n",
       "      <td>-0.055192</td>\n",
       "      <td>-0.166945</td>\n",
       "      <td>-0.097163</td>\n",
       "      <td>-0.280660</td>\n",
       "      <td>-0.205521</td>\n",
       "      <td>-0.231477</td>\n",
       "      <td>-0.166902</td>\n",
       "      <td>-0.218551</td>\n",
       "      <td>-0.185957</td>\n",
       "      <td>-0.020118</td>\n",
       "      <td>-0.032832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002490</td>\n",
       "      <td>-0.031659</td>\n",
       "      <td>0.186201</td>\n",
       "      <td>0.232255</td>\n",
       "      <td>0.215505</td>\n",
       "      <td>0.017630</td>\n",
       "      <td>-0.611954</td>\n",
       "      <td>-0.634302</td>\n",
       "      <td>-0.388251</td>\n",
       "      <td>-0.257434</td>\n",
       "      <td>-0.338366</td>\n",
       "      <td>-0.361394</td>\n",
       "      <td>-0.157941</td>\n",
       "      <td>-0.054840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.007027</td>\n",
       "      <td>-0.002028</td>\n",
       "      <td>-0.382186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60754</th>\n",
       "      <td>-0.385884</td>\n",
       "      <td>-0.050500</td>\n",
       "      <td>-0.025982</td>\n",
       "      <td>-0.062750</td>\n",
       "      <td>-0.025686</td>\n",
       "      <td>-0.058288</td>\n",
       "      <td>-0.023220</td>\n",
       "      <td>-0.053319</td>\n",
       "      <td>0.613051</td>\n",
       "      <td>0.555592</td>\n",
       "      <td>-0.248426</td>\n",
       "      <td>-0.203212</td>\n",
       "      <td>0.095677</td>\n",
       "      <td>-0.084319</td>\n",
       "      <td>-0.305333</td>\n",
       "      <td>-0.330261</td>\n",
       "      <td>-0.057182</td>\n",
       "      <td>-0.055192</td>\n",
       "      <td>-0.166945</td>\n",
       "      <td>-0.097163</td>\n",
       "      <td>-0.280660</td>\n",
       "      <td>-0.205521</td>\n",
       "      <td>-0.231477</td>\n",
       "      <td>-0.166902</td>\n",
       "      <td>-0.218551</td>\n",
       "      <td>-0.185957</td>\n",
       "      <td>-0.020118</td>\n",
       "      <td>-0.032832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002427</td>\n",
       "      <td>-0.020221</td>\n",
       "      <td>-0.285150</td>\n",
       "      <td>-0.318056</td>\n",
       "      <td>-0.311997</td>\n",
       "      <td>-0.455052</td>\n",
       "      <td>-0.096266</td>\n",
       "      <td>-0.191112</td>\n",
       "      <td>-0.276555</td>\n",
       "      <td>-0.257434</td>\n",
       "      <td>-0.338366</td>\n",
       "      <td>-0.361394</td>\n",
       "      <td>-0.157941</td>\n",
       "      <td>-0.054840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.007027</td>\n",
       "      <td>-0.002028</td>\n",
       "      <td>-0.141058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60755</th>\n",
       "      <td>2.591454</td>\n",
       "      <td>-0.050498</td>\n",
       "      <td>-0.007942</td>\n",
       "      <td>-0.029366</td>\n",
       "      <td>0.005043</td>\n",
       "      <td>0.012627</td>\n",
       "      <td>0.003071</td>\n",
       "      <td>-0.000699</td>\n",
       "      <td>-1.050252</td>\n",
       "      <td>-0.878497</td>\n",
       "      <td>2.945876</td>\n",
       "      <td>3.122572</td>\n",
       "      <td>0.861425</td>\n",
       "      <td>2.373202</td>\n",
       "      <td>2.678866</td>\n",
       "      <td>4.261983</td>\n",
       "      <td>-0.020025</td>\n",
       "      <td>-0.006994</td>\n",
       "      <td>-0.166410</td>\n",
       "      <td>-0.097162</td>\n",
       "      <td>0.059734</td>\n",
       "      <td>0.109081</td>\n",
       "      <td>-0.128094</td>\n",
       "      <td>-0.076134</td>\n",
       "      <td>0.110184</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>-0.004474</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002114</td>\n",
       "      <td>-0.013925</td>\n",
       "      <td>-0.285173</td>\n",
       "      <td>-0.318028</td>\n",
       "      <td>-0.311995</td>\n",
       "      <td>-0.453774</td>\n",
       "      <td>2.259372</td>\n",
       "      <td>3.286218</td>\n",
       "      <td>-0.291948</td>\n",
       "      <td>0.012941</td>\n",
       "      <td>2.821734</td>\n",
       "      <td>2.414344</td>\n",
       "      <td>-0.157941</td>\n",
       "      <td>0.029175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.007027</td>\n",
       "      <td>-0.002028</td>\n",
       "      <td>1.218772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60756</th>\n",
       "      <td>-0.385884</td>\n",
       "      <td>-0.037321</td>\n",
       "      <td>-0.025982</td>\n",
       "      <td>-0.066476</td>\n",
       "      <td>-0.025686</td>\n",
       "      <td>-0.058288</td>\n",
       "      <td>-0.023727</td>\n",
       "      <td>-0.053662</td>\n",
       "      <td>-0.344608</td>\n",
       "      <td>-0.024146</td>\n",
       "      <td>-0.370053</td>\n",
       "      <td>-0.356214</td>\n",
       "      <td>-0.447654</td>\n",
       "      <td>-0.311485</td>\n",
       "      <td>-0.305333</td>\n",
       "      <td>-0.330261</td>\n",
       "      <td>-0.057182</td>\n",
       "      <td>-0.055192</td>\n",
       "      <td>-0.166945</td>\n",
       "      <td>-0.097163</td>\n",
       "      <td>-0.280660</td>\n",
       "      <td>-0.205521</td>\n",
       "      <td>-0.231477</td>\n",
       "      <td>-0.166902</td>\n",
       "      <td>-0.218551</td>\n",
       "      <td>-0.185957</td>\n",
       "      <td>-0.020118</td>\n",
       "      <td>-0.032832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002471</td>\n",
       "      <td>-0.025275</td>\n",
       "      <td>0.114816</td>\n",
       "      <td>0.148911</td>\n",
       "      <td>0.135616</td>\n",
       "      <td>0.189375</td>\n",
       "      <td>-0.347499</td>\n",
       "      <td>-0.356222</td>\n",
       "      <td>-0.388241</td>\n",
       "      <td>-0.257434</td>\n",
       "      <td>-0.338366</td>\n",
       "      <td>-0.361394</td>\n",
       "      <td>-0.157941</td>\n",
       "      <td>-0.054840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.007027</td>\n",
       "      <td>-0.002028</td>\n",
       "      <td>-0.192044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60757 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          proto    srcPrt    dstPrt  flowduration  total_fpackets  \\\n",
       "0     -0.385884 -0.049618 -0.025982     -0.012041       -0.025686   \n",
       "1     -0.385884 -0.050379 -0.025982     -0.066477       -0.025686   \n",
       "2     -0.385884 -0.050500 -0.025982     -0.053705       -0.021845   \n",
       "3     -0.385884 -0.037321 -0.025982     -0.065317       -0.025686   \n",
       "4     -0.385884 -0.050172 -0.025982     -0.066476       -0.025686   \n",
       "...         ...       ...       ...           ...             ...   \n",
       "60752 -0.385884 -0.050455 -0.025982     -0.053253       -0.025686   \n",
       "60753 -0.385884 -0.048176 -0.025982     -0.066476       -0.025686   \n",
       "60754 -0.385884 -0.050500 -0.025982     -0.062750       -0.025686   \n",
       "60755  2.591454 -0.050498 -0.007942     -0.029366        0.005043   \n",
       "60756 -0.385884 -0.037321 -0.025982     -0.066476       -0.025686   \n",
       "\n",
       "       total_bpackets  total_fpktl  total_bpktl  min_fpktl  min_bpktl  \\\n",
       "0           -0.058288    -0.023968    -0.052222  -0.798236   2.406686   \n",
       "1           -0.058288    -0.023727    -0.053662  -0.344608  -0.024146   \n",
       "2           -0.051196    -0.021005    -0.053180   0.310632  -0.471663   \n",
       "3           -0.058288    -0.023727    -0.054048  -0.344608  -0.675080   \n",
       "4           -0.058288    -0.023647    -0.053355  -0.193399   0.494567   \n",
       "...               ...          ...          ...        ...        ...   \n",
       "60752       -0.058288    -0.023647    -0.054030  -0.193399  -0.644567   \n",
       "60753       -0.058288    -0.023941    -0.054096  -0.747833  -0.756447   \n",
       "60754       -0.058288    -0.023220    -0.053319   0.613051   0.555592   \n",
       "60755        0.012627     0.003071    -0.000699  -1.050252  -0.878497   \n",
       "60756       -0.058288    -0.023727    -0.053662  -0.344608  -0.024146   \n",
       "\n",
       "       max_fpktl  max_bpktl  mean_fpktl  mean_bpktl  std_fpktl  std_bpktl  \\\n",
       "0      -0.427666   0.285321   -0.705022    0.641017  -0.305333  -0.330261   \n",
       "1      -0.370053  -0.356214   -0.447654   -0.311485  -0.305333  -0.330261   \n",
       "2      -0.274032  -0.393794   -0.047305   -0.427061  -0.281502  -0.194041   \n",
       "3      -0.370053  -0.528006   -0.447654   -0.566549  -0.305333  -0.330261   \n",
       "4      -0.350849  -0.219318   -0.361865   -0.108232  -0.305333  -0.330261   \n",
       "...          ...        ...         ...         ...        ...        ...   \n",
       "60752  -0.350849  -0.519953   -0.361865   -0.554593  -0.305333  -0.330261   \n",
       "60753  -0.421264  -0.549480   -0.676426   -0.598432  -0.305333  -0.330261   \n",
       "60754  -0.248426  -0.203212    0.095677   -0.084319  -0.305333  -0.330261   \n",
       "60755   2.945876   3.122572    0.861425    2.373202   2.678866   4.261983   \n",
       "60756  -0.370053  -0.356214   -0.447654   -0.311485  -0.305333  -0.330261   \n",
       "\n",
       "       total_fipt  total_bipt  min_fipt  min_bipt  max_fipt  max_bipt  \\\n",
       "0       -0.057182   -0.055192 -0.166945 -0.097163 -0.280660 -0.205521   \n",
       "1       -0.057182   -0.055192 -0.166945 -0.097163 -0.280660 -0.205521   \n",
       "2       -0.045593   -0.040162  0.134272  0.253915 -0.131940 -0.067951   \n",
       "3       -0.057182   -0.055192 -0.166945 -0.097163 -0.280660 -0.205521   \n",
       "4       -0.057182   -0.055192 -0.166945 -0.097163 -0.280660 -0.205521   \n",
       "...           ...         ...       ...       ...       ...       ...   \n",
       "60752   -0.057182   -0.055192 -0.166945 -0.097163 -0.280660 -0.205521   \n",
       "60753   -0.057182   -0.055192 -0.166945 -0.097163 -0.280660 -0.205521   \n",
       "60754   -0.057182   -0.055192 -0.166945 -0.097163 -0.280660 -0.205521   \n",
       "60755   -0.020025   -0.006994 -0.166410 -0.097162  0.059734  0.109081   \n",
       "60756   -0.057182   -0.055192 -0.166945 -0.097163 -0.280660 -0.205521   \n",
       "\n",
       "       mean_fipt  mean_bipt  std_fipt  std_bipt  fpsh_cnt  bpsh_cnt  furg_cnt  \\\n",
       "0      -0.231477  -0.166902 -0.218551 -0.185957 -0.020118 -0.032832       0.0   \n",
       "1      -0.231477  -0.166902 -0.218551 -0.185957 -0.020118 -0.032832       0.0   \n",
       "2       0.026489   0.116153 -0.218551 -0.185957 -0.020118 -0.032832       0.0   \n",
       "3      -0.231477  -0.166902 -0.218551 -0.185957 -0.020118 -0.032832       0.0   \n",
       "4      -0.231477  -0.166902 -0.218551 -0.185957 -0.020118 -0.032832       0.0   \n",
       "...          ...        ...       ...       ...       ...       ...       ...   \n",
       "60752  -0.231477  -0.166902 -0.218551 -0.185957 -0.020118 -0.032832       0.0   \n",
       "60753  -0.231477  -0.166902 -0.218551 -0.185957 -0.020118 -0.032832       0.0   \n",
       "60754  -0.231477  -0.166902 -0.218551 -0.185957 -0.020118 -0.032832       0.0   \n",
       "60755  -0.128094  -0.076134  0.110184  0.089552 -0.004474  0.007605       0.0   \n",
       "60756  -0.231477  -0.166902 -0.218551 -0.185957 -0.020118 -0.032832       0.0   \n",
       "\n",
       "       burg_cnt  total_fhlen  total_bhlen  fPktsPerSecond  bPktsPerSecond  \\\n",
       "0           0.0    -0.002492    -0.004083       -0.285369       -0.318312   \n",
       "1           0.0    -0.002471    -0.025275        0.423393        0.509180   \n",
       "2           0.0    -0.002312    -0.021196       -0.285248       -0.318170   \n",
       "3           0.0    -0.002471    -0.030950       -0.284632       -0.317451   \n",
       "4           0.0    -0.002464    -0.020753        0.209234        0.259146   \n",
       "...         ...          ...          ...             ...             ...   \n",
       "60752       0.0    -0.002464    -0.030684       -0.285319       -0.318253   \n",
       "60753       0.0    -0.002490    -0.031659        0.186201        0.232255   \n",
       "60754       0.0    -0.002427    -0.020221       -0.285150       -0.318056   \n",
       "60755       0.0    -0.002114    -0.013925       -0.285173       -0.318028   \n",
       "60756       0.0    -0.002471    -0.025275        0.114816        0.148911   \n",
       "\n",
       "       flowPktsPerSecond  flowBytesPerSecond  mean_flowpktl  std_flowpktl  \\\n",
       "0              -0.312241           -0.455512       0.412811      0.721339   \n",
       "1               0.480953            0.686660      -0.347499     -0.356222   \n",
       "2              -0.312106           -0.455361      -0.397084     -0.528286   \n",
       "3              -0.311416           -0.454719      -0.559063     -0.634302   \n",
       "4               0.241282            0.544569      -0.168991     -0.147662   \n",
       "...                  ...                 ...            ...           ...   \n",
       "60752          -0.312185           -0.455489      -0.539229     -0.634302   \n",
       "60753           0.215505            0.017630      -0.611954     -0.634302   \n",
       "60754          -0.311997           -0.455052      -0.096266     -0.191112   \n",
       "60755          -0.311995           -0.453774       2.259372      3.286218   \n",
       "60756           0.135616            0.189375      -0.347499     -0.356222   \n",
       "\n",
       "       mean_flowipt  std_flowipt  flow_fin  flow_syn  flow_rst  flow_ack  \\\n",
       "0          1.243683    -0.257434 -0.338366 -0.361394 -0.157941 -0.054840   \n",
       "1         -0.388270    -0.257434 -0.338366 -0.361394 -0.157941 -0.054840   \n",
       "2         -0.248679    -0.050418 -0.338366 -0.361394 -0.157941 -0.054840   \n",
       "3         -0.353494    -0.257434 -0.338366 -0.361394 -0.157941 -0.054840   \n",
       "4         -0.388254    -0.257434 -0.338366 -0.361394 -0.157941 -0.054840   \n",
       "...             ...          ...       ...       ...       ...       ...   \n",
       "60752      0.008164    -0.257434 -0.338366 -0.361394 -0.157941 -0.054840   \n",
       "60753     -0.388251    -0.257434 -0.338366 -0.361394 -0.157941 -0.054840   \n",
       "60754     -0.276555    -0.257434 -0.338366 -0.361394 -0.157941 -0.054840   \n",
       "60755     -0.291948     0.012941  2.821734  2.414344 -0.157941  0.029175   \n",
       "60756     -0.388241    -0.257434 -0.338366 -0.361394 -0.157941 -0.054840   \n",
       "\n",
       "       flow_urg  flow_cwr  flow_ece  downUpRatio  \n",
       "0           0.0 -0.007027 -0.002028     0.673101  \n",
       "1           0.0 -0.007027 -0.002028    -0.192044  \n",
       "2           0.0 -0.007027 -0.002028    -0.329721  \n",
       "3           0.0 -0.007027 -0.002028    -0.382186  \n",
       "4           0.0 -0.007027 -0.002028    -0.062402  \n",
       "...         ...       ...       ...          ...  \n",
       "60752       0.0 -0.007027 -0.002028    -0.382186  \n",
       "60753       0.0 -0.007027 -0.002028    -0.382186  \n",
       "60754       0.0 -0.007027 -0.002028    -0.141058  \n",
       "60755       0.0 -0.007027 -0.002028     1.218772  \n",
       "60756       0.0 -0.007027 -0.002028    -0.192044  \n",
       "\n",
       "[60757 rows x 48 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_test_stand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection\n",
    "`VarianceThreshold` is a simple baseline approach to feature selection. It removes all features whose variance doesn’t meet some threshold. Defining and Fiting Threshold\n",
    "For quasi-constant features, that have the same value for a very large subset, i.e. using threshold as 0.01 would mean dropping the column where 99% of the values are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True,  True,  True])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the VarianceThreshold class from sklearn support a type of feature selection\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "var_thr = VarianceThreshold(threshold = 0.25) #.25 would mean dropping the column where 75% of the values are similar.\n",
    "# fit on the trainning dataset\n",
    "var_thr.fit(df_X_train_stand)\n",
    "# Get a mask of the selected features \n",
    "var_thr.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "furg_cnt\n",
      "burg_cnt\n",
      "flow_urg\n"
     ]
    }
   ],
   "source": [
    "#Show features that do not meet the threshold\n",
    "concol = [column for column in df_X_train_stand.columns \n",
    "          if column not in df_X_train_stand.columns[var_thr.get_support()]]\n",
    "\n",
    "for features in concol:\n",
    "    print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping Low Variance Columns:\n",
    "df_X_train_stand.drop(concol,axis=1,inplace=True)\n",
    "df_X_test_stand.drop(concol,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['proto', 'srcPrt', 'dstPrt', 'flowduration', 'total_fpackets',\n",
       "       'total_bpackets', 'total_fpktl', 'total_bpktl', 'min_fpktl',\n",
       "       'min_bpktl', 'max_fpktl', 'max_bpktl', 'mean_fpktl', 'mean_bpktl',\n",
       "       'std_fpktl', 'std_bpktl', 'total_fipt', 'total_bipt', 'min_fipt',\n",
       "       'min_bipt', 'max_fipt', 'max_bipt', 'mean_fipt', 'mean_bipt',\n",
       "       'std_fipt', 'std_bipt', 'fpsh_cnt', 'bpsh_cnt', 'total_fhlen',\n",
       "       'total_bhlen', 'fPktsPerSecond', 'bPktsPerSecond', 'flowPktsPerSecond',\n",
       "       'flowBytesPerSecond', 'mean_flowpktl', 'std_flowpktl', 'mean_flowipt',\n",
       "       'std_flowipt', 'flow_fin', 'flow_syn', 'flow_rst', 'flow_ack',\n",
       "       'flow_cwr', 'flow_ece', 'downUpRatio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show selected features\n",
    "df_X_train_stand.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((243027, 45), (60757, 45))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##final dataset dimensions\n",
    "df_X_train_stand.shape,df_X_test_stand.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Weighted Logistic Regression (W-LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run grid search only on training set using cross-validation\n",
    "parameters={'C':np.logspace(-3,3,7), 'penalty':[\"l1\",\"l2\"]}# l1 lasso l2 ridge\n",
    "model1=GridSearchCV(LogisticRegression(class_weight='balanced', solver='saga' ,max_iter=1000),parameters,cv=5, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "[CV 1/5] END ...............C=0.001, penalty=l1;, score=0.995 total time= 1.1min\n",
      "[CV 2/5] END ...............C=0.001, penalty=l1;, score=0.996 total time= 2.4min\n",
      "[CV 3/5] END ...............C=0.001, penalty=l1;, score=0.996 total time= 1.7min\n",
      "[CV 4/5] END ...............C=0.001, penalty=l1;, score=0.997 total time= 1.8min\n",
      "[CV 5/5] END ...............C=0.001, penalty=l1;, score=0.996 total time= 1.6min\n",
      "[CV 1/5] END ...............C=0.001, penalty=l2;, score=0.996 total time= 1.4min\n",
      "[CV 2/5] END ...............C=0.001, penalty=l2;, score=0.996 total time= 2.4min\n",
      "[CV 3/5] END ...............C=0.001, penalty=l2;, score=0.996 total time= 1.8min\n",
      "[CV 4/5] END ...............C=0.001, penalty=l2;, score=0.998 total time= 2.3min\n",
      "[CV 5/5] END ...............C=0.001, penalty=l2;, score=0.996 total time= 2.1min\n",
      "[CV 1/5] END ................C=0.01, penalty=l1;, score=0.996 total time= 2.9min\n",
      "[CV 2/5] END ................C=0.01, penalty=l1;, score=0.997 total time= 2.9min\n",
      "[CV 3/5] END ................C=0.01, penalty=l1;, score=0.996 total time= 2.9min\n",
      "[CV 4/5] END ................C=0.01, penalty=l1;, score=0.998 total time= 2.9min\n",
      "[CV 5/5] END ................C=0.01, penalty=l1;, score=0.996 total time= 2.8min\n",
      "[CV 1/5] END ................C=0.01, penalty=l2;, score=0.995 total time= 2.6min\n",
      "[CV 2/5] END ................C=0.01, penalty=l2;, score=0.997 total time= 2.6min\n",
      "[CV 3/5] END ................C=0.01, penalty=l2;, score=0.996 total time= 2.6min\n",
      "[CV 4/5] END ................C=0.01, penalty=l2;, score=0.998 total time= 2.6min\n",
      "[CV 5/5] END ................C=0.01, penalty=l2;, score=0.996 total time= 2.6min\n",
      "[CV 1/5] END .................C=0.1, penalty=l1;, score=0.995 total time= 2.9min\n",
      "[CV 2/5] END .................C=0.1, penalty=l1;, score=0.997 total time= 2.9min\n",
      "[CV 3/5] END .................C=0.1, penalty=l1;, score=0.996 total time= 2.9min\n",
      "[CV 4/5] END .................C=0.1, penalty=l1;, score=0.998 total time= 2.9min\n",
      "[CV 5/5] END .................C=0.1, penalty=l1;, score=0.996 total time= 2.9min\n",
      "[CV 1/5] END .................C=0.1, penalty=l2;, score=0.995 total time= 2.6min\n",
      "[CV 2/5] END .................C=0.1, penalty=l2;, score=0.997 total time= 2.6min\n",
      "[CV 3/5] END .................C=0.1, penalty=l2;, score=0.996 total time= 2.6min\n",
      "[CV 4/5] END .................C=0.1, penalty=l2;, score=0.998 total time= 2.6min\n",
      "[CV 5/5] END .................C=0.1, penalty=l2;, score=0.996 total time= 2.6min\n",
      "[CV 1/5] END .................C=1.0, penalty=l1;, score=0.995 total time= 2.9min\n",
      "[CV 2/5] END .................C=1.0, penalty=l1;, score=0.997 total time= 2.9min\n",
      "[CV 3/5] END .................C=1.0, penalty=l1;, score=0.996 total time= 2.9min\n",
      "[CV 4/5] END .................C=1.0, penalty=l1;, score=0.998 total time= 2.9min\n",
      "[CV 5/5] END .................C=1.0, penalty=l1;, score=0.996 total time= 2.9min\n",
      "[CV 1/5] END .................C=1.0, penalty=l2;, score=0.995 total time= 2.6min\n",
      "[CV 2/5] END .................C=1.0, penalty=l2;, score=0.997 total time= 2.6min\n",
      "[CV 3/5] END .................C=1.0, penalty=l2;, score=0.996 total time= 2.6min\n",
      "[CV 4/5] END .................C=1.0, penalty=l2;, score=0.998 total time= 2.6min\n",
      "[CV 5/5] END .................C=1.0, penalty=l2;, score=0.996 total time= 2.6min\n",
      "[CV 1/5] END ................C=10.0, penalty=l1;, score=0.995 total time= 3.0min\n",
      "[CV 2/5] END ................C=10.0, penalty=l1;, score=0.997 total time= 2.9min\n",
      "[CV 3/5] END ................C=10.0, penalty=l1;, score=0.996 total time= 2.9min\n",
      "[CV 4/5] END ................C=10.0, penalty=l1;, score=0.998 total time= 2.9min\n",
      "[CV 5/5] END ................C=10.0, penalty=l1;, score=0.996 total time= 3.0min\n",
      "[CV 1/5] END ................C=10.0, penalty=l2;, score=0.995 total time= 2.6min\n",
      "[CV 2/5] END ................C=10.0, penalty=l2;, score=0.997 total time= 2.6min\n",
      "[CV 3/5] END ................C=10.0, penalty=l2;, score=0.996 total time= 2.6min\n",
      "[CV 4/5] END ................C=10.0, penalty=l2;, score=0.998 total time= 2.6min\n",
      "[CV 5/5] END ................C=10.0, penalty=l2;, score=0.996 total time= 2.7min\n",
      "[CV 1/5] END ...............C=100.0, penalty=l1;, score=0.995 total time= 3.0min\n",
      "[CV 2/5] END ...............C=100.0, penalty=l1;, score=0.997 total time= 2.8min\n",
      "[CV 3/5] END ...............C=100.0, penalty=l1;, score=0.996 total time= 2.8min\n",
      "[CV 4/5] END ...............C=100.0, penalty=l1;, score=0.998 total time= 2.8min\n",
      "[CV 5/5] END ...............C=100.0, penalty=l1;, score=0.996 total time= 2.8min\n",
      "[CV 1/5] END ...............C=100.0, penalty=l2;, score=0.995 total time= 2.5min\n",
      "[CV 2/5] END ...............C=100.0, penalty=l2;, score=0.997 total time= 2.5min\n",
      "[CV 3/5] END ...............C=100.0, penalty=l2;, score=0.996 total time= 2.4min\n",
      "[CV 4/5] END ...............C=100.0, penalty=l2;, score=0.998 total time= 2.4min\n",
      "[CV 5/5] END ...............C=100.0, penalty=l2;, score=0.996 total time= 2.4min\n",
      "[CV 1/5] END ..............C=1000.0, penalty=l1;, score=0.995 total time= 2.7min\n",
      "[CV 2/5] END ..............C=1000.0, penalty=l1;, score=0.997 total time= 2.7min\n",
      "[CV 3/5] END ..............C=1000.0, penalty=l1;, score=0.996 total time= 2.7min\n",
      "[CV 4/5] END ..............C=1000.0, penalty=l1;, score=0.998 total time= 2.7min\n",
      "[CV 5/5] END ..............C=1000.0, penalty=l1;, score=0.996 total time= 2.8min\n",
      "[CV 1/5] END ..............C=1000.0, penalty=l2;, score=0.995 total time= 2.4min\n",
      "[CV 2/5] END ..............C=1000.0, penalty=l2;, score=0.997 total time= 2.4min\n",
      "[CV 3/5] END ..............C=1000.0, penalty=l2;, score=0.996 total time= 2.4min\n",
      "[CV 4/5] END ..............C=1000.0, penalty=l2;, score=0.998 total time= 2.4min\n",
      "[CV 5/5] END ..............C=1000.0, penalty=l2;, score=0.996 total time= 2.4min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=LogisticRegression(class_weight='balanced',\n",
       "                                          max_iter=1000, solver='saga'),\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit on the trainning dataset\n",
    "model1.fit(df_X_train_stand,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'C': 0.001, 'penalty': 'l2'}\n",
      "accuracy : 0.996440727909718\n"
     ]
    }
   ],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",model1.best_params_)\n",
    "print(\"accuracy :\",model1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = model1.predict(df_X_test_stand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      1.00      1.00     60710\n",
      "     class 1       0.13      0.85      0.22        47\n",
      "\n",
      "    accuracy                           1.00     60757\n",
      "   macro avg       0.56      0.92      0.61     60757\n",
      "weighted avg       1.00      1.00      1.00     60757\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#performance results\n",
    "print(classification_report(y_test, y_pred1, target_names=target_names))\n",
    "plot_confusion_matrix(model1, df_X_test_stand, y_test, display_labels=target_names,cmap=plt.cm.Blues);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Over-sampling with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origianl dataset shape: Counter({0: 242877, 1: 150})\n",
      "Resample dataset shape: Counter({0: 242877, 1: 242877})\n"
     ]
    }
   ],
   "source": [
    "# load library\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE()\n",
    "\n",
    "# fit on the trainning dataset\n",
    "X_smote , y_smote = smote.fit_resample(df_X_train_stand, y_train)\n",
    "\n",
    "print('Origianl dataset shape:', Counter(y_train))\n",
    "print('Resample dataset shape:', Counter(y_smote))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### b) Logistic Regression with Synthetic minority over-sampling technique (LR+SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "[CV 1/5] END ...............C=0.001, penalty=l1;, score=0.995 total time= 2.8min\n",
      "[CV 2/5] END ...............C=0.001, penalty=l1;, score=0.995 total time= 2.9min\n",
      "[CV 3/5] END ...............C=0.001, penalty=l1;, score=0.994 total time= 2.8min\n",
      "[CV 4/5] END ...............C=0.001, penalty=l1;, score=0.994 total time= 2.8min\n",
      "[CV 5/5] END ...............C=0.001, penalty=l1;, score=0.994 total time= 2.9min\n",
      "[CV 1/5] END ...............C=0.001, penalty=l2;, score=0.997 total time= 4.3min\n",
      "[CV 2/5] END ...............C=0.001, penalty=l2;, score=0.997 total time= 4.3min\n",
      "[CV 3/5] END ...............C=0.001, penalty=l2;, score=0.997 total time= 4.4min\n",
      "[CV 4/5] END ...............C=0.001, penalty=l2;, score=0.997 total time= 4.4min\n",
      "[CV 5/5] END ...............C=0.001, penalty=l2;, score=0.997 total time= 4.4min\n",
      "[CV 1/5] END ................C=0.01, penalty=l1;, score=0.998 total time= 6.0min\n",
      "[CV 2/5] END ................C=0.01, penalty=l1;, score=0.998 total time= 6.0min\n",
      "[CV 3/5] END ................C=0.01, penalty=l1;, score=0.997 total time= 6.1min\n",
      "[CV 4/5] END ................C=0.01, penalty=l1;, score=0.997 total time= 6.2min\n",
      "[CV 5/5] END ................C=0.01, penalty=l1;, score=0.998 total time= 6.3min\n",
      "[CV 1/5] END ................C=0.01, penalty=l2;, score=0.998 total time= 6.0min\n",
      "[CV 2/5] END ................C=0.01, penalty=l2;, score=0.998 total time= 6.0min\n",
      "[CV 3/5] END ................C=0.01, penalty=l2;, score=0.998 total time= 7.0min\n",
      "[CV 4/5] END ................C=0.01, penalty=l2;, score=0.998 total time= 8.1min\n",
      "[CV 5/5] END ................C=0.01, penalty=l2;, score=0.998 total time= 6.0min\n",
      "[CV 1/5] END .................C=0.1, penalty=l1;, score=0.999 total time= 7.0min\n",
      "[CV 2/5] END .................C=0.1, penalty=l1;, score=0.998 total time= 7.1min\n",
      "[CV 3/5] END .................C=0.1, penalty=l1;, score=0.999 total time= 7.0min\n",
      "[CV 4/5] END .................C=0.1, penalty=l1;, score=0.999 total time= 7.0min\n",
      "[CV 5/5] END .................C=0.1, penalty=l1;, score=0.999 total time= 6.8min\n",
      "[CV 1/5] END .................C=0.1, penalty=l2;, score=0.999 total time= 6.4min\n",
      "[CV 2/5] END .................C=0.1, penalty=l2;, score=0.999 total time= 6.4min\n",
      "[CV 3/5] END .................C=0.1, penalty=l2;, score=0.999 total time= 6.3min\n",
      "[CV 4/5] END .................C=0.1, penalty=l2;, score=0.999 total time= 6.4min\n",
      "[CV 5/5] END .................C=0.1, penalty=l2;, score=0.999 total time= 6.5min\n",
      "[CV 1/5] END .................C=1.0, penalty=l1;, score=0.999 total time= 7.0min\n",
      "[CV 2/5] END .................C=1.0, penalty=l1;, score=0.999 total time= 7.0min\n",
      "[CV 3/5] END .................C=1.0, penalty=l1;, score=0.999 total time= 7.2min\n",
      "[CV 4/5] END .................C=1.0, penalty=l1;, score=0.999 total time= 7.0min\n",
      "[CV 5/5] END .................C=1.0, penalty=l1;, score=0.999 total time= 6.9min\n",
      "[CV 1/5] END .................C=1.0, penalty=l2;, score=0.999 total time= 6.4min\n",
      "[CV 2/5] END .................C=1.0, penalty=l2;, score=0.999 total time= 6.4min\n",
      "[CV 3/5] END .................C=1.0, penalty=l2;, score=0.999 total time= 6.1min\n",
      "[CV 4/5] END .................C=1.0, penalty=l2;, score=0.999 total time= 6.5min\n",
      "[CV 5/5] END .................C=1.0, penalty=l2;, score=0.999 total time= 6.4min\n",
      "[CV 1/5] END ................C=10.0, penalty=l1;, score=0.999 total time= 6.9min\n",
      "[CV 2/5] END ................C=10.0, penalty=l1;, score=0.999 total time= 6.9min\n",
      "[CV 3/5] END ................C=10.0, penalty=l1;, score=0.999 total time= 6.8min\n",
      "[CV 4/5] END ................C=10.0, penalty=l1;, score=0.999 total time= 6.5min\n",
      "[CV 5/5] END ................C=10.0, penalty=l1;, score=0.999 total time= 6.4min\n",
      "[CV 1/5] END ................C=10.0, penalty=l2;, score=0.999 total time= 5.7min\n",
      "[CV 2/5] END ................C=10.0, penalty=l2;, score=0.999 total time= 5.7min\n",
      "[CV 3/5] END ................C=10.0, penalty=l2;, score=0.999 total time= 5.6min\n",
      "[CV 4/5] END ................C=10.0, penalty=l2;, score=0.999 total time= 5.7min\n",
      "[CV 5/5] END ................C=10.0, penalty=l2;, score=0.999 total time= 5.7min\n",
      "[CV 1/5] END ...............C=100.0, penalty=l1;, score=0.999 total time= 6.3min\n",
      "[CV 2/5] END ...............C=100.0, penalty=l1;, score=0.999 total time= 6.3min\n",
      "[CV 3/5] END ...............C=100.0, penalty=l1;, score=0.999 total time= 6.2min\n",
      "[CV 4/5] END ...............C=100.0, penalty=l1;, score=0.999 total time= 6.2min\n",
      "[CV 5/5] END ...............C=100.0, penalty=l1;, score=0.999 total time= 6.2min\n",
      "[CV 1/5] END ...............C=100.0, penalty=l2;, score=0.999 total time= 5.5min\n",
      "[CV 2/5] END ...............C=100.0, penalty=l2;, score=0.999 total time= 5.5min\n",
      "[CV 3/5] END ...............C=100.0, penalty=l2;, score=0.999 total time= 5.4min\n",
      "[CV 4/5] END ...............C=100.0, penalty=l2;, score=0.999 total time= 5.4min\n",
      "[CV 5/5] END ...............C=100.0, penalty=l2;, score=0.999 total time= 5.4min\n",
      "[CV 1/5] END ..............C=1000.0, penalty=l1;, score=0.999 total time= 6.0min\n",
      "[CV 2/5] END ..............C=1000.0, penalty=l1;, score=0.999 total time= 6.0min\n",
      "[CV 3/5] END ..............C=1000.0, penalty=l1;, score=0.999 total time= 6.0min\n",
      "[CV 4/5] END ..............C=1000.0, penalty=l1;, score=0.999 total time= 6.0min\n",
      "[CV 5/5] END ..............C=1000.0, penalty=l1;, score=0.999 total time= 6.0min\n",
      "[CV 1/5] END ..............C=1000.0, penalty=l2;, score=0.999 total time= 5.4min\n",
      "[CV 2/5] END ..............C=1000.0, penalty=l2;, score=0.999 total time= 5.4min\n",
      "[CV 3/5] END ..............C=1000.0, penalty=l2;, score=0.999 total time= 5.4min\n",
      "[CV 4/5] END ..............C=1000.0, penalty=l2;, score=0.999 total time= 5.4min\n",
      "[CV 5/5] END ..............C=1000.0, penalty=l2;, score=0.999 total time= 5.4min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=1000, solver='saga'),\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run grid search only on training set using cross-validation\n",
    "parameters={'C':np.logspace(-3,3,7), 'penalty':[\"l1\",\"l2\"]}# l1 lasso l2 ridge\n",
    "model2=GridSearchCV(LogisticRegression(solver='saga' ,max_iter=1000),parameters,cv=5, verbose=3)\n",
    "model2.fit(X_smote,y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'C': 10.0, 'penalty': 'l1'}\n",
      "accuracy : 0.9988059802147113\n",
      "Best Model: LogisticRegression(C=10.0, max_iter=1000, penalty='l1', solver='saga')\n"
     ]
    }
   ],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",model2.best_params_)\n",
    "print(\"accuracy :\",model2.best_score_)\n",
    "print('Best Model:',model2.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2=model2.predict(df_X_test_stand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      1.00      1.00     60710\n",
      "     class 1       0.19      0.81      0.31        47\n",
      "\n",
      "    accuracy                           1.00     60757\n",
      "   macro avg       0.59      0.90      0.65     60757\n",
      "weighted avg       1.00      1.00      1.00     60757\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAEICAYAAACOBEVFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAjz0lEQVR4nO3de5zVVb3/8dd7GAFRQEEwAhQvaArekkzzHPNSiWli/dTITOxwJE3TLifFy/HWoexYqWRa3hLvkley1DyY1whEU1HMpLyhCCKoqKAMfn5/fNfoZtyzZ4/OzPc7e97PHt/H3rP2d629vsyjzyzXd30/SxGBmZnloy7vDpiZdWUOwmZmOXIQNjPLkYOwmVmOHITNzHLkIGxmliMHYTPrUiStI+k6SX+X9ISknST1k3SHpKfS67ol5x8vaZ6kJyXtWVK+vaQ56bPJkpTKe0i6NpXPlDSsYn+68jph1a8Z6t47725YK2y3xQZ5d8Fa4dlnn2Hx4sX6KG1067NhRMPyqs6N5S/fHhGjK50jaQpwb0RcJKk70As4AVgSEWdImgisGxHHSdoSuBrYAfg48H/AZhGxStIs4Bjgr8AfgckRcaukbwNbR8ThksYCX46IrzbXn/qqrqxGqXtvemx+YN7dsFa4f+a5eXfBWmHnT4/6yG1Ew/Kq/3+64uFfrVfpc0l9gF2AQwEi4h3gHUljgF3TaVOAu4DjgDHANRHxNvC0pHnADpKeAfpExIzU7mXAfsCtqc6pqa3rgHMlKZoZ8Xo6wswKTqC66g5YT9LskmNCk8Y2Bl4Gfivpb5IukrQWsH5ELABIrwPT+YOB50vqz09lg9P7puWr1YmIBuA1oH9zV9elR8Jm1gkIqOtW7dmLI6LS8Lse+CTwnYiYKekcYGIL395UVCivVKcsj4TNrPik6o6WzQfmR8TM9PN1ZEF5oaRB2VdpELCo5PyhJfWHAC+m8iFlylerI6ke6Assaa5DDsJmVnCtmo6oKCJeAp6XtHkq2gOYC0wDxqWyccDN6f00YGxa8bARMByYlaYslknaMa2KOKRJnca29gfubG4+GDwdYWadQXWj3Gp9B7gyrYz4F/BNsgHpVEnjgeeAAwAi4nFJU8kCdQNwZESsSu0cAVwKrEl2Q+7WVH4xcHm6ibcEGFupMw7CZlZsoqpRbrUi4mGg3LzxHs2cPwmYVKZ8NjCyTPkKUhCvhoOwmRVc1fO9nZKDsJkVX/WrIzodB2EzKzi16XRE0TgIm1mxCU9HmJnlyiNhM7O8eDrCzCw/Arr5xpyZWX48J2xmlhdPR5iZ5csjYTOzHHkkbGaWk+rTVHZKDsJmVnx+bNnMLC++MWdmli9PR5iZ5aSN8wkXjYOwmRWcpyPMzPLlG3NmZjnynLCZWU7k6Qgzs3x5JGxmlh85CJuZ5SPb3chB2MwsHxKqcxA2M8uNR8JmZjlyEDYzy1EtB+HaXXxnZrVBrTiqaU56RtIcSQ9Lmp3K+km6Q9JT6XXdkvOPlzRP0pOS9iwp3z61M0/SZKW/FJJ6SLo2lc+UNKxSfxyEzazQhJCqO1pht4jYNiJGpZ8nAtMjYjgwPf2MpC2BscAIYDRwnqTGZ6jPByYAw9MxOpWPB5ZGxKbAWcBPK3XEQdjMCq+urq6q4yMYA0xJ76cA+5WUXxMRb0fE08A8YAdJg4A+ETEjIgK4rEmdxrauA/ZQhb8QDsJmVnitGAmvJ2l2yTGhTHMB/EnSgyWfrx8RCwDS68BUPhh4vqTu/FQ2OL1vWr5anYhoAF4D+jd3bb4xZ2bF1or5XmBxyRRDc3aOiBclDQTukPT3Fr69qahQXqlOWR4Jm1nhteWccES8mF4XATcCOwAL0xQD6XVROn0+MLSk+hDgxVQ+pEz5anUk1QN9gSXN9cdB2MwKrS1vzElaS1LvxvfAF4DHgGnAuHTaOODm9H4aMDateNiI7AbcrDRlsUzSjmm+95AmdRrb2h+4M80bl+XpCDMrvDZ8bHl94MYUsOuBqyLiNkkPAFMljQeeAw4AiIjHJU0F5gINwJERsSq1dQRwKbAmcGs6AC4GLpc0j2wEPLZShxyEzazY1HYPa0TEv4BtypS/AuzRTJ1JwKQy5bOBkWXKV5CCeDUchM2s8Gr5iTkHYTMrPAdhM7OcNN6Yq1UOwmZWfLUbgx2EzazgxEd9JLnQHITNrPA8HWFmlqfajcEOwkXWZ+01mXzSQWyxySAi4Ds/upKnnl3IJT/+DzYY1I/nFizhm8dfzGvLljN0UD9mTj2Jec9lT1vOnvMM3z/jmtXau+rn32LY4P58ZuyPARiy/rqcd+o36Nt7TbrV1XHauTdzx1/mdvh11rqjTr+C2+97jPXW7c2Ma098r/yCa+/iwqn3UN+tjs//20hOP3o//jzzCU47dxrvrGyg+xr1nH70fuzyqc1z7H0xeCTcRiSdCrwRET9rh7a35/2nV/4IHFPpUcHO4Iwf7M/0GXM5dOLFrFHfjTV7ducH3/wC9zzwJGdPuYPvjvs83xv3BU49N3ta8pkXFrPL188o29Y+u23Dm2+9vVrZD8aP5qb/e4hLrr+PzTf6GFPPPoJtxpzS7tfV1Xxtnx057MDPcvgpl71Xdu/sf/DHu+dw39XH06P7Gry8ZBkA/ddZm6t/8S0GDViHufNeZP+jf8XcP37gOYEu5UPkCu5Uamm2u7kEy51S77V68pntNuHym2cAsLJhFa+/sZy9Prs1V98yE4Crb5nJF3fdusW21lqzO0cetDs/u+S21T+IoPdaPYFs1P3S4tfa9iIMgJ0/uSnr9um1Wtkl19/Ld8d9nh7d1wBgQL/eAGy9+VAGDVgHgC02GcSKd1by9jsrO7S/RdQOSd0Lo92CsKRDJD0q6RFJl5f5/DBJD6TPr5fUK5UfIOmxVH5PKhshaZay7UgelTS8SVuVEix3ShsO7s/iV9/gV6cczN1XHMc5Jx5Er57dGdivNwtfeR2Aha+8zoB1e79XZ4OP9+fuK47jlt8cw07bbvJe+QmH78O5V07nrRXvrPYdZ1zwRw7cawceu+VHTD37CI4983cdc3HGvGcXMePhf/K5Q89k7wln89Djz37gnGl3PszWmw19L1B3ZapTVUdn1C5BWNII4ERg94jYBjimzGk3RMSn0udPkG0JAnAysGcq3zeVHQ6cExHbAqNYPZkyVE6w3LRvExoTPkfD8tZfXAep79aNbTYfyiXX3ctnD/4pb614m+8e+vlmz1+4+HW2+tLJfPbgn3LiWTdw4f8cSu+1ejJys8FsPHQAf7jr0Q/U+X97juKqW/7KyH3+mwO/ez6/Pu2QTjua6GwaVr3Lq8ve4o7f/henH7Mf3zzhEkpnz5745wJO/eXNnHVCxdwvXYZHwq23O3BdRCwGiIhyuTRHSrpX0hzg62R7OAHcD1wq6TCgcS+nGcAJko4DNoyIptGz6iTKEXFBRIyKiFGqX7N1V9WBXly0lBcXvcqDaYQ0bfrDbLP5UBYtWcb6/fsAsH7/Pry8NJtLfGdlA0tfexOAR/7+PE/PX8wmGwxkh602YptPbMAjN5/GrRd+j002GMjvf539TTx4zE7c9H8PAfDAnKfp2WMN+q+zVkdfapc0eOA6fGm3bZDE9iOGUSfxyqtvAPDCwqV849gLOP+0b7DRkAE597QA5CD8YYgKmeSTS4GjImIr4DSgJ0BEHA6cRJYU+WFJ/SPiKrJR8XLgdkm7N2mrUoLlTmnRK8t4YeFSNt0w22Vll09tzpNPv8Rt98zha/t8GoCv7fNpbr07G+H2X2dt6tJ/jm04uD8bDx3AMy8s5pLr72PLL57INmNOYa/DzuKfzy3iS4efA8ALLy157877ZsPWp0f3NVi89I2OvtQu6Yu7bs09D/wDgHnPLuSdlQ30X2dtXlv2Fl/93q85+ch92XGbTVpopWsQIFV3dEbttTpiOlnOzrMi4hVJ/cqMhnsDCyStQTYSfgFA0iYRMROYKelLwFBJfYF/RcRkSRsDWwN3NjYUEQskLZO0IzCTLMHyL9vp2jrMsT/7HRecfijd1+jGMy8s5sjTr6Curo7f/uQ/OHjfnZi/cCmHTrwYgM9stynHH743qxpWserd4AdnXMOrr79Vsf2Tzr6Rc078Gt/+2m4EcORpH5i6tzYw/sTfcv+DT/HKq28wYu+TmDjhixy8704cdfqV7PTVSXRfoxvnn/oNJHHh1Ht4+vmXOfOi2zjzouxG6g3nHvXejbuuqfOOcquh9lrFJWkc8ENgFfC3iDi0dImapCOAY4FngTlA73TODWSrG0QWzL9Ltv30wcBK4CXgoKZBXdIoVk+w/J2WlqjV9RoYPTY/sG0u2DrE0gfOzbsL1go7f3oUDz44+yNF0J4f2yw2HFfdmOof/zv6wSr2mCuUdlsnHBFTeH/b58ayU0ven0+2rKxpva+Uae4n6aj0fWUTLJtZJ9eJpxqq4SfmzKzQBO/d76hFDsJmVngeCZuZ5aiWb8w5CJtZsXlO2MwsP0JO6m5mliePhM3McuQ5YTOzvHhO2MwsP1nuiNqNwg7CZlZ4NRyDa2pnDTOrUXV1quqohqRukv4m6Zb0cz9Jd0h6Kr2uW3Lu8ZLmSXpS0p4l5dtLmpM+m6w0VJfUQ9K1qXympGEtXltr/zHMzDpU2+cTPoZsI4lGE4HpETGcLGnYRABJWwJjyXKdjwbOk9SY47y57dTGA0sjYlPgLOCnLXXGQdjMCq0t8wlLGgLsDVxUUjyG95ONTeH9rdHGANdExNsR8TQwD9ihhe3UStu6DthDLfx1cBA2s4KrbhScYt16jduXpWNCk8bOJkuh+25J2foRsQCy3OTAwFQ+GHi+5LzGbdMqbaf2Xp2IaABeA/pXujrfmDOzwmvFjbnFzeUTlrQPsCgiHpS0azVfW6YsKpRXqtMsB2EzKza1WSrLnYF9JX2RbDu1PpKuABZKGpR26BkELErnzyfbZq1R47ZplbZTa6wzX1I90Bcot8fmezwdYWaF1rhO+KPemIuI4yNiSEQMI7vhdmdEHAxMA8al08YBN6f304CxacXDRmQ34GalKYtlknZM872HNKnT2Nb+6Ts8Ejazzq2dH9Y4A5gqaTzwHHAAQEQ8LmkqMBdoAI6MiFWpzhGsvp3aran8YuBySfPIRsBjW/pyB2EzK7y2jsERcRdwV3r/CrBHM+dNAiaVKS+7nVpErCAF8Wo5CJtZ4fmxZTOzvDiBj5lZfrKk7rUbhR2Ezazw6mp4KOwgbGaFV8Mx2EHYzIpN8o05M7Nc1fCUcPNBWNIvqfDMc0Qc3S49MjNroqvemJvdYb0wM2uGyFZI1Kpmg3BETCn9WdJaEfFm+3fJzGx1NTwQbjmBj6SdJM0lZaKXtI2k89q9Z2ZmAFUm7+msN++qyaJ2NrAn8ApARDwC7NKOfTIzW01b7axRRFWtjoiI55v8lVnV3LlmZm1J+GGN5yV9BghJ3YGjWX2TPDOzdlXLqyOqmY44HDiSbO+kF4Bt089mZu2u2qmIzjpYbnEkHBGLga93QF/MzMqq5emIalZHbCzp95JelrRI0s2SNu6IzpmZQeNa4ZaPzqia6YirgKnAIODjwO+Aq9uzU2Zmpbr6EjVFxOUR0ZCOK2hhC2czs7aSrY6o7uiMKuWO6Jfe/lnSROAasuD7VeAPHdA3MzNQ103q/iBZ0G28+m+VfBbAj9qrU2ZmpTrrVEM1KuWO2KgjO2JmVk7jdEStquqJOUkjgS2Bno1lEXFZe3XKzKxUlxwJN5J0CrArWRD+I7AXcB/gIGxmHaJ2Q3B1qyP2B/YAXoqIbwLbAD3atVdmZokE3epU1dEZVTMdsTwi3pXUIKkPsAjwwxpm1mG69HQEMFvSOsCFZCsm3gBmtWenzMxK1XAMbnk6IiK+HRGvRsSvgc8D49K0hJlZuxOiTtUdFduRekqaJekRSY9LOi2V95N0h6Sn0uu6JXWOlzRP0pOS9iwp317SnPTZZKWhuqQekq5N5TMlDWvp+poNwpI+2fQA+gH16b2ZWftruyxqbwO7R8Q2ZNkgR0vaEZgITI+I4cD09DOStgTGAiOA0cB5krqlts4HJgDD0zE6lY8HlkbEpsBZwE9b6lSl6YifV/gsgN1barzotttiA+6feW7e3TCzFrTFnHBEBNl0KsAa6QhgDNkKMIApwF3Acan8moh4G3ha0jxgB0nPAH0iYkbq22XAfsCtqc6pqa3rgHMlKX13WZUe1titlddoZtbmBHSrPgivJ6l0p/gLIuKC99rKRrIPApsCv4qImZLWj4gFABGxQNLAdPpg4K8lbc1PZSvT+6bljXWeT201SHoN6A8sbq7DVT2sYWaWp1asPlscEaOa+zAiVgHbpsUGN6YH0ZpT7lujQnmlOs2qZp2wmVmu2jqLWkS8SjbtMBpYKGkQQHpdlE6bDwwtqTYEeDGVDylTvlodSfVAX2BJxWurvttmZh0vu+n20fMJSxqQRsBIWhP4HPB3YBowLp02Drg5vZ8GjE0rHjYiuwE3K01dLJO0Y1oVcUiTOo1t7Q/cWWk+GKp7bFlk2xttHBGnS9oA+FhEeK2wmXWINnoYbhAwJc0L1wFTI+IWSTOAqZLGA88BBwBExOOSpgJzgQbgyDSdAXAEcCmwJtkNuVtT+cXA5ekm3hKy1RUVVTMnfB7wLtlqiNOBZcD1wKeqqGtm9pG1xcMaEfEosF2Z8lfIUjOUqzMJmFSmfDbwgfnkiFhBCuLVqiYIfzoiPinpb+lLlkrq3povMTP7sATU1/Ajc9UE4ZVp+B6QzauQjYzNzDpEDcfgqoLwZOBGYKCkSWSTzSe1a6/MzBJV8UhyZ9ZiEI6IKyU9SDZnImC/iHii3XtmZpbUcAyuanXEBsBbwO9LyyLiufbsmJlZo06aKrgq1UxH/IH3nxLpCWwEPEmW1MLMrF0JOm3C9mpUMx2xVenPKYPat5o53cysbbXyabjOptW5IyLiIUleI2xmHUY1vMtcNXPC3y/5sQ74JPByu/XIzKyEt7yH3iXvG8jmiK9vn+6YmX1Qlw3C6SGNtSPihx3UHzOzD+iSG31Kqk9Jib2VkZnlJtvyPu9etJ9KI+FZZPO/D0uaBvwOeLPxw4i4oZ37ZmYG0LWfmCPb3PMVsixqjeuFA3AQNrN215VvzA1MKyMe44NbelRMUmxm1pZqeCBcMQh3A9bmQ+yZZGbWdkRdF10nvCAiTu+wnpiZlSG67ki4hi/bzDoNQX0NTwpXCsJlt/swM+tIXXYkHBEVt2k2M+soXX2JmplZrmo4BjsIm1mxiSxzWK1yEDazYpOnI8zMcpM9MecgbGaWm9oNwQ7CZtYJ1PBA2EHYzIpONZ1PuJZvOppZDWhcHVHN0WJb0lBJf5b0hKTHJR2TyvtJukPSU+l13ZI6x0uaJ+lJSXuWlG8vaU76bLLSXwpJPSRdm8pnShpWqU8OwmZWeHVSVUcVGoAfRMQWwI7AkZK2BCYC0yNiODA9/Uz6bCwwAhgNnJd2HAI4H5gADE/H6FQ+HlgaEZsCZwE/rXht1f4jmJnlQtn2RtUcLYmIBRHxUHq/DHgCGAyMAaak06YA+6X3Y4BrIuLtiHgamAfsIGkQ0CciZkREAJc1qdPY1nXAHqrQOQdhMyu0Vk5HrCdpdskxodl2s2mC7YCZwPoRsQCyQA0MTKcNBp4vqTY/lQ1O75uWr1YnIhqA14D+zfXDN+bMrPBacWNucUSMqqK9tcl2jf9uRLxeof3m8qlXyrPeqhzsHgmbWeGpyqOqtqQ1yALwlSV7ZS5MUwyk10WpfD4wtKT6EODFVD6kTPlqdSTVA32BZhOiOQibWaEJ6CZVdbTYVjbkvRh4IiJ+UfLRNGBcej8OuLmkfGxa8bAR2Q24WWnKYpmkHVObhzSp09jW/sCdad64LE9HmFnhteEy4Z2BbwBzJD2cyk4AzgCmShoPPAccABARj0uaCswlW1lxZESsSvWOAC4F1gRuTQdkQf5ySfPIRsBjK3XIQdjMCk6ojR5cjoj7aH7mouxGFhExCZhUpnw2MLJM+QpSEK+Gg7CZFV4NPzDnIGxmxZYtUavdKOwgbGbFJo+Ezcxy5XzCZmY5yZK6592L9uMgbGaF11arI4rIQdjMCq+GZyMchGvJr6/+M1Nu+gtEcMh+O3PEQbvl3SVrYsXbK9l7wtm8vbKBVQ2r2HeP7Tj+W3sz58n5fP+Ma1jx9krq6+v42XFfZfsRw/LubmF4JNxGJJ0KvBERP2uHtieRPTq4bkSs3dbtF93ceS8y5aa/MH3KD+le3439jz6PL/zbCDbZYGDLla3D9Ohez83nH83avXqwsmEVe/3nL/jcZ7bkJ7/5A8f+5158fucR/On+xzll8k3c8pvv5t3dQqj1OeFayh3xe2CHvDuRl3888xKf2moYvXp2p76+Gzt/clNuueuRvLtlTUhi7V49AFjZsIqVDatSLlxY9uYKAF5/YzkfG9A3z24WS5UJ3TvrCop2C8KSDpH0qKRHJF1e5vPDJD2QPr9eUq9UfoCkx1L5PalshKRZkh5ObQ5v2l5E/LUxH2hXtMUmH+cvf5vHklff4K0V73DHXx7nhYVL8+6WlbFq1bv8+0E/YbMvTGTXT3+CUSOH8ePv78/Jk29ixN4ncfI5N3LykWPy7mahtGUWtaJpl+kISSOAE4GdI2KxpH5lTrshIi5M5/8P2ZYgvwROBvaMiBckrZPOPRw4JyKulNQd6FamvWr7NoFsSxKGbrDBh22mcDbf6GMcc8jn+fJR57JWrx6MGD6Y+m4f+p/J2lG3bnXce9XxvLbsLQ7+4YVpKul+fvz9r7Dv7ttx4x0PcfSPruSm876Td1cLIZuO6KwhtmXtNRLeHbguIhYDRES5XJojJd0raQ7wdbI9nADuBy6VdBjvB9sZwAmSjgM2jIjlH7ZjEXFBRIyKiFED1hvwYZsppG+M+Qx3XzGRP17wPdbtsxYbD62t66s1fXv34t+2H870GXO5+paZfGm3bQHY73Pb8dDcZ/PtXMHU8ki4vYKwqJBJPrkUOCoitgJOA3oCRMThwElkSZEfltQ/Iq4C9gWWA7dL2r2d+t2pvbxkGQDPv7SEW/78CPvv2eIGA9bBFi9dxmvL3gJg+Yp3uGvWkwwftj6DBvTl/oeeAuCeB/7hP6BN1XAUbq/VEdOBGyWdFRGvSOpXZjTcG1iQstx/HXgBQNImETETmCnpS8BQSX2Bf0XEZEkbA1sDd7ZT3zutQ467iKWvvUl9fTfOPPZA1unTK+8uWRMvLX6db596OavefZd33w2+/LlPMvrft6Jv714c//PraFj1Lj2713P2CV/Lu6uFUsvTEe0ShFMi5EnA3ZJWAX8DDm1y2n+TbbD3LDCHLCgDnJluvIksmD9Ctv30wZJWAi8Bpzf9Tkn/CxwE9JI0H7goIk5t40srtFsv/F7eXbAWjBw+mHuunPiB8p223YS7Lj8uhx51DrUbgttxnXBETOH9bZ8by04teX8+cH6Zel8p09xP0lHp+44Fjv0wfTWzgqvhKOwn5sys0LLp3tqNwg7CZlZszidsZpavGo7BDsJmVnRCNTwUdhA2s8Kr4RjsIGxmxdaJn8OoioOwmRVfDUdhB2EzKzwvUTMzy5HnhM3M8lLj64RraWcNM6tRqvJ/LbYjXSJpkaTHSsr6SbpD0lPpdd2Sz46XNE/Sk5L2LCnfXtKc9NlkpTV0knpIujaVz5Q0rKU+OQibWaGJbCRczVGFS4HRTcomAtMjYjhZ0rCJAJK2BMaS5TofDZwnqTHH+flkm0MMT0djm+OBpRGxKXAW8NOWOuQgbGaF11bphCPiHqBpWt0xvJ9sbAqwX0n5NRHxdkQ8DcwDdpA0COgTETMiIoDLmtRpbOs6YA+18KSJg7CZFV/1UXg9SbNLjglVtL5+4/6U6bVxi/LBwPMl581PZYPT+6blq9WJiAbgNaB/pS/3jTkzK7xWJHVfHBFttaVMuS+NCuWV6jTLI2EzK7x23t1oYZpiIL0uSuXzybZZazQEeDGVDylTvlodSfVAXz44/bEaB2EzK772jcLTgHHp/Tjg5pLysWnFw0ZkN+BmpSmLZZJ2TPO9hzSp09jW/sCdad64WZ6OMLNCa8uk7pKuBnYlmzueD5wCnAFMlTQeeA44AN7bpm0qMBdoAI6MiFWpqSPIVlqsCdyaDoCLgcslzSMbAY9tqU8OwmZWbG34sEZENLeD6h7NnD8JmFSmfDYwskz5ClIQr5aDsJkVXg0/MOcgbGZF56TuZma5quEY7CBsZsXmpO5mZnmr4SjsIGxmheek7mZmOfKcsJlZXgR1DsJmZnmq3SjsIGxmhdaY1L1WOQibWeHVcAx2EDaz4vNI2MwsR35s2cwsR7Ubgh2EzazgWrGTcqfkIGxmhecn5szM8lS7MdhB2MyKr4ZjsIOwmRWdWrPlfafjIGxmhVbrT8x5y3szsxx5JGxmhVfLI2EHYTMrPC9RMzPLix/WMDPLT63fmHMQNrPC83SEmVmOPBI2M8tRDcdgB2Ez6wRqOAo7CJtZoQlq+rFlRUTefciNpJeBZ/PuRztYD1icdyesVWr1d7ZhRAz4KA1Iuo3s36caiyNi9Ef5vo7WpYNwrZI0OyJG5d0Pq55/Z12Xc0eYmeXIQdjMLEcOwrXpgrw7YK3m31kX5TlhM7MceSRsZpYjB2Ezsxw5CHcSkk6V9F/t1Pb2kuZImidpslTDK+M7UDv/ziZJel7SG+3RvnUcB2EDOB+YAAxPR6da7N5F/R7YIe9O2EfnIFxAkg6R9KikRyRdXubzwyQ9kD6/XlKvVH6ApMdS+T2pbISkWZIeTm0Ob9LWIKBPRMyI7C7tZcB+7X+VtaUjf2cAEfHXiFjQ/ldm7c25IwpG0gjgRGDniFgsqV+Z026IiAvT+f8DjAd+CZwM7BkRL0haJ517OHBORFwpqTvQrUlbg4H5JT/PT2VWpRx+Z1ZDPBIunt2B6yJiMUBELClzzkhJ90qaA3wdGJHK7wculXQY7/8fdwZwgqTjyJ7jX96krXLzv1632Dod/TuzGuIgXDyi5SB4KXBURGwFnAb0BIiIw4GTgKHAw5L6R8RVwL7AcuB2Sbs3aWs+MKTk5yHAix/1IrqYjv6dWQ1xEC6e6cCBkvoDNPOftr2BBZLWIBtVkc7dJCJmRsTJZBm5hkraGPhXREwGpgFblzaU5hWXSdoxrYo4BLi5PS6shnXo78xqi4NwwUTE48Ak4G5JjwC/KHPafwMzgTuAv5eUn5mWmj0G3AM8AnwVeEzSw8AnyG68NXUEcBEwD/gncGvbXE3XkMfvTNL/SpoP9JI0X9KpbXhJ1oH82LKZWY48EjYzy5GDsJlZjhyEzcxy5CBsZpYjB2Ezsxw5CFuzJK1K+Qsek/S7xnwHH7KtSyXtn95fJGnLCufuKukzH+I7npH0gV15mytvck6rspG1Z4Y061ochK2S5RGxbUSMBN4hy2nwHkkfKqdBRPxnRMytcMquQKuDsFln5CBs1boX2DSNUv8s6SpgjqRuks5MGcIelfQtAGXOlTRX0h+AgY0NSbpL0qj0frSkh1IWsemShpEF+++lUfi/SxqQMo89kI6dU93+kv4k6W+SfkP5PBirkXSTpAclPS5pQpPPfp76Ml3SgFS2iaTbUp17JX2iTf41zRJnUbMWSaoH9gJuS0U7ACMj4ukUyF6LiE9J6gHcL+lPwHbA5sBWwPrAXOCSJu0OAC4Edklt9YuIJZJ+DbwRET9L510FnBUR90naALgd2AI4BbgvIk6XtDdZTuSW/Ef6jjWBByRdHxGvAGsBD0XEDySdnNo+imwDzsMj4ilJnwbOI0vYY9YmHIStkjXTo7OQjYQvJpsmmBURT6fyLwBbN873An3JEsPvAlwdEauAFyXdWab9HYF7GttqJvsYwOeALfX+hh99JPVO3/GVVPcPkpZWcU1HS/pyej809fUV4F3g2lR+BXCDpLXT9f6u5Lt7VPEdZlVzELZKlkfEtqUFKRi9WVoEfCcibm9y3hdpObNYNdnHIJs226lpSsfUl6qfu5e0K1lA3yki3pJ0FymbWRmRvvfVpv8GZm3Jc8L2Ud0OHJGygyFpM0lrkSWjGZvmjAcBu5WpOwP4rKSNUt3G7GPLyLKONfoT2dQA6bxt09t7SBnJJO0FrNtCX/sCS1MA/gTZSLxRHdA4mj+IbJrjdeBpSQek75CkbVr4DrNWcRC2j+oisvneh1ImsN+Q/RfWjcBTwByyPezubloxIl4mm8e9IWUfa5wO+D3w5cYbc8DRwKh0428u76/SOA3YRdJDZNMiz7XQ19uAekmPAj8C/lry2ZvACEkPks35np7Kvw6MT/17HBhTxb+JWdWcRc3MLEceCZuZ5chB2MwsRw7CZmY5chA2M8uRg7CZWY4chM3McuQgbGaWo/8Pozmp0QqEqOUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#performance results\n",
    "print(classification_report(y_test, y_pred2, target_names=target_names))\n",
    "plot_confusion_matrix(model2, df_X_test_stand, y_test, display_labels=target_names,cmap=plt.cm.Blues); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Weighted Decision Tree (W-SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 1/5] END .......criterion=gini, max_depth=2;, score=0.995 total time=   0.7s\n",
      "[CV 2/5] END .......criterion=gini, max_depth=2;, score=0.996 total time=   0.7s\n",
      "[CV 3/5] END .......criterion=gini, max_depth=2;, score=0.996 total time=   0.7s\n",
      "[CV 4/5] END .......criterion=gini, max_depth=2;, score=0.998 total time=   0.7s\n",
      "[CV 5/5] END .......criterion=gini, max_depth=2;, score=0.996 total time=   0.6s\n",
      "[CV 1/5] END .......criterion=gini, max_depth=4;, score=0.998 total time=   1.0s\n",
      "[CV 2/5] END .......criterion=gini, max_depth=4;, score=0.998 total time=   1.0s\n",
      "[CV 3/5] END .......criterion=gini, max_depth=4;, score=0.998 total time=   1.0s\n",
      "[CV 4/5] END .......criterion=gini, max_depth=4;, score=0.998 total time=   0.7s\n",
      "[CV 5/5] END .......criterion=gini, max_depth=4;, score=1.000 total time=   1.0s\n",
      "[CV 1/5] END .......criterion=gini, max_depth=6;, score=1.000 total time=   1.0s\n",
      "[CV 2/5] END .......criterion=gini, max_depth=6;, score=1.000 total time=   1.0s\n",
      "[CV 3/5] END .......criterion=gini, max_depth=6;, score=1.000 total time=   1.0s\n",
      "[CV 4/5] END .......criterion=gini, max_depth=6;, score=1.000 total time=   1.0s\n",
      "[CV 5/5] END .......criterion=gini, max_depth=6;, score=1.000 total time=   0.7s\n",
      "[CV 1/5] END .......criterion=gini, max_depth=8;, score=1.000 total time=   1.1s\n",
      "[CV 2/5] END .......criterion=gini, max_depth=8;, score=1.000 total time=   0.7s\n",
      "[CV 3/5] END .......criterion=gini, max_depth=8;, score=1.000 total time=   1.0s\n",
      "[CV 4/5] END .......criterion=gini, max_depth=8;, score=1.000 total time=   0.7s\n",
      "[CV 5/5] END .......criterion=gini, max_depth=8;, score=1.000 total time=   1.0s\n",
      "[CV 1/5] END ......criterion=gini, max_depth=10;, score=1.000 total time=   1.0s\n",
      "[CV 2/5] END ......criterion=gini, max_depth=10;, score=1.000 total time=   1.0s\n",
      "[CV 3/5] END ......criterion=gini, max_depth=10;, score=1.000 total time=   1.0s\n",
      "[CV 4/5] END ......criterion=gini, max_depth=10;, score=1.000 total time=   0.7s\n",
      "[CV 5/5] END ......criterion=gini, max_depth=10;, score=1.000 total time=   0.7s\n",
      "[CV 1/5] END ......criterion=gini, max_depth=12;, score=1.000 total time=   0.7s\n",
      "[CV 2/5] END ......criterion=gini, max_depth=12;, score=1.000 total time=   1.0s\n",
      "[CV 3/5] END ......criterion=gini, max_depth=12;, score=1.000 total time=   0.7s\n",
      "[CV 4/5] END ......criterion=gini, max_depth=12;, score=1.000 total time=   0.7s\n",
      "[CV 5/5] END ......criterion=gini, max_depth=12;, score=1.000 total time=   1.0s\n",
      "[CV 1/5] END ....criterion=entropy, max_depth=2;, score=0.995 total time=   0.7s\n",
      "[CV 2/5] END ....criterion=entropy, max_depth=2;, score=0.995 total time=   0.8s\n",
      "[CV 3/5] END ....criterion=entropy, max_depth=2;, score=0.995 total time=   0.7s\n",
      "[CV 4/5] END ....criterion=entropy, max_depth=2;, score=0.997 total time=   0.8s\n",
      "[CV 5/5] END ....criterion=entropy, max_depth=2;, score=0.995 total time=   0.8s\n",
      "[CV 1/5] END ....criterion=entropy, max_depth=4;, score=1.000 total time=   1.1s\n",
      "[CV 2/5] END ....criterion=entropy, max_depth=4;, score=1.000 total time=   1.1s\n",
      "[CV 3/5] END ....criterion=entropy, max_depth=4;, score=1.000 total time=   1.1s\n",
      "[CV 4/5] END ....criterion=entropy, max_depth=4;, score=1.000 total time=   0.7s\n",
      "[CV 5/5] END ....criterion=entropy, max_depth=4;, score=1.000 total time=   1.1s\n",
      "[CV 1/5] END ....criterion=entropy, max_depth=6;, score=1.000 total time=   0.8s\n",
      "[CV 2/5] END ....criterion=entropy, max_depth=6;, score=1.000 total time=   1.1s\n",
      "[CV 3/5] END ....criterion=entropy, max_depth=6;, score=1.000 total time=   1.1s\n",
      "[CV 4/5] END ....criterion=entropy, max_depth=6;, score=1.000 total time=   1.1s\n",
      "[CV 5/5] END ....criterion=entropy, max_depth=6;, score=1.000 total time=   1.1s\n",
      "[CV 1/5] END ....criterion=entropy, max_depth=8;, score=1.000 total time=   1.1s\n",
      "[CV 2/5] END ....criterion=entropy, max_depth=8;, score=1.000 total time=   0.7s\n",
      "[CV 3/5] END ....criterion=entropy, max_depth=8;, score=1.000 total time=   1.1s\n",
      "[CV 4/5] END ....criterion=entropy, max_depth=8;, score=1.000 total time=   1.1s\n",
      "[CV 5/5] END ....criterion=entropy, max_depth=8;, score=1.000 total time=   0.8s\n",
      "[CV 1/5] END ...criterion=entropy, max_depth=10;, score=1.000 total time=   1.1s\n",
      "[CV 2/5] END ...criterion=entropy, max_depth=10;, score=1.000 total time=   1.1s\n",
      "[CV 3/5] END ...criterion=entropy, max_depth=10;, score=1.000 total time=   0.8s\n",
      "[CV 4/5] END ...criterion=entropy, max_depth=10;, score=1.000 total time=   0.7s\n",
      "[CV 5/5] END ...criterion=entropy, max_depth=10;, score=1.000 total time=   1.1s\n",
      "[CV 1/5] END ...criterion=entropy, max_depth=12;, score=1.000 total time=   0.7s\n",
      "[CV 2/5] END ...criterion=entropy, max_depth=12;, score=1.000 total time=   1.1s\n",
      "[CV 3/5] END ...criterion=entropy, max_depth=12;, score=1.000 total time=   1.1s\n",
      "[CV 4/5] END ...criterion=entropy, max_depth=12;, score=1.000 total time=   1.1s\n",
      "[CV 5/5] END ...criterion=entropy, max_depth=12;, score=1.000 total time=   1.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(class_weight='balanced'),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [2, 4, 6, 8, 10, 12]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run grid search only on training set using cross-validation\n",
    "parameters = {'criterion':['gini','entropy'], 'max_depth' : [2,4,6,8,10,12]}\n",
    "model3 = GridSearchCV(DecisionTreeClassifier(class_weight='balanced'), parameters, cv=5, verbose=3)\n",
    "# fit on the trainning dataset\n",
    "model3.fit(df_X_train_stand, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'criterion': 'entropy', 'max_depth': 10}\n",
      "accuracy : 0.9999300490261855\n",
      "Best Model: DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=10)\n"
     ]
    }
   ],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",model3.best_params_)\n",
    "print(\"accuracy :\",model3.best_score_)\n",
    "print('Best Model:',model3.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = model3.predict(df_X_test_stand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      1.00      1.00     60710\n",
      "     class 1       0.93      0.89      0.91        47\n",
      "\n",
      "    accuracy                           1.00     60757\n",
      "   macro avg       0.97      0.95      0.96     60757\n",
      "weighted avg       1.00      1.00      1.00     60757\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#performance results\n",
    "print(classification_report(y_test, y_pred3, target_names=target_names))\n",
    "plot_confusion_matrix(model3, df_X_test_stand, y_test, display_labels=target_names,cmap=plt.cm.Blues);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling using OSS\n",
    "OneSidedSelection (OSS) is an undersampling technique that combines Tomek Links and the Condensed Nearest Neighbor (CNN) Rule. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "from imblearn.under_sampling import OneSidedSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 21463, 1: 150})\n"
     ]
    }
   ],
   "source": [
    "# define the undersampling method\n",
    "oss = OneSidedSelection(random_state=0)\n",
    "# fit on the trainning dataset\n",
    "X_oss, y_oss = oss.fit_resample(df_X_train_stand, y_train)\n",
    "# summarize the new class distribution\n",
    "counter = Counter(y_oss)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Weighted Support Vector Machine with One Sided Selection (SVM+OSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV 1/5] END ....................C=1, gamma=0.1;, score=0.999 total time=   0.6s\n",
      "[CV 2/5] END ....................C=1, gamma=0.1;, score=0.999 total time=   0.4s\n",
      "[CV 3/5] END ....................C=1, gamma=0.1;, score=0.999 total time=   0.2s\n",
      "[CV 4/5] END ....................C=1, gamma=0.1;, score=0.999 total time=   1.2s\n",
      "[CV 5/5] END ....................C=1, gamma=0.1;, score=0.998 total time=   1.0s\n",
      "[CV 1/5] END ......................C=1, gamma=1;, score=0.999 total time=   0.4s\n",
      "[CV 2/5] END ......................C=1, gamma=1;, score=0.999 total time=   0.4s\n",
      "[CV 3/5] END ......................C=1, gamma=1;, score=0.999 total time=   0.8s\n",
      "[CV 4/5] END ......................C=1, gamma=1;, score=0.999 total time=   1.0s\n",
      "[CV 5/5] END ......................C=1, gamma=1;, score=0.998 total time=   1.4s\n",
      "[CV 1/5] END ....................C=5, gamma=0.1;, score=0.999 total time=   0.5s\n",
      "[CV 2/5] END ....................C=5, gamma=0.1;, score=0.999 total time=   0.5s\n",
      "[CV 3/5] END ....................C=5, gamma=0.1;, score=0.999 total time=   0.6s\n",
      "[CV 4/5] END ....................C=5, gamma=0.1;, score=0.999 total time=   1.2s\n",
      "[CV 5/5] END ....................C=5, gamma=0.1;, score=0.998 total time=   1.0s\n",
      "[CV 1/5] END ......................C=5, gamma=1;, score=0.999 total time=   0.4s\n",
      "[CV 2/5] END ......................C=5, gamma=1;, score=0.999 total time=   0.4s\n",
      "[CV 3/5] END ......................C=5, gamma=1;, score=0.999 total time=   0.8s\n",
      "[CV 4/5] END ......................C=5, gamma=1;, score=0.999 total time=   1.1s\n",
      "[CV 5/5] END ......................C=5, gamma=1;, score=0.998 total time=   1.4s\n",
      "[CV 1/5] END ...................C=10, gamma=0.1;, score=0.999 total time=   0.5s\n",
      "[CV 2/5] END ...................C=10, gamma=0.1;, score=0.999 total time=   0.5s\n",
      "[CV 3/5] END ...................C=10, gamma=0.1;, score=0.999 total time=   0.6s\n",
      "[CV 4/5] END ...................C=10, gamma=0.1;, score=0.999 total time=   1.2s\n",
      "[CV 5/5] END ...................C=10, gamma=0.1;, score=0.998 total time=   1.0s\n",
      "[CV 1/5] END .....................C=10, gamma=1;, score=0.999 total time=   0.4s\n",
      "[CV 2/5] END .....................C=10, gamma=1;, score=0.999 total time=   0.4s\n",
      "[CV 3/5] END .....................C=10, gamma=1;, score=0.999 total time=   0.8s\n",
      "[CV 4/5] END .....................C=10, gamma=1;, score=0.999 total time=   1.1s\n",
      "[CV 5/5] END .....................C=10, gamma=1;, score=0.998 total time=   1.4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(class_weight='balanced', kernel='poly'),\n",
       "             param_grid={'C': [1, 5, 10], 'gamma': [0.1, 1]}, verbose=3)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run grid search only on training set using cross-validation\n",
    "parameters = {'C':[1, 5, 10],'gamma':[0.1, 1]}\n",
    "model4 = GridSearchCV(SVC(class_weight='balanced', kernel='poly'), parameters, cv=5,verbose=3)\n",
    "model4.fit(X_oss, y_oss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'C': 1, 'gamma': 0.1}\n",
      "accuracy : 0.9989358170833386\n",
      "Best Model: SVC(C=1, class_weight='balanced', gamma=0.1, kernel='poly')\n"
     ]
    }
   ],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",model4.best_params_)\n",
    "print(\"accuracy :\",model4.best_score_)\n",
    "print('Best Model:',model4.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred4 = model4.predict(df_X_test_stand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      1.00      1.00     60710\n",
      "     class 1       0.87      0.85      0.86        47\n",
      "\n",
      "    accuracy                           1.00     60757\n",
      "   macro avg       0.93      0.93      0.93     60757\n",
      "weighted avg       1.00      1.00      1.00     60757\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#performance results\n",
    "print(classification_report(y_test, y_pred4, target_names=target_names))\n",
    "plot_confusion_matrix(model4, df_X_test_stand, y_test, display_labels=target_names,cmap=plt.cm.Blues);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e)  XG Boost, Extreme Gradient Boosting (XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=50;, score=1.000 total time=   1.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=50;, score=1.000 total time=   1.5s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=50;, score=1.000 total time=   1.4s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=50;, score=1.000 total time=   1.4s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=50;, score=1.000 total time=   1.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=100;, score=1.000 total time=   2.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=100;, score=1.000 total time=   2.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=100;, score=1.000 total time=   2.8s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=100;, score=1.000 total time=   3.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=100;, score=1.000 total time=   2.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=180;, score=1.000 total time=   4.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=180;, score=1.000 total time=   4.3s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=180;, score=1.000 total time=   4.3s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=180;, score=1.000 total time=   4.3s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=180;, score=1.000 total time=   4.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=4, n_estimators=700;, score=1.000 total time=  10.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=4, n_estimators=700;, score=1.000 total time=  10.0s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=4, n_estimators=700;, score=1.000 total time=  10.5s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=4, n_estimators=700;, score=1.000 total time=  11.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=4, n_estimators=700;, score=1.000 total time=  11.5s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=15, n_estimators=50;, score=1.000 total time=   1.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=15, n_estimators=50;, score=1.000 total time=   1.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=15, n_estimators=50;, score=1.000 total time=   1.8s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=15, n_estimators=50;, score=1.000 total time=   1.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=15, n_estimators=50;, score=1.000 total time=   1.9s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=15, n_estimators=100;, score=1.000 total time=   3.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=15, n_estimators=100;, score=1.000 total time=   3.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=15, n_estimators=100;, score=1.000 total time=   3.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=15, n_estimators=100;, score=1.000 total time=   3.2s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=15, n_estimators=100;, score=1.000 total time=   3.4s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=15, n_estimators=180;, score=1.000 total time=   5.3s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=15, n_estimators=180;, score=1.000 total time=   4.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=15, n_estimators=180;, score=1.000 total time=   4.7s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=15, n_estimators=180;, score=1.000 total time=   4.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=15, n_estimators=180;, score=1.000 total time=   4.9s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=15, n_estimators=700;, score=1.000 total time=  11.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=15, n_estimators=700;, score=1.000 total time=   9.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=15, n_estimators=700;, score=1.000 total time=  10.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=15, n_estimators=700;, score=1.000 total time=  11.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=15, n_estimators=700;, score=1.000 total time=  10.9s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=30, n_estimators=50;, score=1.000 total time=   1.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=30, n_estimators=50;, score=1.000 total time=   1.8s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=30, n_estimators=50;, score=1.000 total time=   1.8s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=30, n_estimators=50;, score=1.000 total time=   1.8s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=30, n_estimators=50;, score=1.000 total time=   1.9s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=30, n_estimators=100;, score=1.000 total time=   3.2s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=30, n_estimators=100;, score=1.000 total time=   3.2s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=30, n_estimators=100;, score=1.000 total time=   3.2s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=30, n_estimators=100;, score=1.000 total time=   3.1s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=30, n_estimators=100;, score=1.000 total time=   3.2s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=30, n_estimators=180;, score=1.000 total time=   4.6s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=30, n_estimators=180;, score=1.000 total time=   4.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=30, n_estimators=180;, score=1.000 total time=   4.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=30, n_estimators=180;, score=1.000 total time=   4.6s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=30, n_estimators=180;, score=1.000 total time=   4.8s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=30, n_estimators=700;, score=1.000 total time=  10.8s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=30, n_estimators=700;, score=1.000 total time=   9.9s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=30, n_estimators=700;, score=1.000 total time=  10.7s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=30, n_estimators=700;, score=1.000 total time=  11.7s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=30, n_estimators=700;, score=1.000 total time=  11.0s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=50;, score=1.000 total time=   1.6s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=50;, score=1.000 total time=   1.6s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=50;, score=1.000 total time=   1.5s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=50;, score=1.000 total time=   1.7s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=50;, score=1.000 total time=   1.5s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=100;, score=1.000 total time=   3.0s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=100;, score=1.000 total time=   3.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=100;, score=1.000 total time=   2.9s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=100;, score=1.000 total time=   3.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=100;, score=1.000 total time=   2.9s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=180;, score=1.000 total time=   5.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=180;, score=1.000 total time=   5.5s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=180;, score=1.000 total time=   5.2s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=180;, score=1.000 total time=   5.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=180;, score=1.000 total time=   5.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=4, n_estimators=700;, score=1.000 total time=  19.9s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=4, n_estimators=700;, score=1.000 total time=  20.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=4, n_estimators=700;, score=1.000 total time=  20.7s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=4, n_estimators=700;, score=1.000 total time=  19.4s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=4, n_estimators=700;, score=1.000 total time=  19.9s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=15, n_estimators=50;, score=1.000 total time=   1.8s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=15, n_estimators=50;, score=1.000 total time=   2.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=15, n_estimators=50;, score=1.000 total time=   1.8s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=15, n_estimators=50;, score=1.000 total time=   2.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=15, n_estimators=50;, score=1.000 total time=   1.9s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=15, n_estimators=100;, score=1.000 total time=   4.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END learning_rate=0.01, max_depth=15, n_estimators=100;, score=1.000 total time=   4.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=15, n_estimators=100;, score=1.000 total time=   3.6s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=15, n_estimators=100;, score=1.000 total time=   3.9s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=15, n_estimators=100;, score=1.000 total time=   3.9s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=15, n_estimators=180;, score=1.000 total time=   6.9s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=15, n_estimators=180;, score=1.000 total time=   8.5s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=15, n_estimators=180;, score=1.000 total time=   8.1s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=15, n_estimators=180;, score=1.000 total time=   7.1s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=15, n_estimators=180;, score=1.000 total time=   7.3s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=15, n_estimators=700;, score=1.000 total time=  23.8s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=15, n_estimators=700;, score=1.000 total time=  23.9s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=15, n_estimators=700;, score=1.000 total time=  23.6s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=15, n_estimators=700;, score=1.000 total time=  23.7s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=15, n_estimators=700;, score=1.000 total time=  25.5s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=30, n_estimators=50;, score=1.000 total time=   1.8s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=30, n_estimators=50;, score=1.000 total time=   2.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=30, n_estimators=50;, score=1.000 total time=   1.8s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=30, n_estimators=50;, score=1.000 total time=   2.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=30, n_estimators=50;, score=1.000 total time=   1.9s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=30, n_estimators=100;, score=1.000 total time=   3.7s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=30, n_estimators=100;, score=1.000 total time=   4.0s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=30, n_estimators=100;, score=1.000 total time=   3.6s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=30, n_estimators=100;, score=1.000 total time=   4.0s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=30, n_estimators=100;, score=1.000 total time=   3.9s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=30, n_estimators=180;, score=1.000 total time=   6.9s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=30, n_estimators=180;, score=1.000 total time=   7.3s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=30, n_estimators=180;, score=1.000 total time=   6.8s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=30, n_estimators=180;, score=1.000 total time=   7.3s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=30, n_estimators=180;, score=1.000 total time=   7.2s\n",
      "[CV 1/5] END learning_rate=0.01, max_depth=30, n_estimators=700;, score=1.000 total time=  24.3s\n",
      "[CV 2/5] END learning_rate=0.01, max_depth=30, n_estimators=700;, score=1.000 total time=  24.2s\n",
      "[CV 3/5] END learning_rate=0.01, max_depth=30, n_estimators=700;, score=1.000 total time=  23.8s\n",
      "[CV 4/5] END learning_rate=0.01, max_depth=30, n_estimators=700;, score=1.000 total time=  23.9s\n",
      "[CV 5/5] END learning_rate=0.01, max_depth=30, n_estimators=700;, score=1.000 total time=  24.5s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=4, n_estimators=50;, score=1.000 total time=   1.5s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=4, n_estimators=50;, score=1.000 total time=   1.6s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=4, n_estimators=50;, score=1.000 total time=   1.5s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=4, n_estimators=50;, score=1.000 total time=   1.5s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=4, n_estimators=50;, score=1.000 total time=   1.5s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=4, n_estimators=100;, score=1.000 total time=   3.5s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=4, n_estimators=100;, score=1.000 total time=   3.2s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=4, n_estimators=100;, score=1.000 total time=   3.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=4, n_estimators=100;, score=1.000 total time=   3.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=4, n_estimators=100;, score=1.000 total time=   3.2s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=4, n_estimators=180;, score=1.000 total time=   5.8s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=4, n_estimators=180;, score=1.000 total time=   5.3s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=4, n_estimators=180;, score=1.000 total time=   5.1s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=4, n_estimators=180;, score=1.000 total time=   5.1s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=4, n_estimators=180;, score=1.000 total time=   5.1s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=4, n_estimators=700;, score=1.000 total time=  13.6s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=4, n_estimators=700;, score=1.000 total time=  13.3s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=4, n_estimators=700;, score=1.000 total time=  13.3s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=4, n_estimators=700;, score=1.000 total time=  13.6s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=4, n_estimators=700;, score=1.000 total time=  14.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=15, n_estimators=50;, score=1.000 total time=   2.1s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=15, n_estimators=50;, score=1.000 total time=   2.1s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=15, n_estimators=50;, score=1.000 total time=   2.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=15, n_estimators=50;, score=1.000 total time=   2.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=15, n_estimators=50;, score=1.000 total time=   2.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=15, n_estimators=100;, score=1.000 total time=   3.7s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=15, n_estimators=100;, score=1.000 total time=   3.7s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=15, n_estimators=100;, score=1.000 total time=   3.6s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=15, n_estimators=100;, score=1.000 total time=   3.7s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=15, n_estimators=100;, score=1.000 total time=   3.7s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=15, n_estimators=180;, score=1.000 total time=   5.8s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=15, n_estimators=180;, score=1.000 total time=   5.9s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=15, n_estimators=180;, score=1.000 total time=   6.0s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=15, n_estimators=180;, score=1.000 total time=   5.8s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=15, n_estimators=180;, score=1.000 total time=   6.1s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=15, n_estimators=700;, score=1.000 total time=  14.0s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=15, n_estimators=700;, score=1.000 total time=  13.8s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=15, n_estimators=700;, score=1.000 total time=  14.3s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=15, n_estimators=700;, score=1.000 total time=  14.4s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=15, n_estimators=700;, score=1.000 total time=  14.7s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=30, n_estimators=50;, score=1.000 total time=   2.0s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=30, n_estimators=50;, score=1.000 total time=   2.0s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=30, n_estimators=50;, score=1.000 total time=   1.9s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=30, n_estimators=50;, score=1.000 total time=   2.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=30, n_estimators=50;, score=1.000 total time=   2.0s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=30, n_estimators=100;, score=1.000 total time=   4.5s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=30, n_estimators=100;, score=1.000 total time=   3.7s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=30, n_estimators=100;, score=1.000 total time=   3.7s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=30, n_estimators=100;, score=1.000 total time=   3.7s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=30, n_estimators=100;, score=1.000 total time=   3.7s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=30, n_estimators=180;, score=1.000 total time=   6.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END learning_rate=0.05, max_depth=30, n_estimators=180;, score=1.000 total time=   5.9s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=30, n_estimators=180;, score=1.000 total time=   5.8s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=30, n_estimators=180;, score=1.000 total time=   5.7s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=30, n_estimators=180;, score=1.000 total time=   5.9s\n",
      "[CV 1/5] END learning_rate=0.05, max_depth=30, n_estimators=700;, score=1.000 total time=  13.4s\n",
      "[CV 2/5] END learning_rate=0.05, max_depth=30, n_estimators=700;, score=1.000 total time=  13.8s\n",
      "[CV 3/5] END learning_rate=0.05, max_depth=30, n_estimators=700;, score=1.000 total time=  13.7s\n",
      "[CV 4/5] END learning_rate=0.05, max_depth=30, n_estimators=700;, score=1.000 total time=  14.0s\n",
      "[CV 5/5] END learning_rate=0.05, max_depth=30, n_estimators=700;, score=1.000 total time=  14.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     eval_metric='logloss', gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, random_state=None,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, subsample=None,\n",
       "                                     tree_method=None, use_label_encoder=False,\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             param_grid={'learning_rate': [0.1, 0.01, 0.05],\n",
       "                         'max_depth': [4, 15, 30],\n",
       "                         'n_estimators': [50, 100, 180, 700]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run grid search only on training set using cross-validation\n",
    "parameters = {'max_depth': [4, 15, 30],'n_estimators': [50, 100, 180, 700], 'learning_rate': [0.1, 0.01, 0.05]}\n",
    "model5 = GridSearchCV(XGBClassifier(eval_metric='logloss',use_label_encoder =False), parameters, cv=5, verbose=3)\n",
    "model5.fit(df_X_train_stand, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 180}\n",
      "accuracy : 0.999967081999251\n",
      "Best Model: XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, eval_metric='logloss',\n",
      "              gamma=0, gpu_id=-1, importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.05, max_delta_step=0,\n",
      "              max_depth=4, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=180, n_jobs=32,\n",
      "              num_parallel_tree=1, random_state=0, reg_alpha=0, reg_lambda=1,\n",
      "              scale_pos_weight=1, subsample=1, tree_method='exact',\n",
      "              use_label_encoder=False, validate_parameters=1, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",model5.best_params_)\n",
    "print(\"accuracy :\",model5.best_score_)\n",
    "print('Best Model:',model5.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred5 = model5.predict(df_X_test_stand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      1.00      1.00     60710\n",
      "     class 1       0.81      0.28      0.41        47\n",
      "\n",
      "    accuracy                           1.00     60757\n",
      "   macro avg       0.91      0.64      0.71     60757\n",
      "weighted avg       1.00      1.00      1.00     60757\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#performance results\n",
    "print(classification_report(y_test, y_pred5, target_names=target_names))\n",
    "plot_confusion_matrix(model5, df_X_test_stand, y_test, display_labels=target_names,cmap=plt.cm.Blues);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save notebook session\n",
    "import dill\n",
    "dill.dump_session('session_esc-04.db')\n",
    "#to restore a notebook session\n",
    "#dill.load_session('session_esc-04.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
