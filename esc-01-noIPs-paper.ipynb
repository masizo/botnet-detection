{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupiter's Notebook for Scenario 01\n",
    "Requieres: [CategoryEncoders](http://contrib.scikit-learn.org/category_encoders/), [imbalanced-learn](https://imbalanced-learn.org/stable/), [XGBoost](https://pypi.org/project/xgboost/), and [dill](https://pypi.org/project/dill/)<br>\n",
    "`pip install category_encoders`<br>\n",
    "`pip install imbalanced-learn`<br>\n",
    "`pip install xgboost`<br>\n",
    "`pip install dill`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To identify class 0 and 1, respectively\n",
    "target_names = ['class 0', 'class 1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "df=pd.read_csv('esc-01-Mixed-traffic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No trunkated \n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(310663, 52)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataset dimensions, number of sessions and features\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 292386, 1: 18277})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#counting classes\n",
    "collections.Counter(df.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proto                 0\n",
      "ts                    0\n",
      "srcIP                 0\n",
      "srcPrt                0\n",
      "dstIP                 0\n",
      "dstPrt                0\n",
      "flowduration          0\n",
      "total_fpackets        0\n",
      "total_bpackets        0\n",
      "total_fpktl           0\n",
      "total_bpktl           0\n",
      "min_fpktl             0\n",
      "min_bpktl             0\n",
      "max_fpktl             0\n",
      "max_bpktl             0\n",
      "mean_fpktl            0\n",
      "mean_bpktl            0\n",
      "std_fpktl             0\n",
      "std_bpktl             0\n",
      "total_fipt            0\n",
      "total_bipt            0\n",
      "min_fipt              0\n",
      "min_bipt              0\n",
      "max_fipt              0\n",
      "max_bipt              0\n",
      "mean_fipt             0\n",
      "mean_bipt             0\n",
      "std_fipt              0\n",
      "std_bipt              0\n",
      "fpsh_cnt              0\n",
      "bpsh_cnt              0\n",
      "furg_cnt              0\n",
      "burg_cnt              0\n",
      "total_fhlen           0\n",
      "total_bhlen           0\n",
      "fPktsPerSecond        0\n",
      "bPktsPerSecond        0\n",
      "flowPktsPerSecond     0\n",
      "flowBytesPerSecond    0\n",
      "mean_flowpktl         0\n",
      "std_flowpktl          0\n",
      "mean_flowipt          0\n",
      "std_flowipt           0\n",
      "flow_fin              0\n",
      "flow_syn              0\n",
      "flow_rst              0\n",
      "flow_ack              0\n",
      "flow_urg              0\n",
      "flow_cwr              0\n",
      "flow_ece              0\n",
      "downUpRatio           0\n",
      "label                 0\n",
      "dtype: int64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#check the number of null values\n",
    "print(df.isnull().sum())\n",
    "print(df.isnull().values.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping Rows with NA inplace\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proto                      2\n",
      "ts                    310663\n",
      "srcIP                  12361\n",
      "srcPrt                 52788\n",
      "dstIP                  13632\n",
      "dstPrt                   340\n",
      "flowduration          187149\n",
      "total_fpackets           703\n",
      "total_bpackets           922\n",
      "total_fpktl             9883\n",
      "total_bpktl            22973\n",
      "min_fpktl                149\n",
      "min_bpktl                495\n",
      "max_fpktl               1333\n",
      "max_bpktl               1142\n",
      "mean_fpktl             21622\n",
      "mean_bpktl             27875\n",
      "std_fpktl              38638\n",
      "std_bpktl              35450\n",
      "total_fipt            110017\n",
      "total_bipt             89339\n",
      "min_fipt               53908\n",
      "min_bipt               31118\n",
      "max_fipt              106490\n",
      "max_bipt               80321\n",
      "mean_fipt             104800\n",
      "mean_bipt              86597\n",
      "std_fipt               86574\n",
      "std_bipt               74955\n",
      "fpsh_cnt                 173\n",
      "bpsh_cnt                 440\n",
      "furg_cnt                   1\n",
      "burg_cnt                   1\n",
      "total_fhlen             3413\n",
      "total_bhlen             4511\n",
      "fPktsPerSecond        175700\n",
      "bPktsPerSecond        169465\n",
      "flowPktsPerSecond     179128\n",
      "flowBytesPerSecond    229271\n",
      "mean_flowpktl          40935\n",
      "std_flowpktl           58473\n",
      "mean_flowipt          177222\n",
      "std_flowipt           109432\n",
      "flow_fin                  17\n",
      "flow_syn                  18\n",
      "flow_rst                  34\n",
      "flow_ack                1196\n",
      "flow_urg                   1\n",
      "flow_cwr                   2\n",
      "flow_ece                   1\n",
      "downUpRatio            60814\n",
      "label                      2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#sumarize the number of unique values for each column \n",
    "print(df.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete time stamp (ts), srcIP and dstIP features\n",
    "# Models do not learn with IP addresses\n",
    "df.drop(['ts','srcIP','dstIP'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(310663, 49)\n"
     ]
    }
   ],
   "source": [
    "#Dataset dimensions, number of sessions and features\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(310663, 49)\n",
      "(307754, 49)\n"
     ]
    }
   ],
   "source": [
    "#Delete Rows That Contain Duplicate Data\n",
    "print(df.shape)\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proto</th>\n",
       "      <th>srcPrt</th>\n",
       "      <th>dstPrt</th>\n",
       "      <th>flowduration</th>\n",
       "      <th>total_fpackets</th>\n",
       "      <th>total_bpackets</th>\n",
       "      <th>total_fpktl</th>\n",
       "      <th>total_bpktl</th>\n",
       "      <th>min_fpktl</th>\n",
       "      <th>min_bpktl</th>\n",
       "      <th>max_fpktl</th>\n",
       "      <th>max_bpktl</th>\n",
       "      <th>mean_fpktl</th>\n",
       "      <th>mean_bpktl</th>\n",
       "      <th>std_fpktl</th>\n",
       "      <th>std_bpktl</th>\n",
       "      <th>total_fipt</th>\n",
       "      <th>total_bipt</th>\n",
       "      <th>min_fipt</th>\n",
       "      <th>min_bipt</th>\n",
       "      <th>max_fipt</th>\n",
       "      <th>max_bipt</th>\n",
       "      <th>mean_fipt</th>\n",
       "      <th>mean_bipt</th>\n",
       "      <th>std_fipt</th>\n",
       "      <th>std_bipt</th>\n",
       "      <th>fpsh_cnt</th>\n",
       "      <th>bpsh_cnt</th>\n",
       "      <th>furg_cnt</th>\n",
       "      <th>burg_cnt</th>\n",
       "      <th>total_fhlen</th>\n",
       "      <th>total_bhlen</th>\n",
       "      <th>fPktsPerSecond</th>\n",
       "      <th>bPktsPerSecond</th>\n",
       "      <th>flowPktsPerSecond</th>\n",
       "      <th>flowBytesPerSecond</th>\n",
       "      <th>mean_flowpktl</th>\n",
       "      <th>std_flowpktl</th>\n",
       "      <th>mean_flowipt</th>\n",
       "      <th>std_flowipt</th>\n",
       "      <th>flow_fin</th>\n",
       "      <th>flow_syn</th>\n",
       "      <th>flow_rst</th>\n",
       "      <th>flow_ack</th>\n",
       "      <th>flow_urg</th>\n",
       "      <th>flow_cwr</th>\n",
       "      <th>flow_ece</th>\n",
       "      <th>downUpRatio</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCP</td>\n",
       "      <td>41039</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>54</td>\n",
       "      <td>62</td>\n",
       "      <td>54</td>\n",
       "      <td>62</td>\n",
       "      <td>54</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>83886.078125</td>\n",
       "      <td>83886.078125</td>\n",
       "      <td>167772.156250</td>\n",
       "      <td>9.730785e+06</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCP</td>\n",
       "      <td>41040</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>54</td>\n",
       "      <td>62</td>\n",
       "      <td>54</td>\n",
       "      <td>62</td>\n",
       "      <td>54</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>83886.078125</td>\n",
       "      <td>83886.078125</td>\n",
       "      <td>167772.156250</td>\n",
       "      <td>9.730785e+06</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>5.656854</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCP</td>\n",
       "      <td>60720</td>\n",
       "      <td>80</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>47662.546875</td>\n",
       "      <td>47662.546875</td>\n",
       "      <td>95325.093750</td>\n",
       "      <td>5.433530e+06</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>4.242640</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCP</td>\n",
       "      <td>60731</td>\n",
       "      <td>80</td>\n",
       "      <td>55.912911</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "      <td>1632</td>\n",
       "      <td>43821</td>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>426</td>\n",
       "      <td>1434</td>\n",
       "      <td>77.714287</td>\n",
       "      <td>1252.028564</td>\n",
       "      <td>79.812993</td>\n",
       "      <td>459.122215</td>\n",
       "      <td>55.912897</td>\n",
       "      <td>55.912895</td>\n",
       "      <td>0.006430</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>50.871063</td>\n",
       "      <td>50.879055</td>\n",
       "      <td>2.795645</td>\n",
       "      <td>1.644497</td>\n",
       "      <td>11.363543</td>\n",
       "      <td>8.740217</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>432</td>\n",
       "      <td>712</td>\n",
       "      <td>0.375584</td>\n",
       "      <td>0.625973</td>\n",
       "      <td>1.001558</td>\n",
       "      <td>8.129249e+02</td>\n",
       "      <td>811.660714</td>\n",
       "      <td>679.490845</td>\n",
       "      <td>1.101565</td>\n",
       "      <td>6.891815</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.851103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TCP</td>\n",
       "      <td>48889</td>\n",
       "      <td>80</td>\n",
       "      <td>12.624237</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>788</td>\n",
       "      <td>735</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>516</td>\n",
       "      <td>459</td>\n",
       "      <td>157.600006</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>200.381636</td>\n",
       "      <td>174.490687</td>\n",
       "      <td>12.624228</td>\n",
       "      <td>12.624222</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>12.213220</td>\n",
       "      <td>12.211629</td>\n",
       "      <td>3.156057</td>\n",
       "      <td>3.156055</td>\n",
       "      <td>6.038878</td>\n",
       "      <td>6.037814</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>172</td>\n",
       "      <td>0.396064</td>\n",
       "      <td>0.396064</td>\n",
       "      <td>0.792127</td>\n",
       "      <td>1.206410e+02</td>\n",
       "      <td>152.300000</td>\n",
       "      <td>177.225571</td>\n",
       "      <td>2.737010</td>\n",
       "      <td>5.315071</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.932741</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310658</th>\n",
       "      <td>UDP</td>\n",
       "      <td>58665</td>\n",
       "      <td>53</td>\n",
       "      <td>0.259362</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>382</td>\n",
       "      <td>73</td>\n",
       "      <td>382</td>\n",
       "      <td>73</td>\n",
       "      <td>382</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>382.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>348</td>\n",
       "      <td>3.855615</td>\n",
       "      <td>3.855615</td>\n",
       "      <td>7.711230</td>\n",
       "      <td>1.754305e+03</td>\n",
       "      <td>227.500000</td>\n",
       "      <td>218.496002</td>\n",
       "      <td>0.259362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.232877</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310659</th>\n",
       "      <td>UDP</td>\n",
       "      <td>47777</td>\n",
       "      <td>53</td>\n",
       "      <td>0.076347</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>324</td>\n",
       "      <td>84</td>\n",
       "      <td>324</td>\n",
       "      <td>84</td>\n",
       "      <td>324</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>290</td>\n",
       "      <td>13.098072</td>\n",
       "      <td>13.098072</td>\n",
       "      <td>26.196144</td>\n",
       "      <td>5.344014e+03</td>\n",
       "      <td>204.000000</td>\n",
       "      <td>169.705627</td>\n",
       "      <td>0.076347</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310660</th>\n",
       "      <td>UDP</td>\n",
       "      <td>62559</td>\n",
       "      <td>53</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>143</td>\n",
       "      <td>84</td>\n",
       "      <td>143</td>\n",
       "      <td>84</td>\n",
       "      <td>143</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>109</td>\n",
       "      <td>5433.036133</td>\n",
       "      <td>5433.036133</td>\n",
       "      <td>10866.072266</td>\n",
       "      <td>1.233299e+06</td>\n",
       "      <td>113.500000</td>\n",
       "      <td>41.719299</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.702381</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310661</th>\n",
       "      <td>UDP</td>\n",
       "      <td>47777</td>\n",
       "      <td>53</td>\n",
       "      <td>0.107837</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>129</td>\n",
       "      <td>100</td>\n",
       "      <td>129</td>\n",
       "      <td>100</td>\n",
       "      <td>129</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>95</td>\n",
       "      <td>9.273258</td>\n",
       "      <td>9.273258</td>\n",
       "      <td>18.546516</td>\n",
       "      <td>2.123576e+03</td>\n",
       "      <td>114.500000</td>\n",
       "      <td>20.506096</td>\n",
       "      <td>0.107837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.290000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310662</th>\n",
       "      <td>UDP</td>\n",
       "      <td>47777</td>\n",
       "      <td>53</td>\n",
       "      <td>0.071667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>110</td>\n",
       "      <td>89</td>\n",
       "      <td>110</td>\n",
       "      <td>89</td>\n",
       "      <td>110</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>76</td>\n",
       "      <td>13.953432</td>\n",
       "      <td>13.953432</td>\n",
       "      <td>27.906864</td>\n",
       "      <td>2.776733e+03</td>\n",
       "      <td>99.500000</td>\n",
       "      <td>14.849242</td>\n",
       "      <td>0.071667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.235955</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>307754 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       proto  srcPrt  dstPrt  flowduration  total_fpackets  total_bpackets  \\\n",
       "0        TCP   41039      25      0.000012               1               1   \n",
       "1        TCP   41040      25      0.000012               1               1   \n",
       "2        TCP   60720      80      0.000021               1               1   \n",
       "3        TCP   60731      80     55.912911              21              35   \n",
       "4        TCP   48889      80     12.624237               5               5   \n",
       "...      ...     ...     ...           ...             ...             ...   \n",
       "310658   UDP   58665      53      0.259362               1               1   \n",
       "310659   UDP   47777      53      0.076347               1               1   \n",
       "310660   UDP   62559      53      0.000184               1               1   \n",
       "310661   UDP   47777      53      0.107837               1               1   \n",
       "310662   UDP   47777      53      0.071667               1               1   \n",
       "\n",
       "        total_fpktl  total_bpktl  min_fpktl  min_bpktl  max_fpktl  max_bpktl  \\\n",
       "0                62           54         62         54         62         54   \n",
       "1                62           54         62         54         62         54   \n",
       "2                60           54         60         54         60         54   \n",
       "3              1632        43821         60         54        426       1434   \n",
       "4               788          735         66         66        516        459   \n",
       "...             ...          ...        ...        ...        ...        ...   \n",
       "310658           73          382         73        382         73        382   \n",
       "310659           84          324         84        324         84        324   \n",
       "310660           84          143         84        143         84        143   \n",
       "310661          100          129        100        129        100        129   \n",
       "310662           89          110         89        110         89        110   \n",
       "\n",
       "        mean_fpktl   mean_bpktl   std_fpktl   std_bpktl  total_fipt  \\\n",
       "0        62.000000    54.000000    0.000000    0.000000    0.000000   \n",
       "1        62.000000    54.000000    0.000000    0.000000    0.000000   \n",
       "2        60.000000    54.000000    0.000000    0.000000    0.000000   \n",
       "3        77.714287  1252.028564   79.812993  459.122215   55.912897   \n",
       "4       157.600006   147.000000  200.381636  174.490687   12.624228   \n",
       "...            ...          ...         ...         ...         ...   \n",
       "310658   73.000000   382.000000    0.000000    0.000000    0.000000   \n",
       "310659   84.000000   324.000000    0.000000    0.000000    0.000000   \n",
       "310660   84.000000   143.000000    0.000000    0.000000    0.000000   \n",
       "310661  100.000000   129.000000    0.000000    0.000000    0.000000   \n",
       "310662   89.000000   110.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "        total_bipt  min_fipt  min_bipt   max_fipt   max_bipt  mean_fipt  \\\n",
       "0         0.000000  0.000000  0.000000   0.000000   0.000000   0.000000   \n",
       "1         0.000000  0.000000  0.000000   0.000000   0.000000   0.000000   \n",
       "2         0.000000  0.000000  0.000000   0.000000   0.000000   0.000000   \n",
       "3        55.912895  0.006430  0.000005  50.871063  50.879055   2.795645   \n",
       "4        12.624222  0.000705  0.001572  12.213220  12.211629   3.156057   \n",
       "...            ...       ...       ...        ...        ...        ...   \n",
       "310658    0.000000  0.000000  0.000000   0.000000   0.000000   0.000000   \n",
       "310659    0.000000  0.000000  0.000000   0.000000   0.000000   0.000000   \n",
       "310660    0.000000  0.000000  0.000000   0.000000   0.000000   0.000000   \n",
       "310661    0.000000  0.000000  0.000000   0.000000   0.000000   0.000000   \n",
       "310662    0.000000  0.000000  0.000000   0.000000   0.000000   0.000000   \n",
       "\n",
       "        mean_bipt   std_fipt  std_bipt  fpsh_cnt  bpsh_cnt  furg_cnt  \\\n",
       "0        0.000000   0.000000  0.000000         0         0         0   \n",
       "1        0.000000   0.000000  0.000000         0         0         0   \n",
       "2        0.000000   0.000000  0.000000         0         0         0   \n",
       "3        1.644497  11.363543  8.740217         1        11         0   \n",
       "4        3.156055   6.038878  6.037814         1         1         0   \n",
       "...           ...        ...       ...       ...       ...       ...   \n",
       "310658   0.000000   0.000000  0.000000         0         0         0   \n",
       "310659   0.000000   0.000000  0.000000         0         0         0   \n",
       "310660   0.000000   0.000000  0.000000         0         0         0   \n",
       "310661   0.000000   0.000000  0.000000         0         0         0   \n",
       "310662   0.000000   0.000000  0.000000         0         0         0   \n",
       "\n",
       "        burg_cnt  total_fhlen  total_bhlen  fPktsPerSecond  bPktsPerSecond  \\\n",
       "0              0           28           20    83886.078125    83886.078125   \n",
       "1              0           28           20    83886.078125    83886.078125   \n",
       "2              0           20           20    47662.546875    47662.546875   \n",
       "3              0          432          712        0.375584        0.625973   \n",
       "4              0          168          172        0.396064        0.396064   \n",
       "...          ...          ...          ...             ...             ...   \n",
       "310658         0           39          348        3.855615        3.855615   \n",
       "310659         0           50          290       13.098072       13.098072   \n",
       "310660         0           50          109     5433.036133     5433.036133   \n",
       "310661         0           66           95        9.273258        9.273258   \n",
       "310662         0           55           76       13.953432       13.953432   \n",
       "\n",
       "        flowPktsPerSecond  flowBytesPerSecond  mean_flowpktl  std_flowpktl  \\\n",
       "0           167772.156250        9.730785e+06      58.000000      5.656854   \n",
       "1           167772.156250        9.730785e+06      58.000000      5.656854   \n",
       "2            95325.093750        5.433530e+06      57.000000      4.242640   \n",
       "3                1.001558        8.129249e+02     811.660714    679.490845   \n",
       "4                0.792127        1.206410e+02     152.300000    177.225571   \n",
       "...                   ...                 ...            ...           ...   \n",
       "310658           7.711230        1.754305e+03     227.500000    218.496002   \n",
       "310659          26.196144        5.344014e+03     204.000000    169.705627   \n",
       "310660       10866.072266        1.233299e+06     113.500000     41.719299   \n",
       "310661          18.546516        2.123576e+03     114.500000     20.506096   \n",
       "310662          27.906864        2.776733e+03      99.500000     14.849242   \n",
       "\n",
       "        mean_flowipt  std_flowipt  flow_fin  flow_syn  flow_rst  flow_ack  \\\n",
       "0           0.000012     0.000000         0         1         1         1   \n",
       "1           0.000012     0.000000         0         1         1         1   \n",
       "2           0.000021     0.000000         1         0         0         2   \n",
       "3           1.101565     6.891815         2         2         0        55   \n",
       "4           2.737010     5.315071         2         2         0         9   \n",
       "...              ...          ...       ...       ...       ...       ...   \n",
       "310658      0.259362     0.000000         0         0         0         0   \n",
       "310659      0.076347     0.000000         0         0         0         0   \n",
       "310660      0.000184     0.000000         0         0         0         0   \n",
       "310661      0.107837     0.000000         0         0         0         0   \n",
       "310662      0.071667     0.000000         0         0         0         0   \n",
       "\n",
       "        flow_urg  flow_cwr  flow_ece  downUpRatio  label  \n",
       "0              0         0         0     0.870968      0  \n",
       "1              0         0         0     0.870968      0  \n",
       "2              0         0         0     0.900000      0  \n",
       "3              0         0         0    26.851103      0  \n",
       "4              0         0         0     0.932741      0  \n",
       "...          ...       ...       ...          ...    ...  \n",
       "310658         0         0         0     5.232877      0  \n",
       "310659         0         0         0     3.857143      0  \n",
       "310660         0         0         0     1.702381      0  \n",
       "310661         0         0         0     1.290000      0  \n",
       "310662         0         0         0     1.235955      0  \n",
       "\n",
       "[307754 rows x 49 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Class 0 : 289490 of 307754 (94.1%)\n",
      "> Class 1 : 18264 of 307754 (5.9%)\n"
     ]
    }
   ],
   "source": [
    "#check % class distribution \n",
    "y=df['label'].values #convert to nparray\n",
    "\n",
    "classes=np.unique(y)\n",
    "total=len(y)\n",
    "\n",
    "for c in classes:\n",
    "    n_examples=len(y[y==c])\n",
    "    percent = n_examples/total*100\n",
    "    print('> Class %d : %d of %d (%.1f%%)' % (c, n_examples,total,percent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(df.drop(columns=['label']), df['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((246203, 48), (61551, 48))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Original dataset dimensions\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding of categorical variables\n",
    "[Target encoding](https://contrib.scikit-learn.org/category_encoders/targetencoder.html) for categorical features will be used to encode three nominal categorical variables: protocol, source and destination ports. This method is supervised and requires training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load library for target encoder \n",
    "from category_encoders import TargetEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "proto                  object\n",
       "srcPrt                  int64\n",
       "dstPrt                  int64\n",
       "flowduration          float64\n",
       "total_fpackets          int64\n",
       "total_bpackets          int64\n",
       "total_fpktl             int64\n",
       "total_bpktl             int64\n",
       "min_fpktl               int64\n",
       "min_bpktl               int64\n",
       "max_fpktl               int64\n",
       "max_bpktl               int64\n",
       "mean_fpktl            float64\n",
       "mean_bpktl            float64\n",
       "std_fpktl             float64\n",
       "std_bpktl             float64\n",
       "total_fipt            float64\n",
       "total_bipt            float64\n",
       "min_fipt              float64\n",
       "min_bipt              float64\n",
       "max_fipt              float64\n",
       "max_bipt              float64\n",
       "mean_fipt             float64\n",
       "mean_bipt             float64\n",
       "std_fipt              float64\n",
       "std_bipt              float64\n",
       "fpsh_cnt                int64\n",
       "bpsh_cnt                int64\n",
       "furg_cnt                int64\n",
       "burg_cnt                int64\n",
       "total_fhlen             int64\n",
       "total_bhlen             int64\n",
       "fPktsPerSecond        float64\n",
       "bPktsPerSecond        float64\n",
       "flowPktsPerSecond     float64\n",
       "flowBytesPerSecond    float64\n",
       "mean_flowpktl         float64\n",
       "std_flowpktl          float64\n",
       "mean_flowipt          float64\n",
       "std_flowipt           float64\n",
       "flow_fin                int64\n",
       "flow_syn                int64\n",
       "flow_rst                int64\n",
       "flow_ack                int64\n",
       "flow_urg                int64\n",
       "flow_cwr                int64\n",
       "flow_ece                int64\n",
       "downUpRatio           float64\n",
       "label                   int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check data types for each feature\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the three categorical variables to be coded\n",
    "enc = TargetEncoder(cols=['proto','srcPrt','dstPrt'])\n",
    "# fit on the trainning dataset\n",
    "enc.fit_transform(X_train, y_train)\n",
    "# Coding categorical variables of the trainning dataset\n",
    "training_numeric_dataset=enc.transform(X_train)\n",
    "# Coding categorical variables of the test dataset\n",
    "testing_numeric_dataset = enc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proto</th>\n",
       "      <th>srcPrt</th>\n",
       "      <th>dstPrt</th>\n",
       "      <th>flowduration</th>\n",
       "      <th>total_fpackets</th>\n",
       "      <th>total_bpackets</th>\n",
       "      <th>total_fpktl</th>\n",
       "      <th>total_bpktl</th>\n",
       "      <th>min_fpktl</th>\n",
       "      <th>min_bpktl</th>\n",
       "      <th>max_fpktl</th>\n",
       "      <th>max_bpktl</th>\n",
       "      <th>mean_fpktl</th>\n",
       "      <th>mean_bpktl</th>\n",
       "      <th>std_fpktl</th>\n",
       "      <th>std_bpktl</th>\n",
       "      <th>total_fipt</th>\n",
       "      <th>total_bipt</th>\n",
       "      <th>min_fipt</th>\n",
       "      <th>min_bipt</th>\n",
       "      <th>max_fipt</th>\n",
       "      <th>max_bipt</th>\n",
       "      <th>mean_fipt</th>\n",
       "      <th>mean_bipt</th>\n",
       "      <th>std_fipt</th>\n",
       "      <th>std_bipt</th>\n",
       "      <th>fpsh_cnt</th>\n",
       "      <th>bpsh_cnt</th>\n",
       "      <th>furg_cnt</th>\n",
       "      <th>burg_cnt</th>\n",
       "      <th>total_fhlen</th>\n",
       "      <th>total_bhlen</th>\n",
       "      <th>fPktsPerSecond</th>\n",
       "      <th>bPktsPerSecond</th>\n",
       "      <th>flowPktsPerSecond</th>\n",
       "      <th>flowBytesPerSecond</th>\n",
       "      <th>mean_flowpktl</th>\n",
       "      <th>std_flowpktl</th>\n",
       "      <th>mean_flowipt</th>\n",
       "      <th>std_flowipt</th>\n",
       "      <th>flow_fin</th>\n",
       "      <th>flow_syn</th>\n",
       "      <th>flow_rst</th>\n",
       "      <th>flow_ack</th>\n",
       "      <th>flow_urg</th>\n",
       "      <th>flow_cwr</th>\n",
       "      <th>flow_ece</th>\n",
       "      <th>downUpRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>214710</th>\n",
       "      <td>0.025356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025093</td>\n",
       "      <td>181.908309</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>533</td>\n",
       "      <td>1086</td>\n",
       "      <td>72</td>\n",
       "      <td>120</td>\n",
       "      <td>86</td>\n",
       "      <td>216</td>\n",
       "      <td>76.14286</td>\n",
       "      <td>155.142853</td>\n",
       "      <td>4.913538</td>\n",
       "      <td>30.262345</td>\n",
       "      <td>181.726792</td>\n",
       "      <td>181.723170</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>87.210060</td>\n",
       "      <td>87.210007</td>\n",
       "      <td>30.287798</td>\n",
       "      <td>30.287195</td>\n",
       "      <td>43.597218</td>\n",
       "      <td>43.596474</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>295</td>\n",
       "      <td>848</td>\n",
       "      <td>0.038481</td>\n",
       "      <td>0.038481</td>\n",
       "      <td>0.076962</td>\n",
       "      <td>8.900088e+00</td>\n",
       "      <td>115.642857</td>\n",
       "      <td>45.979271</td>\n",
       "      <td>14.064630</td>\n",
       "      <td>32.192545</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.037524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85870</th>\n",
       "      <td>0.025356</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>0.025093</td>\n",
       "      <td>14.980404</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>68.00000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>0.066754</td>\n",
       "      <td>0.066754</td>\n",
       "      <td>0.133508</td>\n",
       "      <td>9.078526e+00</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.980404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257863</th>\n",
       "      <td>0.025356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025093</td>\n",
       "      <td>0.077758</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>305</td>\n",
       "      <td>91</td>\n",
       "      <td>305</td>\n",
       "      <td>91</td>\n",
       "      <td>305</td>\n",
       "      <td>91.00000</td>\n",
       "      <td>305.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>271</td>\n",
       "      <td>12.860401</td>\n",
       "      <td>12.860401</td>\n",
       "      <td>25.720802</td>\n",
       "      <td>5.092719e+03</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>151.320847</td>\n",
       "      <td>0.077758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.351648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252154</th>\n",
       "      <td>0.025356</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.025093</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>169</td>\n",
       "      <td>77</td>\n",
       "      <td>169</td>\n",
       "      <td>77</td>\n",
       "      <td>169</td>\n",
       "      <td>77.00000</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>135</td>\n",
       "      <td>3226.387695</td>\n",
       "      <td>3226.387695</td>\n",
       "      <td>6452.775391</td>\n",
       "      <td>7.936914e+05</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>65.053825</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.194805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10867</th>\n",
       "      <td>0.167577</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.021653</td>\n",
       "      <td>5.899355</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>993</td>\n",
       "      <td>8622</td>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>571</td>\n",
       "      <td>1434</td>\n",
       "      <td>124.12500</td>\n",
       "      <td>862.200012</td>\n",
       "      <td>180.566124</td>\n",
       "      <td>696.695975</td>\n",
       "      <td>5.899345</td>\n",
       "      <td>5.899335</td>\n",
       "      <td>0.011698</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>4.927249</td>\n",
       "      <td>4.945889</td>\n",
       "      <td>0.842763</td>\n",
       "      <td>0.655482</td>\n",
       "      <td>1.817853</td>\n",
       "      <td>1.626900</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>208</td>\n",
       "      <td>1.356080</td>\n",
       "      <td>1.695101</td>\n",
       "      <td>3.051181</td>\n",
       "      <td>1.629839e+03</td>\n",
       "      <td>534.166667</td>\n",
       "      <td>642.505554</td>\n",
       "      <td>0.638679</td>\n",
       "      <td>1.614033</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.682779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120465</th>\n",
       "      <td>0.025356</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.025093</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>54</td>\n",
       "      <td>161</td>\n",
       "      <td>54</td>\n",
       "      <td>161</td>\n",
       "      <td>54</td>\n",
       "      <td>161.00000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>20</td>\n",
       "      <td>5882.614258</td>\n",
       "      <td>5882.614258</td>\n",
       "      <td>11765.228516</td>\n",
       "      <td>1.264762e+06</td>\n",
       "      <td>107.500000</td>\n",
       "      <td>75.660423</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.335404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261382</th>\n",
       "      <td>0.025356</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.025093</td>\n",
       "      <td>5.311210</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>158</td>\n",
       "      <td>724</td>\n",
       "      <td>79</td>\n",
       "      <td>362</td>\n",
       "      <td>79</td>\n",
       "      <td>362</td>\n",
       "      <td>79.00000</td>\n",
       "      <td>362.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.310636</td>\n",
       "      <td>5.310701</td>\n",
       "      <td>5.310636</td>\n",
       "      <td>5.310701</td>\n",
       "      <td>5.310636</td>\n",
       "      <td>5.310701</td>\n",
       "      <td>5.310636</td>\n",
       "      <td>5.310701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>656</td>\n",
       "      <td>0.376562</td>\n",
       "      <td>0.376562</td>\n",
       "      <td>0.753124</td>\n",
       "      <td>1.660639e+02</td>\n",
       "      <td>220.500000</td>\n",
       "      <td>163.390121</td>\n",
       "      <td>1.770573</td>\n",
       "      <td>3.065785</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.582278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132663</th>\n",
       "      <td>0.025356</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>0.025093</td>\n",
       "      <td>19.777777</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>72.00000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>0.050562</td>\n",
       "      <td>0.050562</td>\n",
       "      <td>0.101124</td>\n",
       "      <td>7.280899e+00</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.777777</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147738</th>\n",
       "      <td>0.025356</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.025093</td>\n",
       "      <td>8.926250</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>234</td>\n",
       "      <td>435</td>\n",
       "      <td>78</td>\n",
       "      <td>145</td>\n",
       "      <td>78</td>\n",
       "      <td>145</td>\n",
       "      <td>78.00000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.926037</td>\n",
       "      <td>8.926047</td>\n",
       "      <td>0.493811</td>\n",
       "      <td>0.493788</td>\n",
       "      <td>8.432226</td>\n",
       "      <td>8.432259</td>\n",
       "      <td>4.463018</td>\n",
       "      <td>4.463023</td>\n",
       "      <td>5.613307</td>\n",
       "      <td>5.613346</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>333</td>\n",
       "      <td>0.336087</td>\n",
       "      <td>0.336087</td>\n",
       "      <td>0.672175</td>\n",
       "      <td>7.494749e+01</td>\n",
       "      <td>111.500000</td>\n",
       "      <td>36.697411</td>\n",
       "      <td>1.785338</td>\n",
       "      <td>3.721865</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.858974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122562</th>\n",
       "      <td>0.025356</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.025093</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>162</td>\n",
       "      <td>76</td>\n",
       "      <td>162</td>\n",
       "      <td>76</td>\n",
       "      <td>162</td>\n",
       "      <td>76.00000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>128</td>\n",
       "      <td>4466.777344</td>\n",
       "      <td>4466.777344</td>\n",
       "      <td>8933.554688</td>\n",
       "      <td>1.063093e+06</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>60.811184</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.131579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246203 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           proto    srcPrt    dstPrt  flowduration  total_fpackets  \\\n",
       "214710  0.025356  0.000000  0.025093    181.908309               7   \n",
       "85870   0.025356  0.001066  0.025093     14.980404               1   \n",
       "257863  0.025356  0.000000  0.025093      0.077758               1   \n",
       "252154  0.025356  0.333333  0.025093      0.000310               1   \n",
       "10867   0.167577  0.153846  0.021653      5.899355               8   \n",
       "...          ...       ...       ...           ...             ...   \n",
       "120465  0.025356  0.000003  0.025093      0.000170               1   \n",
       "261382  0.025356  0.000020  0.025093      5.311210               2   \n",
       "132663  0.025356  0.001066  0.025093     19.777777               1   \n",
       "147738  0.025356  0.000054  0.025093      8.926250               3   \n",
       "122562  0.025356  0.000054  0.025093      0.000224               1   \n",
       "\n",
       "        total_bpackets  total_fpktl  total_bpktl  min_fpktl  min_bpktl  \\\n",
       "214710               7          533         1086         72        120   \n",
       "85870                1           68           68         68         68   \n",
       "257863               1           91          305         91        305   \n",
       "252154               1           77          169         77        169   \n",
       "10867               10          993         8622         60         54   \n",
       "...                ...          ...          ...        ...        ...   \n",
       "120465               1          161           54        161         54   \n",
       "261382               2          158          724         79        362   \n",
       "132663               1           72           72         72         72   \n",
       "147738               3          234          435         78        145   \n",
       "122562               1           76          162         76        162   \n",
       "\n",
       "        max_fpktl  max_bpktl  mean_fpktl  mean_bpktl   std_fpktl   std_bpktl  \\\n",
       "214710         86        216    76.14286  155.142853    4.913538   30.262345   \n",
       "85870          68         68    68.00000   68.000000    0.000000    0.000000   \n",
       "257863         91        305    91.00000  305.000000    0.000000    0.000000   \n",
       "252154         77        169    77.00000  169.000000    0.000000    0.000000   \n",
       "10867         571       1434   124.12500  862.200012  180.566124  696.695975   \n",
       "...           ...        ...         ...         ...         ...         ...   \n",
       "120465        161         54   161.00000   54.000000    0.000000    0.000000   \n",
       "261382         79        362    79.00000  362.000000    0.000000    0.000000   \n",
       "132663         72         72    72.00000   72.000000    0.000000    0.000000   \n",
       "147738         78        145    78.00000  145.000000    0.000000    0.000000   \n",
       "122562         76        162    76.00000  162.000000    0.000000    0.000000   \n",
       "\n",
       "        total_fipt  total_bipt  min_fipt  min_bipt   max_fipt   max_bipt  \\\n",
       "214710  181.726792  181.723170  0.000057  0.000018  87.210060  87.210007   \n",
       "85870     0.000000    0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "257863    0.000000    0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "252154    0.000000    0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "10867     5.899345    5.899335  0.011698  0.000009   4.927249   4.945889   \n",
       "...            ...         ...       ...       ...        ...        ...   \n",
       "120465    0.000000    0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "261382    5.310636    5.310701  5.310636  5.310701   5.310636   5.310701   \n",
       "132663    0.000000    0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "147738    8.926037    8.926047  0.493811  0.493788   8.432226   8.432259   \n",
       "122562    0.000000    0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "\n",
       "        mean_fipt  mean_bipt   std_fipt   std_bipt  fpsh_cnt  bpsh_cnt  \\\n",
       "214710  30.287798  30.287195  43.597218  43.596474         0         0   \n",
       "85870    0.000000   0.000000   0.000000   0.000000         0         0   \n",
       "257863   0.000000   0.000000   0.000000   0.000000         0         0   \n",
       "252154   0.000000   0.000000   0.000000   0.000000         0         0   \n",
       "10867    0.842763   0.655482   1.817853   1.626900         1         2   \n",
       "...           ...        ...        ...        ...       ...       ...   \n",
       "120465   0.000000   0.000000   0.000000   0.000000         0         0   \n",
       "261382   5.310636   5.310701   0.000000   0.000000         0         0   \n",
       "132663   0.000000   0.000000   0.000000   0.000000         0         0   \n",
       "147738   4.463018   4.463023   5.613307   5.613346         0         0   \n",
       "122562   0.000000   0.000000   0.000000   0.000000         0         0   \n",
       "\n",
       "        furg_cnt  burg_cnt  total_fhlen  total_bhlen  fPktsPerSecond  \\\n",
       "214710         0         0          295          848        0.038481   \n",
       "85870          0         0           34           34        0.066754   \n",
       "257863         0         0           57          271       12.860401   \n",
       "252154         0         0           43          135     3226.387695   \n",
       "10867          0         0          168          208        1.356080   \n",
       "...          ...       ...          ...          ...             ...   \n",
       "120465         0         0          127           20     5882.614258   \n",
       "261382         0         0           90          656        0.376562   \n",
       "132663         0         0           38           38        0.050562   \n",
       "147738         0         0          132          333        0.336087   \n",
       "122562         0         0           42          128     4466.777344   \n",
       "\n",
       "        bPktsPerSecond  flowPktsPerSecond  flowBytesPerSecond  mean_flowpktl  \\\n",
       "214710        0.038481           0.076962        8.900088e+00     115.642857   \n",
       "85870         0.066754           0.133508        9.078526e+00      68.000000   \n",
       "257863       12.860401          25.720802        5.092719e+03     198.000000   \n",
       "252154     3226.387695        6452.775391        7.936914e+05     123.000000   \n",
       "10867         1.695101           3.051181        1.629839e+03     534.166667   \n",
       "...                ...                ...                 ...            ...   \n",
       "120465     5882.614258       11765.228516        1.264762e+06     107.500000   \n",
       "261382        0.376562           0.753124        1.660639e+02     220.500000   \n",
       "132663        0.050562           0.101124        7.280899e+00      72.000000   \n",
       "147738        0.336087           0.672175        7.494749e+01     111.500000   \n",
       "122562     4466.777344        8933.554688        1.063093e+06     119.000000   \n",
       "\n",
       "        std_flowpktl  mean_flowipt  std_flowipt  flow_fin  flow_syn  flow_rst  \\\n",
       "214710     45.979271     14.064630    32.192545         0         0         0   \n",
       "85870       0.000000     14.980404     0.000000         0         0         0   \n",
       "257863    151.320847      0.077758     0.000000         0         0         0   \n",
       "252154     65.053825      0.000310     0.000000         0         0         0   \n",
       "10867     642.505554      0.638679     1.614033         2         2         0   \n",
       "...              ...           ...          ...       ...       ...       ...   \n",
       "120465     75.660423      0.000170     0.000000         0         0         0   \n",
       "261382    163.390121      1.770573     3.065785         0         0         0   \n",
       "132663      0.000000     19.777777     0.000000         0         0         0   \n",
       "147738     36.697411      1.785338     3.721865         0         0         0   \n",
       "122562     60.811184      0.000224     0.000000         0         0         0   \n",
       "\n",
       "        flow_ack  flow_urg  flow_cwr  flow_ece  downUpRatio  \n",
       "214710         0         0         0         0     2.037524  \n",
       "85870          0         0         0         0     1.000000  \n",
       "257863         0         0         0         0     3.351648  \n",
       "252154         0         0         0         0     2.194805  \n",
       "10867         17         0         0         0     8.682779  \n",
       "...          ...       ...       ...       ...          ...  \n",
       "120465         0         0         0         0     0.335404  \n",
       "261382         0         0         0         0     4.582278  \n",
       "132663         0         0         0         0     1.000000  \n",
       "147738         0         0         0         0     1.858974  \n",
       "122562         0         0         0         0     2.131579  \n",
       "\n",
       "[246203 rows x 48 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show trainning dataset\n",
    "training_numeric_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proto</th>\n",
       "      <th>srcPrt</th>\n",
       "      <th>dstPrt</th>\n",
       "      <th>flowduration</th>\n",
       "      <th>total_fpackets</th>\n",
       "      <th>total_bpackets</th>\n",
       "      <th>total_fpktl</th>\n",
       "      <th>total_bpktl</th>\n",
       "      <th>min_fpktl</th>\n",
       "      <th>min_bpktl</th>\n",
       "      <th>max_fpktl</th>\n",
       "      <th>max_bpktl</th>\n",
       "      <th>mean_fpktl</th>\n",
       "      <th>mean_bpktl</th>\n",
       "      <th>std_fpktl</th>\n",
       "      <th>std_bpktl</th>\n",
       "      <th>total_fipt</th>\n",
       "      <th>total_bipt</th>\n",
       "      <th>min_fipt</th>\n",
       "      <th>min_bipt</th>\n",
       "      <th>max_fipt</th>\n",
       "      <th>max_bipt</th>\n",
       "      <th>mean_fipt</th>\n",
       "      <th>mean_bipt</th>\n",
       "      <th>std_fipt</th>\n",
       "      <th>std_bipt</th>\n",
       "      <th>fpsh_cnt</th>\n",
       "      <th>bpsh_cnt</th>\n",
       "      <th>furg_cnt</th>\n",
       "      <th>burg_cnt</th>\n",
       "      <th>total_fhlen</th>\n",
       "      <th>total_bhlen</th>\n",
       "      <th>fPktsPerSecond</th>\n",
       "      <th>bPktsPerSecond</th>\n",
       "      <th>flowPktsPerSecond</th>\n",
       "      <th>flowBytesPerSecond</th>\n",
       "      <th>mean_flowpktl</th>\n",
       "      <th>std_flowpktl</th>\n",
       "      <th>mean_flowipt</th>\n",
       "      <th>std_flowipt</th>\n",
       "      <th>flow_fin</th>\n",
       "      <th>flow_syn</th>\n",
       "      <th>flow_rst</th>\n",
       "      <th>flow_ack</th>\n",
       "      <th>flow_urg</th>\n",
       "      <th>flow_cwr</th>\n",
       "      <th>flow_ece</th>\n",
       "      <th>downUpRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156306</th>\n",
       "      <td>0.025356</td>\n",
       "      <td>5.929254e-02</td>\n",
       "      <td>0.025093</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>54</td>\n",
       "      <td>106</td>\n",
       "      <td>54</td>\n",
       "      <td>106</td>\n",
       "      <td>54</td>\n",
       "      <td>106.00000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>20</td>\n",
       "      <td>9532.508789</td>\n",
       "      <td>9532.508789</td>\n",
       "      <td>19065.017578</td>\n",
       "      <td>1.525202e+06</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>36.769554</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.509434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190053</th>\n",
       "      <td>0.025356</td>\n",
       "      <td>9.968726e-01</td>\n",
       "      <td>0.025093</td>\n",
       "      <td>60.318130</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>568</td>\n",
       "      <td>1544</td>\n",
       "      <td>66</td>\n",
       "      <td>342</td>\n",
       "      <td>75</td>\n",
       "      <td>458</td>\n",
       "      <td>71.00000</td>\n",
       "      <td>386.000000</td>\n",
       "      <td>3.464102</td>\n",
       "      <td>53.447794</td>\n",
       "      <td>60.193201</td>\n",
       "      <td>60.193153</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.144929</td>\n",
       "      <td>59.297104</td>\n",
       "      <td>59.297256</td>\n",
       "      <td>8.599029</td>\n",
       "      <td>20.064384</td>\n",
       "      <td>22.356379</td>\n",
       "      <td>33.978016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>296</td>\n",
       "      <td>1408</td>\n",
       "      <td>0.132630</td>\n",
       "      <td>0.066315</td>\n",
       "      <td>0.198945</td>\n",
       "      <td>3.501435e+01</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>157.611145</td>\n",
       "      <td>5.516488</td>\n",
       "      <td>17.837491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.718310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239389</th>\n",
       "      <td>0.025356</td>\n",
       "      <td>3.643037e-07</td>\n",
       "      <td>0.025093</td>\n",
       "      <td>2.132073</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>149</td>\n",
       "      <td>85</td>\n",
       "      <td>149</td>\n",
       "      <td>85</td>\n",
       "      <td>149</td>\n",
       "      <td>85.00000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>115</td>\n",
       "      <td>0.469027</td>\n",
       "      <td>0.469027</td>\n",
       "      <td>0.938054</td>\n",
       "      <td>1.097523e+02</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>45.254833</td>\n",
       "      <td>2.132073</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.752941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65943</th>\n",
       "      <td>0.167577</td>\n",
       "      <td>9.902696e-07</td>\n",
       "      <td>0.021653</td>\n",
       "      <td>80.740670</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>1130</td>\n",
       "      <td>21826</td>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>368</td>\n",
       "      <td>1434</td>\n",
       "      <td>86.92308</td>\n",
       "      <td>909.416687</td>\n",
       "      <td>84.611324</td>\n",
       "      <td>677.102643</td>\n",
       "      <td>80.740668</td>\n",
       "      <td>80.671958</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>77.496185</td>\n",
       "      <td>38.111744</td>\n",
       "      <td>6.728389</td>\n",
       "      <td>3.507476</td>\n",
       "      <td>22.287613</td>\n",
       "      <td>8.695065</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>332</td>\n",
       "      <td>488</td>\n",
       "      <td>0.161009</td>\n",
       "      <td>0.297248</td>\n",
       "      <td>0.458257</td>\n",
       "      <td>2.843177e+02</td>\n",
       "      <td>620.432432</td>\n",
       "      <td>673.613342</td>\n",
       "      <td>4.393708</td>\n",
       "      <td>14.396949</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.315044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155587</th>\n",
       "      <td>0.025356</td>\n",
       "      <td>5.401853e-05</td>\n",
       "      <td>0.025093</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>360</td>\n",
       "      <td>81</td>\n",
       "      <td>360</td>\n",
       "      <td>81</td>\n",
       "      <td>360</td>\n",
       "      <td>81.00000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>326</td>\n",
       "      <td>2105.574219</td>\n",
       "      <td>2105.574219</td>\n",
       "      <td>4211.148438</td>\n",
       "      <td>9.285582e+05</td>\n",
       "      <td>220.500000</td>\n",
       "      <td>197.282791</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.444445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49948</th>\n",
       "      <td>0.167577</td>\n",
       "      <td>9.030241e-10</td>\n",
       "      <td>0.021653</td>\n",
       "      <td>9.454764</td>\n",
       "      <td>32</td>\n",
       "      <td>47</td>\n",
       "      <td>2564</td>\n",
       "      <td>61705</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>506</td>\n",
       "      <td>1434</td>\n",
       "      <td>80.12500</td>\n",
       "      <td>1312.872314</td>\n",
       "      <td>77.742233</td>\n",
       "      <td>384.982139</td>\n",
       "      <td>9.454740</td>\n",
       "      <td>9.454748</td>\n",
       "      <td>0.004886</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>3.499667</td>\n",
       "      <td>3.861936</td>\n",
       "      <td>0.304992</td>\n",
       "      <td>0.205538</td>\n",
       "      <td>0.685145</td>\n",
       "      <td>0.635484</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1036</td>\n",
       "      <td>1516</td>\n",
       "      <td>3.384537</td>\n",
       "      <td>4.971039</td>\n",
       "      <td>8.355576</td>\n",
       "      <td>6.797525e+03</td>\n",
       "      <td>813.531646</td>\n",
       "      <td>678.766235</td>\n",
       "      <td>0.123546</td>\n",
       "      <td>0.453059</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.065912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205339</th>\n",
       "      <td>0.025356</td>\n",
       "      <td>5.929254e-02</td>\n",
       "      <td>0.025093</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>139</td>\n",
       "      <td>88</td>\n",
       "      <td>139</td>\n",
       "      <td>88</td>\n",
       "      <td>139</td>\n",
       "      <td>88.00000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>105</td>\n",
       "      <td>6364.649414</td>\n",
       "      <td>6364.649414</td>\n",
       "      <td>12729.298828</td>\n",
       "      <td>1.444775e+06</td>\n",
       "      <td>113.500000</td>\n",
       "      <td>36.062447</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.579545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188501</th>\n",
       "      <td>0.025356</td>\n",
       "      <td>1.594622e-02</td>\n",
       "      <td>0.025093</td>\n",
       "      <td>0.358496</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>74.00000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>2.789432</td>\n",
       "      <td>2.789432</td>\n",
       "      <td>5.578864</td>\n",
       "      <td>4.128359e+02</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.358496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299192</th>\n",
       "      <td>0.025356</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.025093</td>\n",
       "      <td>0.191670</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>223</td>\n",
       "      <td>90</td>\n",
       "      <td>223</td>\n",
       "      <td>90</td>\n",
       "      <td>223</td>\n",
       "      <td>90.00000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>189</td>\n",
       "      <td>5.217296</td>\n",
       "      <td>5.217296</td>\n",
       "      <td>10.434591</td>\n",
       "      <td>1.633014e+03</td>\n",
       "      <td>156.500000</td>\n",
       "      <td>94.045204</td>\n",
       "      <td>0.191670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.477778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267454</th>\n",
       "      <td>0.025356</td>\n",
       "      <td>9.902696e-07</td>\n",
       "      <td>0.025093</td>\n",
       "      <td>0.336579</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>74.00000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>2.971070</td>\n",
       "      <td>2.971070</td>\n",
       "      <td>5.942140</td>\n",
       "      <td>4.397184e+02</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.336579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61551 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           proto        srcPrt    dstPrt  flowduration  total_fpackets  \\\n",
       "156306  0.025356  5.929254e-02  0.025093      0.000105               1   \n",
       "190053  0.025356  9.968726e-01  0.025093     60.318130               8   \n",
       "239389  0.025356  3.643037e-07  0.025093      2.132073               1   \n",
       "65943   0.167577  9.902696e-07  0.021653     80.740670              13   \n",
       "155587  0.025356  5.401853e-05  0.025093      0.000475               1   \n",
       "...          ...           ...       ...           ...             ...   \n",
       "49948   0.167577  9.030241e-10  0.021653      9.454764              32   \n",
       "205339  0.025356  5.929254e-02  0.025093      0.000157               1   \n",
       "188501  0.025356  1.594622e-02  0.025093      0.358496               1   \n",
       "299192  0.025356  0.000000e+00  0.025093      0.191670               1   \n",
       "267454  0.025356  9.902696e-07  0.025093      0.336579               1   \n",
       "\n",
       "        total_bpackets  total_fpktl  total_bpktl  min_fpktl  min_bpktl  \\\n",
       "156306               1          106           54        106         54   \n",
       "190053               4          568         1544         66        342   \n",
       "239389               1           85          149         85        149   \n",
       "65943               24         1130        21826         60         54   \n",
       "155587               1           81          360         81        360   \n",
       "...                ...          ...          ...        ...        ...   \n",
       "49948               47         2564        61705         66         66   \n",
       "205339               1           88          139         88        139   \n",
       "188501               1           74           74         74         74   \n",
       "299192               1           90          223         90        223   \n",
       "267454               1           74           74         74         74   \n",
       "\n",
       "        max_fpktl  max_bpktl  mean_fpktl   mean_bpktl  std_fpktl   std_bpktl  \\\n",
       "156306        106         54   106.00000    54.000000   0.000000    0.000000   \n",
       "190053         75        458    71.00000   386.000000   3.464102   53.447794   \n",
       "239389         85        149    85.00000   149.000000   0.000000    0.000000   \n",
       "65943         368       1434    86.92308   909.416687  84.611324  677.102643   \n",
       "155587         81        360    81.00000   360.000000   0.000000    0.000000   \n",
       "...           ...        ...         ...          ...        ...         ...   \n",
       "49948         506       1434    80.12500  1312.872314  77.742233  384.982139   \n",
       "205339         88        139    88.00000   139.000000   0.000000    0.000000   \n",
       "188501         74         74    74.00000    74.000000   0.000000    0.000000   \n",
       "299192         90        223    90.00000   223.000000   0.000000    0.000000   \n",
       "267454         74         74    74.00000    74.000000   0.000000    0.000000   \n",
       "\n",
       "        total_fipt  total_bipt  min_fipt  min_bipt   max_fipt   max_bipt  \\\n",
       "156306    0.000000    0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "190053   60.193201   60.193153  0.000006  0.144929  59.297104  59.297256   \n",
       "239389    0.000000    0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "65943    80.740668   80.671958  0.000743  0.000008  77.496185  38.111744   \n",
       "155587    0.000000    0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "...            ...         ...       ...       ...        ...        ...   \n",
       "49948     9.454740    9.454748  0.004886  0.000006   3.499667   3.861936   \n",
       "205339    0.000000    0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "188501    0.000000    0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "299192    0.000000    0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "267454    0.000000    0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "\n",
       "        mean_fipt  mean_bipt   std_fipt   std_bipt  fpsh_cnt  bpsh_cnt  \\\n",
       "156306   0.000000   0.000000   0.000000   0.000000         0         0   \n",
       "190053   8.599029  20.064384  22.356379  33.978016         0         0   \n",
       "239389   0.000000   0.000000   0.000000   0.000000         0         0   \n",
       "65943    6.728389   3.507476  22.287613   8.695065         1         8   \n",
       "155587   0.000000   0.000000   0.000000   0.000000         0         0   \n",
       "...           ...        ...        ...        ...       ...       ...   \n",
       "49948    0.304992   0.205538   0.685145   0.635484         1        17   \n",
       "205339   0.000000   0.000000   0.000000   0.000000         0         0   \n",
       "188501   0.000000   0.000000   0.000000   0.000000         0         0   \n",
       "299192   0.000000   0.000000   0.000000   0.000000         0         0   \n",
       "267454   0.000000   0.000000   0.000000   0.000000         0         0   \n",
       "\n",
       "        furg_cnt  burg_cnt  total_fhlen  total_bhlen  fPktsPerSecond  \\\n",
       "156306         0         0           72           20     9532.508789   \n",
       "190053         0         0          296         1408        0.132630   \n",
       "239389         0         0           51          115        0.469027   \n",
       "65943          0         0          332          488        0.161009   \n",
       "155587         0         0           47          326     2105.574219   \n",
       "...          ...       ...          ...          ...             ...   \n",
       "49948          0         0         1036         1516        3.384537   \n",
       "205339         0         0           54          105     6364.649414   \n",
       "188501         0         0           40           40        2.789432   \n",
       "299192         0         0           56          189        5.217296   \n",
       "267454         0         0           40           40        2.971070   \n",
       "\n",
       "        bPktsPerSecond  flowPktsPerSecond  flowBytesPerSecond  mean_flowpktl  \\\n",
       "156306     9532.508789       19065.017578        1.525202e+06      80.000000   \n",
       "190053        0.066315           0.198945        3.501435e+01     176.000000   \n",
       "239389        0.469027           0.938054        1.097523e+02     117.000000   \n",
       "65943         0.297248           0.458257        2.843177e+02     620.432432   \n",
       "155587     2105.574219        4211.148438        9.285582e+05     220.500000   \n",
       "...                ...                ...                 ...            ...   \n",
       "49948         4.971039           8.355576        6.797525e+03     813.531646   \n",
       "205339     6364.649414       12729.298828        1.444775e+06     113.500000   \n",
       "188501        2.789432           5.578864        4.128359e+02      74.000000   \n",
       "299192        5.217296          10.434591        1.633014e+03     156.500000   \n",
       "267454        2.971070           5.942140        4.397184e+02      74.000000   \n",
       "\n",
       "        std_flowpktl  mean_flowipt  std_flowipt  flow_fin  flow_syn  flow_rst  \\\n",
       "156306     36.769554      0.000105     0.000000         0         0         0   \n",
       "190053    157.611145      5.516488    17.837491         0         0         0   \n",
       "239389     45.254833      2.132073     0.000000         0         0         0   \n",
       "65943     673.613342      4.393708    14.396949         7         2         1   \n",
       "155587    197.282791      0.000475     0.000000         0         0         0   \n",
       "...              ...           ...          ...       ...       ...       ...   \n",
       "49948     678.766235      0.123546     0.453059         2         2         0   \n",
       "205339     36.062447      0.000157     0.000000         0         0         0   \n",
       "188501      0.000000      0.358496     0.000000         0         0         0   \n",
       "299192     94.045204      0.191670     0.000000         0         0         0   \n",
       "267454      0.000000      0.336579     0.000000         0         0         0   \n",
       "\n",
       "        flow_ack  flow_urg  flow_cwr  flow_ece  downUpRatio  \n",
       "156306         0         0         0         0     0.509434  \n",
       "190053         0         0         0         0     2.718310  \n",
       "239389         0         0         0         0     1.752941  \n",
       "65943         35         0         0         0    19.315044  \n",
       "155587         0         0         0         0     4.444445  \n",
       "...          ...       ...       ...       ...          ...  \n",
       "49948         78         0         0         0    24.065912  \n",
       "205339         0         0         0         0     1.579545  \n",
       "188501         0         0         0         0     1.000000  \n",
       "299192         0         0         0         0     2.477778  \n",
       "267454         0         0         0         0     1.000000  \n",
       "\n",
       "[61551 rows x 48 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show testing dataset\n",
    "testing_numeric_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardization and scaling of numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_cols = training_numeric_dataset.select_dtypes(include=['float64', 'int']).columns.to_list()\n",
    "preprocessor = ColumnTransformer([('scale', StandardScaler(), numeric_cols)], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit on the trainning dataset\n",
    "preprocessor.fit_transform(training_numeric_dataset)\n",
    "X_train_stand = preprocessor.transform(training_numeric_dataset)\n",
    "X_test_stand  = preprocessor.transform(testing_numeric_dataset)\n",
    "#The result returned by ColumnTransformer is a numpy array, so the column names are lost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-generate the dataset as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=list(training_numeric_dataset.columns.values.tolist())\n",
    "df_X_train_stand=pd.DataFrame(X_train_stand,columns=labels)\n",
    "df_X_test_stand=pd.DataFrame(X_test_stand,columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proto</th>\n",
       "      <th>srcPrt</th>\n",
       "      <th>dstPrt</th>\n",
       "      <th>flowduration</th>\n",
       "      <th>total_fpackets</th>\n",
       "      <th>total_bpackets</th>\n",
       "      <th>total_fpktl</th>\n",
       "      <th>total_bpktl</th>\n",
       "      <th>min_fpktl</th>\n",
       "      <th>min_bpktl</th>\n",
       "      <th>max_fpktl</th>\n",
       "      <th>max_bpktl</th>\n",
       "      <th>mean_fpktl</th>\n",
       "      <th>mean_bpktl</th>\n",
       "      <th>std_fpktl</th>\n",
       "      <th>std_bpktl</th>\n",
       "      <th>total_fipt</th>\n",
       "      <th>total_bipt</th>\n",
       "      <th>min_fipt</th>\n",
       "      <th>min_bipt</th>\n",
       "      <th>max_fipt</th>\n",
       "      <th>max_bipt</th>\n",
       "      <th>mean_fipt</th>\n",
       "      <th>mean_bipt</th>\n",
       "      <th>std_fipt</th>\n",
       "      <th>std_bipt</th>\n",
       "      <th>fpsh_cnt</th>\n",
       "      <th>bpsh_cnt</th>\n",
       "      <th>furg_cnt</th>\n",
       "      <th>burg_cnt</th>\n",
       "      <th>total_fhlen</th>\n",
       "      <th>total_bhlen</th>\n",
       "      <th>fPktsPerSecond</th>\n",
       "      <th>bPktsPerSecond</th>\n",
       "      <th>flowPktsPerSecond</th>\n",
       "      <th>flowBytesPerSecond</th>\n",
       "      <th>mean_flowpktl</th>\n",
       "      <th>std_flowpktl</th>\n",
       "      <th>mean_flowipt</th>\n",
       "      <th>std_flowipt</th>\n",
       "      <th>flow_fin</th>\n",
       "      <th>flow_syn</th>\n",
       "      <th>flow_rst</th>\n",
       "      <th>flow_ack</th>\n",
       "      <th>flow_urg</th>\n",
       "      <th>flow_cwr</th>\n",
       "      <th>flow_ece</th>\n",
       "      <th>downUpRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.559826</td>\n",
       "      <td>-0.335388</td>\n",
       "      <td>-0.213772</td>\n",
       "      <td>1.195319</td>\n",
       "      <td>-0.006503</td>\n",
       "      <td>-0.015504</td>\n",
       "      <td>-0.005116</td>\n",
       "      <td>-0.075125</td>\n",
       "      <td>-0.392445</td>\n",
       "      <td>-0.150419</td>\n",
       "      <td>-0.398600</td>\n",
       "      <td>-0.267301</td>\n",
       "      <td>-0.450292</td>\n",
       "      <td>-0.323381</td>\n",
       "      <td>-0.317058</td>\n",
       "      <td>-0.261627</td>\n",
       "      <td>1.205301</td>\n",
       "      <td>1.752528</td>\n",
       "      <td>-0.157466</td>\n",
       "      <td>-0.111559</td>\n",
       "      <td>6.153691</td>\n",
       "      <td>5.952686</td>\n",
       "      <td>3.838381</td>\n",
       "      <td>4.096133</td>\n",
       "      <td>8.777740</td>\n",
       "      <td>8.258777</td>\n",
       "      <td>-0.019147</td>\n",
       "      <td>-0.038842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.087152</td>\n",
       "      <td>-0.250775</td>\n",
       "      <td>-0.306128</td>\n",
       "      <td>-0.293634</td>\n",
       "      <td>-0.423457</td>\n",
       "      <td>-0.376780</td>\n",
       "      <td>-0.479209</td>\n",
       "      <td>2.264255</td>\n",
       "      <td>6.137893</td>\n",
       "      <td>-0.429674</td>\n",
       "      <td>-0.461294</td>\n",
       "      <td>-0.160378</td>\n",
       "      <td>-0.024718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.202572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.559826</td>\n",
       "      <td>-0.329689</td>\n",
       "      <td>-0.213772</td>\n",
       "      <td>0.026711</td>\n",
       "      <td>-0.019554</td>\n",
       "      <td>-0.041220</td>\n",
       "      <td>-0.006044</td>\n",
       "      <td>-0.084518</td>\n",
       "      <td>-0.531970</td>\n",
       "      <td>-0.640862</td>\n",
       "      <td>-0.494768</td>\n",
       "      <td>-0.584252</td>\n",
       "      <td>-0.629997</td>\n",
       "      <td>-0.619999</td>\n",
       "      <td>-0.386251</td>\n",
       "      <td>-0.414641</td>\n",
       "      <td>-0.069644</td>\n",
       "      <td>-0.076469</td>\n",
       "      <td>-0.157475</td>\n",
       "      <td>-0.111562</td>\n",
       "      <td>-0.331743</td>\n",
       "      <td>-0.255439</td>\n",
       "      <td>-0.247348</td>\n",
       "      <td>-0.196640</td>\n",
       "      <td>-0.277847</td>\n",
       "      <td>-0.226395</td>\n",
       "      <td>-0.019147</td>\n",
       "      <td>-0.038842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.026106</td>\n",
       "      <td>-0.069672</td>\n",
       "      <td>-0.250771</td>\n",
       "      <td>-0.306123</td>\n",
       "      <td>-0.293630</td>\n",
       "      <td>-0.423457</td>\n",
       "      <td>-0.649541</td>\n",
       "      <td>-0.721500</td>\n",
       "      <td>2.434748</td>\n",
       "      <td>-0.308827</td>\n",
       "      <td>-0.429674</td>\n",
       "      <td>-0.461294</td>\n",
       "      <td>-0.160378</td>\n",
       "      <td>-0.024718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.397161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.559826</td>\n",
       "      <td>-0.335388</td>\n",
       "      <td>-0.213772</td>\n",
       "      <td>-0.077618</td>\n",
       "      <td>-0.019554</td>\n",
       "      <td>-0.041220</td>\n",
       "      <td>-0.005998</td>\n",
       "      <td>-0.082331</td>\n",
       "      <td>0.270294</td>\n",
       "      <td>1.594427</td>\n",
       "      <td>-0.371886</td>\n",
       "      <td>-0.076703</td>\n",
       "      <td>-0.122409</td>\n",
       "      <td>0.186703</td>\n",
       "      <td>-0.386251</td>\n",
       "      <td>-0.414641</td>\n",
       "      <td>-0.069644</td>\n",
       "      <td>-0.076469</td>\n",
       "      <td>-0.157475</td>\n",
       "      <td>-0.111562</td>\n",
       "      <td>-0.331743</td>\n",
       "      <td>-0.255439</td>\n",
       "      <td>-0.247348</td>\n",
       "      <td>-0.196640</td>\n",
       "      <td>-0.277847</td>\n",
       "      <td>-0.226395</td>\n",
       "      <td>-0.019147</td>\n",
       "      <td>-0.038842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.023755</td>\n",
       "      <td>-0.024012</td>\n",
       "      <td>-0.249272</td>\n",
       "      <td>-0.304122</td>\n",
       "      <td>-0.291797</td>\n",
       "      <td>-0.418433</td>\n",
       "      <td>0.094723</td>\n",
       "      <td>0.075897</td>\n",
       "      <td>-0.339734</td>\n",
       "      <td>-0.308827</td>\n",
       "      <td>-0.429674</td>\n",
       "      <td>-0.461294</td>\n",
       "      <td>-0.160378</td>\n",
       "      <td>-0.024718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.559826</td>\n",
       "      <td>1.445965</td>\n",
       "      <td>-0.213772</td>\n",
       "      <td>-0.078160</td>\n",
       "      <td>-0.019554</td>\n",
       "      <td>-0.041220</td>\n",
       "      <td>-0.006026</td>\n",
       "      <td>-0.083586</td>\n",
       "      <td>-0.218040</td>\n",
       "      <td>0.311730</td>\n",
       "      <td>-0.446684</td>\n",
       "      <td>-0.367954</td>\n",
       "      <td>-0.431376</td>\n",
       "      <td>-0.276214</td>\n",
       "      <td>-0.386251</td>\n",
       "      <td>-0.414641</td>\n",
       "      <td>-0.069644</td>\n",
       "      <td>-0.076469</td>\n",
       "      <td>-0.157475</td>\n",
       "      <td>-0.111562</td>\n",
       "      <td>-0.331743</td>\n",
       "      <td>-0.255439</td>\n",
       "      <td>-0.247348</td>\n",
       "      <td>-0.196640</td>\n",
       "      <td>-0.277847</td>\n",
       "      <td>-0.226395</td>\n",
       "      <td>-0.019147</td>\n",
       "      <td>-0.038842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.025186</td>\n",
       "      <td>-0.050214</td>\n",
       "      <td>0.127355</td>\n",
       "      <td>0.198496</td>\n",
       "      <td>0.168839</td>\n",
       "      <td>0.360849</td>\n",
       "      <td>-0.334660</td>\n",
       "      <td>-0.378694</td>\n",
       "      <td>-0.354153</td>\n",
       "      <td>-0.308827</td>\n",
       "      <td>-0.429674</td>\n",
       "      <td>-0.461294</td>\n",
       "      <td>-0.160378</td>\n",
       "      <td>-0.024718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.173073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.786270</td>\n",
       "      <td>0.486772</td>\n",
       "      <td>-0.235435</td>\n",
       "      <td>-0.036863</td>\n",
       "      <td>-0.004328</td>\n",
       "      <td>-0.002646</td>\n",
       "      <td>-0.004199</td>\n",
       "      <td>-0.005591</td>\n",
       "      <td>-0.811018</td>\n",
       "      <td>-0.772904</td>\n",
       "      <td>2.192618</td>\n",
       "      <td>2.341114</td>\n",
       "      <td>0.608627</td>\n",
       "      <td>2.083304</td>\n",
       "      <td>2.156511</td>\n",
       "      <td>3.108032</td>\n",
       "      <td>-0.028256</td>\n",
       "      <td>-0.017094</td>\n",
       "      <td>-0.155633</td>\n",
       "      <td>-0.111560</td>\n",
       "      <td>0.034675</td>\n",
       "      <td>0.096639</td>\n",
       "      <td>-0.133662</td>\n",
       "      <td>-0.103735</td>\n",
       "      <td>0.099740</td>\n",
       "      <td>0.090249</td>\n",
       "      <td>-0.008888</td>\n",
       "      <td>-0.014464</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.012408</td>\n",
       "      <td>-0.036150</td>\n",
       "      <td>-0.250620</td>\n",
       "      <td>-0.305868</td>\n",
       "      <td>-0.293421</td>\n",
       "      <td>-0.421855</td>\n",
       "      <td>2.019315</td>\n",
       "      <td>2.664234</td>\n",
       "      <td>-0.235305</td>\n",
       "      <td>0.014391</td>\n",
       "      <td>2.150908</td>\n",
       "      <td>0.995542</td>\n",
       "      <td>-0.160378</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.043756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246198</th>\n",
       "      <td>-0.559826</td>\n",
       "      <td>-0.335374</td>\n",
       "      <td>-0.213772</td>\n",
       "      <td>-0.078161</td>\n",
       "      <td>-0.019554</td>\n",
       "      <td>-0.041220</td>\n",
       "      <td>-0.005858</td>\n",
       "      <td>-0.084647</td>\n",
       "      <td>2.711967</td>\n",
       "      <td>-0.772904</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>-0.614233</td>\n",
       "      <td>1.422423</td>\n",
       "      <td>-0.667652</td>\n",
       "      <td>-0.386251</td>\n",
       "      <td>-0.414641</td>\n",
       "      <td>-0.069644</td>\n",
       "      <td>-0.076469</td>\n",
       "      <td>-0.157475</td>\n",
       "      <td>-0.111562</td>\n",
       "      <td>-0.331743</td>\n",
       "      <td>-0.255439</td>\n",
       "      <td>-0.247348</td>\n",
       "      <td>-0.196640</td>\n",
       "      <td>-0.277847</td>\n",
       "      <td>-0.226395</td>\n",
       "      <td>-0.019147</td>\n",
       "      <td>-0.038842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.016599</td>\n",
       "      <td>-0.072369</td>\n",
       "      <td>0.438666</td>\n",
       "      <td>0.613948</td>\n",
       "      <td>0.549590</td>\n",
       "      <td>0.826355</td>\n",
       "      <td>-0.423399</td>\n",
       "      <td>-0.322801</td>\n",
       "      <td>-0.354179</td>\n",
       "      <td>-0.308827</td>\n",
       "      <td>-0.429674</td>\n",
       "      <td>-0.461294</td>\n",
       "      <td>-0.160378</td>\n",
       "      <td>-0.024718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.521807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246199</th>\n",
       "      <td>-0.559826</td>\n",
       "      <td>-0.335282</td>\n",
       "      <td>-0.213772</td>\n",
       "      <td>-0.040980</td>\n",
       "      <td>-0.017378</td>\n",
       "      <td>-0.036934</td>\n",
       "      <td>-0.005864</td>\n",
       "      <td>-0.078465</td>\n",
       "      <td>-0.148278</td>\n",
       "      <td>2.132029</td>\n",
       "      <td>-0.435999</td>\n",
       "      <td>0.045366</td>\n",
       "      <td>-0.387238</td>\n",
       "      <td>0.380720</td>\n",
       "      <td>-0.386251</td>\n",
       "      <td>-0.414641</td>\n",
       "      <td>-0.032386</td>\n",
       "      <td>-0.023018</td>\n",
       "      <td>0.678771</td>\n",
       "      <td>0.816334</td>\n",
       "      <td>0.063186</td>\n",
       "      <td>0.122608</td>\n",
       "      <td>0.469040</td>\n",
       "      <td>0.556075</td>\n",
       "      <td>-0.277847</td>\n",
       "      <td>-0.226395</td>\n",
       "      <td>-0.019147</td>\n",
       "      <td>-0.038842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.020381</td>\n",
       "      <td>0.050161</td>\n",
       "      <td>-0.250735</td>\n",
       "      <td>-0.306075</td>\n",
       "      <td>-0.293586</td>\n",
       "      <td>-0.423302</td>\n",
       "      <td>0.223538</td>\n",
       "      <td>0.139497</td>\n",
       "      <td>-0.024576</td>\n",
       "      <td>0.305112</td>\n",
       "      <td>-0.429674</td>\n",
       "      <td>-0.461294</td>\n",
       "      <td>-0.160378</td>\n",
       "      <td>-0.024718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.274701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246200</th>\n",
       "      <td>-0.559826</td>\n",
       "      <td>-0.329689</td>\n",
       "      <td>-0.213772</td>\n",
       "      <td>0.060296</td>\n",
       "      <td>-0.019554</td>\n",
       "      <td>-0.041220</td>\n",
       "      <td>-0.006036</td>\n",
       "      <td>-0.084481</td>\n",
       "      <td>-0.392445</td>\n",
       "      <td>-0.603135</td>\n",
       "      <td>-0.473398</td>\n",
       "      <td>-0.575685</td>\n",
       "      <td>-0.541721</td>\n",
       "      <td>-0.606384</td>\n",
       "      <td>-0.386251</td>\n",
       "      <td>-0.414641</td>\n",
       "      <td>-0.069644</td>\n",
       "      <td>-0.076469</td>\n",
       "      <td>-0.157475</td>\n",
       "      <td>-0.111562</td>\n",
       "      <td>-0.331743</td>\n",
       "      <td>-0.255439</td>\n",
       "      <td>-0.247348</td>\n",
       "      <td>-0.196640</td>\n",
       "      <td>-0.277847</td>\n",
       "      <td>-0.226395</td>\n",
       "      <td>-0.019147</td>\n",
       "      <td>-0.038842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.025697</td>\n",
       "      <td>-0.068902</td>\n",
       "      <td>-0.250773</td>\n",
       "      <td>-0.306126</td>\n",
       "      <td>-0.293633</td>\n",
       "      <td>-0.423459</td>\n",
       "      <td>-0.626641</td>\n",
       "      <td>-0.721500</td>\n",
       "      <td>3.327893</td>\n",
       "      <td>-0.308827</td>\n",
       "      <td>-0.429674</td>\n",
       "      <td>-0.461294</td>\n",
       "      <td>-0.160378</td>\n",
       "      <td>-0.024718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.397161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246201</th>\n",
       "      <td>-0.559826</td>\n",
       "      <td>-0.335099</td>\n",
       "      <td>-0.213772</td>\n",
       "      <td>-0.015672</td>\n",
       "      <td>-0.015203</td>\n",
       "      <td>-0.032648</td>\n",
       "      <td>-0.005713</td>\n",
       "      <td>-0.081131</td>\n",
       "      <td>-0.183159</td>\n",
       "      <td>0.085371</td>\n",
       "      <td>-0.441341</td>\n",
       "      <td>-0.419352</td>\n",
       "      <td>-0.409307</td>\n",
       "      <td>-0.357906</td>\n",
       "      <td>-0.386251</td>\n",
       "      <td>-0.414641</td>\n",
       "      <td>-0.007022</td>\n",
       "      <td>0.013369</td>\n",
       "      <td>-0.079717</td>\n",
       "      <td>-0.025286</td>\n",
       "      <td>0.295325</td>\n",
       "      <td>0.344819</td>\n",
       "      <td>0.354699</td>\n",
       "      <td>0.435929</td>\n",
       "      <td>0.888094</td>\n",
       "      <td>0.866130</td>\n",
       "      <td>-0.019147</td>\n",
       "      <td>-0.038842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.016088</td>\n",
       "      <td>-0.012067</td>\n",
       "      <td>-0.250740</td>\n",
       "      <td>-0.306081</td>\n",
       "      <td>-0.293592</td>\n",
       "      <td>-0.423392</td>\n",
       "      <td>-0.400499</td>\n",
       "      <td>-0.528120</td>\n",
       "      <td>-0.021827</td>\n",
       "      <td>0.436495</td>\n",
       "      <td>-0.429674</td>\n",
       "      <td>-0.461294</td>\n",
       "      <td>-0.160378</td>\n",
       "      <td>-0.024718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.236059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246202</th>\n",
       "      <td>-0.559826</td>\n",
       "      <td>-0.335099</td>\n",
       "      <td>-0.213772</td>\n",
       "      <td>-0.078161</td>\n",
       "      <td>-0.019554</td>\n",
       "      <td>-0.041220</td>\n",
       "      <td>-0.006028</td>\n",
       "      <td>-0.083650</td>\n",
       "      <td>-0.252921</td>\n",
       "      <td>0.245709</td>\n",
       "      <td>-0.452027</td>\n",
       "      <td>-0.382945</td>\n",
       "      <td>-0.453445</td>\n",
       "      <td>-0.300041</td>\n",
       "      <td>-0.386251</td>\n",
       "      <td>-0.414641</td>\n",
       "      <td>-0.069644</td>\n",
       "      <td>-0.076469</td>\n",
       "      <td>-0.157475</td>\n",
       "      <td>-0.111562</td>\n",
       "      <td>-0.331743</td>\n",
       "      <td>-0.255439</td>\n",
       "      <td>-0.247348</td>\n",
       "      <td>-0.196640</td>\n",
       "      <td>-0.277847</td>\n",
       "      <td>-0.226395</td>\n",
       "      <td>-0.019147</td>\n",
       "      <td>-0.038842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.025288</td>\n",
       "      <td>-0.051562</td>\n",
       "      <td>0.272729</td>\n",
       "      <td>0.392501</td>\n",
       "      <td>0.346640</td>\n",
       "      <td>0.627068</td>\n",
       "      <td>-0.357560</td>\n",
       "      <td>-0.401051</td>\n",
       "      <td>-0.354169</td>\n",
       "      <td>-0.308827</td>\n",
       "      <td>-0.429674</td>\n",
       "      <td>-0.461294</td>\n",
       "      <td>-0.160378</td>\n",
       "      <td>-0.024718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.184931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246203 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           proto    srcPrt    dstPrt  flowduration  total_fpackets  \\\n",
       "0      -0.559826 -0.335388 -0.213772      1.195319       -0.006503   \n",
       "1      -0.559826 -0.329689 -0.213772      0.026711       -0.019554   \n",
       "2      -0.559826 -0.335388 -0.213772     -0.077618       -0.019554   \n",
       "3      -0.559826  1.445965 -0.213772     -0.078160       -0.019554   \n",
       "4       1.786270  0.486772 -0.235435     -0.036863       -0.004328   \n",
       "...          ...       ...       ...           ...             ...   \n",
       "246198 -0.559826 -0.335374 -0.213772     -0.078161       -0.019554   \n",
       "246199 -0.559826 -0.335282 -0.213772     -0.040980       -0.017378   \n",
       "246200 -0.559826 -0.329689 -0.213772      0.060296       -0.019554   \n",
       "246201 -0.559826 -0.335099 -0.213772     -0.015672       -0.015203   \n",
       "246202 -0.559826 -0.335099 -0.213772     -0.078161       -0.019554   \n",
       "\n",
       "        total_bpackets  total_fpktl  total_bpktl  min_fpktl  min_bpktl  \\\n",
       "0            -0.015504    -0.005116    -0.075125  -0.392445  -0.150419   \n",
       "1            -0.041220    -0.006044    -0.084518  -0.531970  -0.640862   \n",
       "2            -0.041220    -0.005998    -0.082331   0.270294   1.594427   \n",
       "3            -0.041220    -0.006026    -0.083586  -0.218040   0.311730   \n",
       "4            -0.002646    -0.004199    -0.005591  -0.811018  -0.772904   \n",
       "...                ...          ...          ...        ...        ...   \n",
       "246198       -0.041220    -0.005858    -0.084647   2.711967  -0.772904   \n",
       "246199       -0.036934    -0.005864    -0.078465  -0.148278   2.132029   \n",
       "246200       -0.041220    -0.006036    -0.084481  -0.392445  -0.603135   \n",
       "246201       -0.032648    -0.005713    -0.081131  -0.183159   0.085371   \n",
       "246202       -0.041220    -0.006028    -0.083650  -0.252921   0.245709   \n",
       "\n",
       "        max_fpktl  max_bpktl  mean_fpktl  mean_bpktl  std_fpktl  std_bpktl  \\\n",
       "0       -0.398600  -0.267301   -0.450292   -0.323381  -0.317058  -0.261627   \n",
       "1       -0.494768  -0.584252   -0.629997   -0.619999  -0.386251  -0.414641   \n",
       "2       -0.371886  -0.076703   -0.122409    0.186703  -0.386251  -0.414641   \n",
       "3       -0.446684  -0.367954   -0.431376   -0.276214  -0.386251  -0.414641   \n",
       "4        2.192618   2.341114    0.608627    2.083304   2.156511   3.108032   \n",
       "...           ...        ...         ...         ...        ...        ...   \n",
       "246198   0.002104  -0.614233    1.422423   -0.667652  -0.386251  -0.414641   \n",
       "246199  -0.435999   0.045366   -0.387238    0.380720  -0.386251  -0.414641   \n",
       "246200  -0.473398  -0.575685   -0.541721   -0.606384  -0.386251  -0.414641   \n",
       "246201  -0.441341  -0.419352   -0.409307   -0.357906  -0.386251  -0.414641   \n",
       "246202  -0.452027  -0.382945   -0.453445   -0.300041  -0.386251  -0.414641   \n",
       "\n",
       "        total_fipt  total_bipt  min_fipt  min_bipt  max_fipt  max_bipt  \\\n",
       "0         1.205301    1.752528 -0.157466 -0.111559  6.153691  5.952686   \n",
       "1        -0.069644   -0.076469 -0.157475 -0.111562 -0.331743 -0.255439   \n",
       "2        -0.069644   -0.076469 -0.157475 -0.111562 -0.331743 -0.255439   \n",
       "3        -0.069644   -0.076469 -0.157475 -0.111562 -0.331743 -0.255439   \n",
       "4        -0.028256   -0.017094 -0.155633 -0.111560  0.034675  0.096639   \n",
       "...            ...         ...       ...       ...       ...       ...   \n",
       "246198   -0.069644   -0.076469 -0.157475 -0.111562 -0.331743 -0.255439   \n",
       "246199   -0.032386   -0.023018  0.678771  0.816334  0.063186  0.122608   \n",
       "246200   -0.069644   -0.076469 -0.157475 -0.111562 -0.331743 -0.255439   \n",
       "246201   -0.007022    0.013369 -0.079717 -0.025286  0.295325  0.344819   \n",
       "246202   -0.069644   -0.076469 -0.157475 -0.111562 -0.331743 -0.255439   \n",
       "\n",
       "        mean_fipt  mean_bipt  std_fipt  std_bipt  fpsh_cnt  bpsh_cnt  \\\n",
       "0        3.838381   4.096133  8.777740  8.258777 -0.019147 -0.038842   \n",
       "1       -0.247348  -0.196640 -0.277847 -0.226395 -0.019147 -0.038842   \n",
       "2       -0.247348  -0.196640 -0.277847 -0.226395 -0.019147 -0.038842   \n",
       "3       -0.247348  -0.196640 -0.277847 -0.226395 -0.019147 -0.038842   \n",
       "4       -0.133662  -0.103735  0.099740  0.090249 -0.008888 -0.014464   \n",
       "...           ...        ...       ...       ...       ...       ...   \n",
       "246198  -0.247348  -0.196640 -0.277847 -0.226395 -0.019147 -0.038842   \n",
       "246199   0.469040   0.556075 -0.277847 -0.226395 -0.019147 -0.038842   \n",
       "246200  -0.247348  -0.196640 -0.277847 -0.226395 -0.019147 -0.038842   \n",
       "246201   0.354699   0.435929  0.888094  0.866130 -0.019147 -0.038842   \n",
       "246202  -0.247348  -0.196640 -0.277847 -0.226395 -0.019147 -0.038842   \n",
       "\n",
       "        furg_cnt  burg_cnt  total_fhlen  total_bhlen  fPktsPerSecond  \\\n",
       "0            0.0       0.0     0.000575     0.087152       -0.250775   \n",
       "1            0.0       0.0    -0.026106    -0.069672       -0.250771   \n",
       "2            0.0       0.0    -0.023755    -0.024012       -0.249272   \n",
       "3            0.0       0.0    -0.025186    -0.050214        0.127355   \n",
       "4            0.0       0.0    -0.012408    -0.036150       -0.250620   \n",
       "...          ...       ...          ...          ...             ...   \n",
       "246198       0.0       0.0    -0.016599    -0.072369        0.438666   \n",
       "246199       0.0       0.0    -0.020381     0.050161       -0.250735   \n",
       "246200       0.0       0.0    -0.025697    -0.068902       -0.250773   \n",
       "246201       0.0       0.0    -0.016088    -0.012067       -0.250740   \n",
       "246202       0.0       0.0    -0.025288    -0.051562        0.272729   \n",
       "\n",
       "        bPktsPerSecond  flowPktsPerSecond  flowBytesPerSecond  mean_flowpktl  \\\n",
       "0            -0.306128          -0.293634           -0.423457      -0.376780   \n",
       "1            -0.306123          -0.293630           -0.423457      -0.649541   \n",
       "2            -0.304122          -0.291797           -0.418433       0.094723   \n",
       "3             0.198496           0.168839            0.360849      -0.334660   \n",
       "4            -0.305868          -0.293421           -0.421855       2.019315   \n",
       "...                ...                ...                 ...            ...   \n",
       "246198        0.613948           0.549590            0.826355      -0.423399   \n",
       "246199       -0.306075          -0.293586           -0.423302       0.223538   \n",
       "246200       -0.306126          -0.293633           -0.423459      -0.626641   \n",
       "246201       -0.306081          -0.293592           -0.423392      -0.400499   \n",
       "246202        0.392501           0.346640            0.627068      -0.357560   \n",
       "\n",
       "        std_flowpktl  mean_flowipt  std_flowipt  flow_fin  flow_syn  flow_rst  \\\n",
       "0          -0.479209      2.264255     6.137893 -0.429674 -0.461294 -0.160378   \n",
       "1          -0.721500      2.434748    -0.308827 -0.429674 -0.461294 -0.160378   \n",
       "2           0.075897     -0.339734    -0.308827 -0.429674 -0.461294 -0.160378   \n",
       "3          -0.378694     -0.354153    -0.308827 -0.429674 -0.461294 -0.160378   \n",
       "4           2.664234     -0.235305     0.014391  2.150908  0.995542 -0.160378   \n",
       "...              ...           ...          ...       ...       ...       ...   \n",
       "246198     -0.322801     -0.354179    -0.308827 -0.429674 -0.461294 -0.160378   \n",
       "246199      0.139497     -0.024576     0.305112 -0.429674 -0.461294 -0.160378   \n",
       "246200     -0.721500      3.327893    -0.308827 -0.429674 -0.461294 -0.160378   \n",
       "246201     -0.528120     -0.021827     0.436495 -0.429674 -0.461294 -0.160378   \n",
       "246202     -0.401051     -0.354169    -0.308827 -0.429674 -0.461294 -0.160378   \n",
       "\n",
       "        flow_ack  flow_urg  flow_cwr  flow_ece  downUpRatio  \n",
       "0      -0.024718       0.0 -0.004937       0.0    -0.202572  \n",
       "1      -0.024718       0.0 -0.004937       0.0    -0.397161  \n",
       "2      -0.024718       0.0 -0.004937       0.0     0.043894  \n",
       "3      -0.024718       0.0 -0.004937       0.0    -0.173073  \n",
       "4       0.000116       0.0 -0.004937       0.0     1.043756  \n",
       "...          ...       ...       ...       ...          ...  \n",
       "246198 -0.024718       0.0 -0.004937       0.0    -0.521807  \n",
       "246199 -0.024718       0.0 -0.004937       0.0     0.274701  \n",
       "246200 -0.024718       0.0 -0.004937       0.0    -0.397161  \n",
       "246201 -0.024718       0.0 -0.004937       0.0    -0.236059  \n",
       "246202 -0.024718       0.0 -0.004937       0.0    -0.184931  \n",
       "\n",
       "[246203 rows x 48 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_train_stand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proto</th>\n",
       "      <th>srcPrt</th>\n",
       "      <th>dstPrt</th>\n",
       "      <th>flowduration</th>\n",
       "      <th>total_fpackets</th>\n",
       "      <th>total_bpackets</th>\n",
       "      <th>total_fpktl</th>\n",
       "      <th>total_bpktl</th>\n",
       "      <th>min_fpktl</th>\n",
       "      <th>min_bpktl</th>\n",
       "      <th>max_fpktl</th>\n",
       "      <th>max_bpktl</th>\n",
       "      <th>mean_fpktl</th>\n",
       "      <th>mean_bpktl</th>\n",
       "      <th>std_fpktl</th>\n",
       "      <th>std_bpktl</th>\n",
       "      <th>total_fipt</th>\n",
       "      <th>total_bipt</th>\n",
       "      <th>min_fipt</th>\n",
       "      <th>min_bipt</th>\n",
       "      <th>max_fipt</th>\n",
       "      <th>max_bipt</th>\n",
       "      <th>mean_fipt</th>\n",
       "      <th>mean_bipt</th>\n",
       "      <th>std_fipt</th>\n",
       "      <th>std_bipt</th>\n",
       "      <th>fpsh_cnt</th>\n",
       "      <th>bpsh_cnt</th>\n",
       "      <th>furg_cnt</th>\n",
       "      <th>burg_cnt</th>\n",
       "      <th>total_fhlen</th>\n",
       "      <th>total_bhlen</th>\n",
       "      <th>fPktsPerSecond</th>\n",
       "      <th>bPktsPerSecond</th>\n",
       "      <th>flowPktsPerSecond</th>\n",
       "      <th>flowBytesPerSecond</th>\n",
       "      <th>mean_flowpktl</th>\n",
       "      <th>std_flowpktl</th>\n",
       "      <th>mean_flowipt</th>\n",
       "      <th>std_flowipt</th>\n",
       "      <th>flow_fin</th>\n",
       "      <th>flow_syn</th>\n",
       "      <th>flow_rst</th>\n",
       "      <th>flow_ack</th>\n",
       "      <th>flow_urg</th>\n",
       "      <th>flow_cwr</th>\n",
       "      <th>flow_ece</th>\n",
       "      <th>downUpRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.559826</td>\n",
       "      <td>-0.018525</td>\n",
       "      <td>-0.213772</td>\n",
       "      <td>-0.078161</td>\n",
       "      <td>-0.019554</td>\n",
       "      <td>-0.041220</td>\n",
       "      <td>-0.005968</td>\n",
       "      <td>-0.084647</td>\n",
       "      <td>0.793510</td>\n",
       "      <td>-0.772904</td>\n",
       "      <td>-0.291745</td>\n",
       "      <td>-0.614233</td>\n",
       "      <td>0.208626</td>\n",
       "      <td>-0.667652</td>\n",
       "      <td>-0.386251</td>\n",
       "      <td>-0.414641</td>\n",
       "      <td>-0.069644</td>\n",
       "      <td>-0.076469</td>\n",
       "      <td>-0.157475</td>\n",
       "      <td>-0.111562</td>\n",
       "      <td>-0.331743</td>\n",
       "      <td>-0.255439</td>\n",
       "      <td>-0.247348</td>\n",
       "      <td>-0.196640</td>\n",
       "      <td>-0.277847</td>\n",
       "      <td>-0.226395</td>\n",
       "      <td>-0.019147</td>\n",
       "      <td>-0.038842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.022221</td>\n",
       "      <td>-0.072369</td>\n",
       "      <td>0.866436</td>\n",
       "      <td>1.184817</td>\n",
       "      <td>1.072775</td>\n",
       "      <td>1.083718</td>\n",
       "      <td>-0.580840</td>\n",
       "      <td>-0.527740</td>\n",
       "      <td>-0.354191</td>\n",
       "      <td>-0.308827</td>\n",
       "      <td>-0.429674</td>\n",
       "      <td>-0.461294</td>\n",
       "      <td>-0.160378</td>\n",
       "      <td>-0.024718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.489167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.559826</td>\n",
       "      <td>4.991958</td>\n",
       "      <td>-0.213772</td>\n",
       "      <td>0.344105</td>\n",
       "      <td>-0.004328</td>\n",
       "      <td>-0.028362</td>\n",
       "      <td>-0.005047</td>\n",
       "      <td>-0.070899</td>\n",
       "      <td>-0.601732</td>\n",
       "      <td>1.943397</td>\n",
       "      <td>-0.457369</td>\n",
       "      <td>0.250955</td>\n",
       "      <td>-0.563790</td>\n",
       "      <td>0.462412</td>\n",
       "      <td>-0.337469</td>\n",
       "      <td>-0.144395</td>\n",
       "      <td>0.352655</td>\n",
       "      <td>0.529360</td>\n",
       "      <td>-0.157475</td>\n",
       "      <td>-0.086239</td>\n",
       "      <td>4.077925</td>\n",
       "      <td>3.965691</td>\n",
       "      <td>0.912634</td>\n",
       "      <td>2.647197</td>\n",
       "      <td>4.365801</td>\n",
       "      <td>6.386738</td>\n",
       "      <td>-0.019147</td>\n",
       "      <td>-0.038842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.195041</td>\n",
       "      <td>-0.250764</td>\n",
       "      <td>-0.306123</td>\n",
       "      <td>-0.293626</td>\n",
       "      <td>-0.423431</td>\n",
       "      <td>-0.031229</td>\n",
       "      <td>0.109044</td>\n",
       "      <td>0.672815</td>\n",
       "      <td>3.263221</td>\n",
       "      <td>-0.429674</td>\n",
       "      <td>-0.461294</td>\n",
       "      <td>-0.160378</td>\n",
       "      <td>-0.024718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.074889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.559826</td>\n",
       "      <td>-0.335386</td>\n",
       "      <td>-0.213772</td>\n",
       "      <td>-0.063236</td>\n",
       "      <td>-0.019554</td>\n",
       "      <td>-0.041220</td>\n",
       "      <td>-0.006010</td>\n",
       "      <td>-0.083770</td>\n",
       "      <td>0.061008</td>\n",
       "      <td>0.123098</td>\n",
       "      <td>-0.403942</td>\n",
       "      <td>-0.410785</td>\n",
       "      <td>-0.254824</td>\n",
       "      <td>-0.344291</td>\n",
       "      <td>-0.386251</td>\n",
       "      <td>-0.414641</td>\n",
       "      <td>-0.069644</td>\n",
       "      <td>-0.076469</td>\n",
       "      <td>-0.157475</td>\n",
       "      <td>-0.111562</td>\n",
       "      <td>-0.331743</td>\n",
       "      <td>-0.255439</td>\n",
       "      <td>-0.247348</td>\n",
       "      <td>-0.196640</td>\n",
       "      <td>-0.277847</td>\n",
       "      <td>-0.226395</td>\n",
       "      <td>-0.019147</td>\n",
       "      <td>-0.038842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.024368</td>\n",
       "      <td>-0.054067</td>\n",
       "      <td>-0.250724</td>\n",
       "      <td>-0.306060</td>\n",
       "      <td>-0.293573</td>\n",
       "      <td>-0.423357</td>\n",
       "      <td>-0.369011</td>\n",
       "      <td>-0.483026</td>\n",
       "      <td>0.042726</td>\n",
       "      <td>-0.308827</td>\n",
       "      <td>-0.429674</td>\n",
       "      <td>-0.461294</td>\n",
       "      <td>-0.160378</td>\n",
       "      <td>-0.024718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.255945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.786270</td>\n",
       "      <td>-0.335383</td>\n",
       "      <td>-0.235435</td>\n",
       "      <td>0.487077</td>\n",
       "      <td>0.006547</td>\n",
       "      <td>0.057359</td>\n",
       "      <td>-0.003926</td>\n",
       "      <td>0.116239</td>\n",
       "      <td>-0.811018</td>\n",
       "      <td>-0.772904</td>\n",
       "      <td>1.108047</td>\n",
       "      <td>2.341114</td>\n",
       "      <td>-0.212383</td>\n",
       "      <td>2.244021</td>\n",
       "      <td>0.805260</td>\n",
       "      <td>3.008963</td>\n",
       "      <td>0.496810</td>\n",
       "      <td>0.735474</td>\n",
       "      <td>-0.157358</td>\n",
       "      <td>-0.111560</td>\n",
       "      <td>5.431312</td>\n",
       "      <td>2.457581</td>\n",
       "      <td>0.660290</td>\n",
       "      <td>0.300494</td>\n",
       "      <td>4.351518</td>\n",
       "      <td>1.465924</td>\n",
       "      <td>-0.008888</td>\n",
       "      <td>0.058670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004357</td>\n",
       "      <td>0.017795</td>\n",
       "      <td>-0.250760</td>\n",
       "      <td>-0.306087</td>\n",
       "      <td>-0.293607</td>\n",
       "      <td>-0.423185</td>\n",
       "      <td>2.513196</td>\n",
       "      <td>2.828159</td>\n",
       "      <td>0.463783</td>\n",
       "      <td>2.574235</td>\n",
       "      <td>8.602364</td>\n",
       "      <td>0.995542</td>\n",
       "      <td>1.699426</td>\n",
       "      <td>0.026409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.037853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.559826</td>\n",
       "      <td>-0.335099</td>\n",
       "      <td>-0.213772</td>\n",
       "      <td>-0.078159</td>\n",
       "      <td>-0.019554</td>\n",
       "      <td>-0.041220</td>\n",
       "      <td>-0.006018</td>\n",
       "      <td>-0.081823</td>\n",
       "      <td>-0.078516</td>\n",
       "      <td>2.113165</td>\n",
       "      <td>-0.425313</td>\n",
       "      <td>0.041083</td>\n",
       "      <td>-0.343100</td>\n",
       "      <td>0.373913</td>\n",
       "      <td>-0.386251</td>\n",
       "      <td>-0.414641</td>\n",
       "      <td>-0.069644</td>\n",
       "      <td>-0.076469</td>\n",
       "      <td>-0.157475</td>\n",
       "      <td>-0.111562</td>\n",
       "      <td>-0.331743</td>\n",
       "      <td>-0.255439</td>\n",
       "      <td>-0.247348</td>\n",
       "      <td>-0.196640</td>\n",
       "      <td>-0.277847</td>\n",
       "      <td>-0.226395</td>\n",
       "      <td>-0.019147</td>\n",
       "      <td>-0.038842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.024777</td>\n",
       "      <td>-0.013416</td>\n",
       "      <td>-0.004005</td>\n",
       "      <td>0.023193</td>\n",
       "      <td>0.008179</td>\n",
       "      <td>0.494123</td>\n",
       "      <td>0.223538</td>\n",
       "      <td>0.318097</td>\n",
       "      <td>-0.354122</td>\n",
       "      <td>-0.308827</td>\n",
       "      <td>-0.429674</td>\n",
       "      <td>-0.461294</td>\n",
       "      <td>-0.160378</td>\n",
       "      <td>-0.024718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.248850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61546</th>\n",
       "      <td>1.786270</td>\n",
       "      <td>-0.335388</td>\n",
       "      <td>-0.235435</td>\n",
       "      <td>-0.011972</td>\n",
       "      <td>0.047873</td>\n",
       "      <td>0.155937</td>\n",
       "      <td>-0.001066</td>\n",
       "      <td>0.484196</td>\n",
       "      <td>-0.601732</td>\n",
       "      <td>-0.659725</td>\n",
       "      <td>1.845342</td>\n",
       "      <td>2.341114</td>\n",
       "      <td>-0.362410</td>\n",
       "      <td>3.617306</td>\n",
       "      <td>0.708528</td>\n",
       "      <td>1.531927</td>\n",
       "      <td>-0.003312</td>\n",
       "      <td>0.018691</td>\n",
       "      <td>-0.156706</td>\n",
       "      <td>-0.111561</td>\n",
       "      <td>-0.071488</td>\n",
       "      <td>0.019477</td>\n",
       "      <td>-0.206206</td>\n",
       "      <td>-0.167508</td>\n",
       "      <td>-0.135535</td>\n",
       "      <td>-0.102711</td>\n",
       "      <td>-0.008888</td>\n",
       "      <td>0.168370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076324</td>\n",
       "      <td>0.215848</td>\n",
       "      <td>-0.250383</td>\n",
       "      <td>-0.305356</td>\n",
       "      <td>-0.293041</td>\n",
       "      <td>-0.416749</td>\n",
       "      <td>3.618711</td>\n",
       "      <td>2.855313</td>\n",
       "      <td>-0.331210</td>\n",
       "      <td>-0.218100</td>\n",
       "      <td>2.150908</td>\n",
       "      <td>0.995542</td>\n",
       "      <td>-0.160378</td>\n",
       "      <td>0.089222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.928886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61547</th>\n",
       "      <td>-0.559826</td>\n",
       "      <td>-0.018525</td>\n",
       "      <td>-0.213772</td>\n",
       "      <td>-0.078161</td>\n",
       "      <td>-0.019554</td>\n",
       "      <td>-0.041220</td>\n",
       "      <td>-0.006004</td>\n",
       "      <td>-0.083863</td>\n",
       "      <td>0.165651</td>\n",
       "      <td>0.028782</td>\n",
       "      <td>-0.387914</td>\n",
       "      <td>-0.432201</td>\n",
       "      <td>-0.188616</td>\n",
       "      <td>-0.378329</td>\n",
       "      <td>-0.386251</td>\n",
       "      <td>-0.414641</td>\n",
       "      <td>-0.069644</td>\n",
       "      <td>-0.076469</td>\n",
       "      <td>-0.157475</td>\n",
       "      <td>-0.111562</td>\n",
       "      <td>-0.331743</td>\n",
       "      <td>-0.255439</td>\n",
       "      <td>-0.247348</td>\n",
       "      <td>-0.196640</td>\n",
       "      <td>-0.277847</td>\n",
       "      <td>-0.226395</td>\n",
       "      <td>-0.019147</td>\n",
       "      <td>-0.038842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.024062</td>\n",
       "      <td>-0.055993</td>\n",
       "      <td>0.495161</td>\n",
       "      <td>0.689342</td>\n",
       "      <td>0.618686</td>\n",
       "      <td>1.004242</td>\n",
       "      <td>-0.389049</td>\n",
       "      <td>-0.531466</td>\n",
       "      <td>-0.354181</td>\n",
       "      <td>-0.308827</td>\n",
       "      <td>-0.429674</td>\n",
       "      <td>-0.461294</td>\n",
       "      <td>-0.160378</td>\n",
       "      <td>-0.024718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.288466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61548</th>\n",
       "      <td>-0.559826</td>\n",
       "      <td>-0.250171</td>\n",
       "      <td>-0.213772</td>\n",
       "      <td>-0.075652</td>\n",
       "      <td>-0.019554</td>\n",
       "      <td>-0.041220</td>\n",
       "      <td>-0.006032</td>\n",
       "      <td>-0.084462</td>\n",
       "      <td>-0.322683</td>\n",
       "      <td>-0.584272</td>\n",
       "      <td>-0.462712</td>\n",
       "      <td>-0.571402</td>\n",
       "      <td>-0.497583</td>\n",
       "      <td>-0.599576</td>\n",
       "      <td>-0.386251</td>\n",
       "      <td>-0.414641</td>\n",
       "      <td>-0.069644</td>\n",
       "      <td>-0.076469</td>\n",
       "      <td>-0.157475</td>\n",
       "      <td>-0.111562</td>\n",
       "      <td>-0.331743</td>\n",
       "      <td>-0.255439</td>\n",
       "      <td>-0.247348</td>\n",
       "      <td>-0.196640</td>\n",
       "      <td>-0.277847</td>\n",
       "      <td>-0.226395</td>\n",
       "      <td>-0.019147</td>\n",
       "      <td>-0.038842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.025493</td>\n",
       "      <td>-0.068516</td>\n",
       "      <td>-0.250452</td>\n",
       "      <td>-0.305697</td>\n",
       "      <td>-0.293240</td>\n",
       "      <td>-0.423058</td>\n",
       "      <td>-0.615190</td>\n",
       "      <td>-0.721500</td>\n",
       "      <td>-0.287468</td>\n",
       "      <td>-0.308827</td>\n",
       "      <td>-0.429674</td>\n",
       "      <td>-0.461294</td>\n",
       "      <td>-0.160378</td>\n",
       "      <td>-0.024718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.397161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61549</th>\n",
       "      <td>-0.559826</td>\n",
       "      <td>-0.335388</td>\n",
       "      <td>-0.213772</td>\n",
       "      <td>-0.076820</td>\n",
       "      <td>-0.019554</td>\n",
       "      <td>-0.041220</td>\n",
       "      <td>-0.006000</td>\n",
       "      <td>-0.083087</td>\n",
       "      <td>0.235413</td>\n",
       "      <td>0.821036</td>\n",
       "      <td>-0.377229</td>\n",
       "      <td>-0.252310</td>\n",
       "      <td>-0.144478</td>\n",
       "      <td>-0.092409</td>\n",
       "      <td>-0.386251</td>\n",
       "      <td>-0.414641</td>\n",
       "      <td>-0.069644</td>\n",
       "      <td>-0.076469</td>\n",
       "      <td>-0.157475</td>\n",
       "      <td>-0.111562</td>\n",
       "      <td>-0.331743</td>\n",
       "      <td>-0.255439</td>\n",
       "      <td>-0.247348</td>\n",
       "      <td>-0.196640</td>\n",
       "      <td>-0.277847</td>\n",
       "      <td>-0.226395</td>\n",
       "      <td>-0.019147</td>\n",
       "      <td>-0.038842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.023857</td>\n",
       "      <td>-0.039810</td>\n",
       "      <td>-0.250168</td>\n",
       "      <td>-0.305318</td>\n",
       "      <td>-0.292892</td>\n",
       "      <td>-0.421852</td>\n",
       "      <td>-0.142869</td>\n",
       "      <td>-0.225921</td>\n",
       "      <td>-0.318527</td>\n",
       "      <td>-0.308827</td>\n",
       "      <td>-0.429674</td>\n",
       "      <td>-0.461294</td>\n",
       "      <td>-0.160378</td>\n",
       "      <td>-0.024718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.120001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61550</th>\n",
       "      <td>-0.559826</td>\n",
       "      <td>-0.335383</td>\n",
       "      <td>-0.213772</td>\n",
       "      <td>-0.075806</td>\n",
       "      <td>-0.019554</td>\n",
       "      <td>-0.041220</td>\n",
       "      <td>-0.006032</td>\n",
       "      <td>-0.084462</td>\n",
       "      <td>-0.322683</td>\n",
       "      <td>-0.584272</td>\n",
       "      <td>-0.462712</td>\n",
       "      <td>-0.571402</td>\n",
       "      <td>-0.497583</td>\n",
       "      <td>-0.599576</td>\n",
       "      <td>-0.386251</td>\n",
       "      <td>-0.414641</td>\n",
       "      <td>-0.069644</td>\n",
       "      <td>-0.076469</td>\n",
       "      <td>-0.157475</td>\n",
       "      <td>-0.111562</td>\n",
       "      <td>-0.331743</td>\n",
       "      <td>-0.255439</td>\n",
       "      <td>-0.247348</td>\n",
       "      <td>-0.196640</td>\n",
       "      <td>-0.277847</td>\n",
       "      <td>-0.226395</td>\n",
       "      <td>-0.019147</td>\n",
       "      <td>-0.038842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.025493</td>\n",
       "      <td>-0.068516</td>\n",
       "      <td>-0.250431</td>\n",
       "      <td>-0.305669</td>\n",
       "      <td>-0.293214</td>\n",
       "      <td>-0.423031</td>\n",
       "      <td>-0.615190</td>\n",
       "      <td>-0.721500</td>\n",
       "      <td>-0.291548</td>\n",
       "      <td>-0.308827</td>\n",
       "      <td>-0.429674</td>\n",
       "      <td>-0.461294</td>\n",
       "      <td>-0.160378</td>\n",
       "      <td>-0.024718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.397161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61551 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          proto    srcPrt    dstPrt  flowduration  total_fpackets  \\\n",
       "0     -0.559826 -0.018525 -0.213772     -0.078161       -0.019554   \n",
       "1     -0.559826  4.991958 -0.213772      0.344105       -0.004328   \n",
       "2     -0.559826 -0.335386 -0.213772     -0.063236       -0.019554   \n",
       "3      1.786270 -0.335383 -0.235435      0.487077        0.006547   \n",
       "4     -0.559826 -0.335099 -0.213772     -0.078159       -0.019554   \n",
       "...         ...       ...       ...           ...             ...   \n",
       "61546  1.786270 -0.335388 -0.235435     -0.011972        0.047873   \n",
       "61547 -0.559826 -0.018525 -0.213772     -0.078161       -0.019554   \n",
       "61548 -0.559826 -0.250171 -0.213772     -0.075652       -0.019554   \n",
       "61549 -0.559826 -0.335388 -0.213772     -0.076820       -0.019554   \n",
       "61550 -0.559826 -0.335383 -0.213772     -0.075806       -0.019554   \n",
       "\n",
       "       total_bpackets  total_fpktl  total_bpktl  min_fpktl  min_bpktl  \\\n",
       "0           -0.041220    -0.005968    -0.084647   0.793510  -0.772904   \n",
       "1           -0.028362    -0.005047    -0.070899  -0.601732   1.943397   \n",
       "2           -0.041220    -0.006010    -0.083770   0.061008   0.123098   \n",
       "3            0.057359    -0.003926     0.116239  -0.811018  -0.772904   \n",
       "4           -0.041220    -0.006018    -0.081823  -0.078516   2.113165   \n",
       "...               ...          ...          ...        ...        ...   \n",
       "61546        0.155937    -0.001066     0.484196  -0.601732  -0.659725   \n",
       "61547       -0.041220    -0.006004    -0.083863   0.165651   0.028782   \n",
       "61548       -0.041220    -0.006032    -0.084462  -0.322683  -0.584272   \n",
       "61549       -0.041220    -0.006000    -0.083087   0.235413   0.821036   \n",
       "61550       -0.041220    -0.006032    -0.084462  -0.322683  -0.584272   \n",
       "\n",
       "       max_fpktl  max_bpktl  mean_fpktl  mean_bpktl  std_fpktl  std_bpktl  \\\n",
       "0      -0.291745  -0.614233    0.208626   -0.667652  -0.386251  -0.414641   \n",
       "1      -0.457369   0.250955   -0.563790    0.462412  -0.337469  -0.144395   \n",
       "2      -0.403942  -0.410785   -0.254824   -0.344291  -0.386251  -0.414641   \n",
       "3       1.108047   2.341114   -0.212383    2.244021   0.805260   3.008963   \n",
       "4      -0.425313   0.041083   -0.343100    0.373913  -0.386251  -0.414641   \n",
       "...          ...        ...         ...         ...        ...        ...   \n",
       "61546   1.845342   2.341114   -0.362410    3.617306   0.708528   1.531927   \n",
       "61547  -0.387914  -0.432201   -0.188616   -0.378329  -0.386251  -0.414641   \n",
       "61548  -0.462712  -0.571402   -0.497583   -0.599576  -0.386251  -0.414641   \n",
       "61549  -0.377229  -0.252310   -0.144478   -0.092409  -0.386251  -0.414641   \n",
       "61550  -0.462712  -0.571402   -0.497583   -0.599576  -0.386251  -0.414641   \n",
       "\n",
       "       total_fipt  total_bipt  min_fipt  min_bipt  max_fipt  max_bipt  \\\n",
       "0       -0.069644   -0.076469 -0.157475 -0.111562 -0.331743 -0.255439   \n",
       "1        0.352655    0.529360 -0.157475 -0.086239  4.077925  3.965691   \n",
       "2       -0.069644   -0.076469 -0.157475 -0.111562 -0.331743 -0.255439   \n",
       "3        0.496810    0.735474 -0.157358 -0.111560  5.431312  2.457581   \n",
       "4       -0.069644   -0.076469 -0.157475 -0.111562 -0.331743 -0.255439   \n",
       "...           ...         ...       ...       ...       ...       ...   \n",
       "61546   -0.003312    0.018691 -0.156706 -0.111561 -0.071488  0.019477   \n",
       "61547   -0.069644   -0.076469 -0.157475 -0.111562 -0.331743 -0.255439   \n",
       "61548   -0.069644   -0.076469 -0.157475 -0.111562 -0.331743 -0.255439   \n",
       "61549   -0.069644   -0.076469 -0.157475 -0.111562 -0.331743 -0.255439   \n",
       "61550   -0.069644   -0.076469 -0.157475 -0.111562 -0.331743 -0.255439   \n",
       "\n",
       "       mean_fipt  mean_bipt  std_fipt  std_bipt  fpsh_cnt  bpsh_cnt  furg_cnt  \\\n",
       "0      -0.247348  -0.196640 -0.277847 -0.226395 -0.019147 -0.038842       0.0   \n",
       "1       0.912634   2.647197  4.365801  6.386738 -0.019147 -0.038842       0.0   \n",
       "2      -0.247348  -0.196640 -0.277847 -0.226395 -0.019147 -0.038842       0.0   \n",
       "3       0.660290   0.300494  4.351518  1.465924 -0.008888  0.058670       0.0   \n",
       "4      -0.247348  -0.196640 -0.277847 -0.226395 -0.019147 -0.038842       0.0   \n",
       "...          ...        ...       ...       ...       ...       ...       ...   \n",
       "61546  -0.206206  -0.167508 -0.135535 -0.102711 -0.008888  0.168370       0.0   \n",
       "61547  -0.247348  -0.196640 -0.277847 -0.226395 -0.019147 -0.038842       0.0   \n",
       "61548  -0.247348  -0.196640 -0.277847 -0.226395 -0.019147 -0.038842       0.0   \n",
       "61549  -0.247348  -0.196640 -0.277847 -0.226395 -0.019147 -0.038842       0.0   \n",
       "61550  -0.247348  -0.196640 -0.277847 -0.226395 -0.019147 -0.038842       0.0   \n",
       "\n",
       "       burg_cnt  total_fhlen  total_bhlen  fPktsPerSecond  bPktsPerSecond  \\\n",
       "0           0.0    -0.022221    -0.072369        0.866436        1.184817   \n",
       "1           0.0     0.000677     0.195041       -0.250764       -0.306123   \n",
       "2           0.0    -0.024368    -0.054067       -0.250724       -0.306060   \n",
       "3           0.0     0.004357     0.017795       -0.250760       -0.306087   \n",
       "4           0.0    -0.024777    -0.013416       -0.004005        0.023193   \n",
       "...         ...          ...          ...             ...             ...   \n",
       "61546       0.0     0.076324     0.215848       -0.250383       -0.305356   \n",
       "61547       0.0    -0.024062    -0.055993        0.495161        0.689342   \n",
       "61548       0.0    -0.025493    -0.068516       -0.250452       -0.305697   \n",
       "61549       0.0    -0.023857    -0.039810       -0.250168       -0.305318   \n",
       "61550       0.0    -0.025493    -0.068516       -0.250431       -0.305669   \n",
       "\n",
       "       flowPktsPerSecond  flowBytesPerSecond  mean_flowpktl  std_flowpktl  \\\n",
       "0               1.072775            1.083718      -0.580840     -0.527740   \n",
       "1              -0.293626           -0.423431      -0.031229      0.109044   \n",
       "2              -0.293573           -0.423357      -0.369011     -0.483026   \n",
       "3              -0.293607           -0.423185       2.513196      2.828159   \n",
       "4               0.008179            0.494123       0.223538      0.318097   \n",
       "...                  ...                 ...            ...           ...   \n",
       "61546          -0.293041           -0.416749       3.618711      2.855313   \n",
       "61547           0.618686            1.004242      -0.389049     -0.531466   \n",
       "61548          -0.293240           -0.423058      -0.615190     -0.721500   \n",
       "61549          -0.292892           -0.421852      -0.142869     -0.225921   \n",
       "61550          -0.293214           -0.423031      -0.615190     -0.721500   \n",
       "\n",
       "       mean_flowipt  std_flowipt  flow_fin  flow_syn  flow_rst  flow_ack  \\\n",
       "0         -0.354191    -0.308827 -0.429674 -0.461294 -0.160378 -0.024718   \n",
       "1          0.672815     3.263221 -0.429674 -0.461294 -0.160378 -0.024718   \n",
       "2          0.042726    -0.308827 -0.429674 -0.461294 -0.160378 -0.024718   \n",
       "3          0.463783     2.574235  8.602364  0.995542  1.699426  0.026409   \n",
       "4         -0.354122    -0.308827 -0.429674 -0.461294 -0.160378 -0.024718   \n",
       "...             ...          ...       ...       ...       ...       ...   \n",
       "61546     -0.331210    -0.218100  2.150908  0.995542 -0.160378  0.089222   \n",
       "61547     -0.354181    -0.308827 -0.429674 -0.461294 -0.160378 -0.024718   \n",
       "61548     -0.287468    -0.308827 -0.429674 -0.461294 -0.160378 -0.024718   \n",
       "61549     -0.318527    -0.308827 -0.429674 -0.461294 -0.160378 -0.024718   \n",
       "61550     -0.291548    -0.308827 -0.429674 -0.461294 -0.160378 -0.024718   \n",
       "\n",
       "       flow_urg  flow_cwr  flow_ece  downUpRatio  \n",
       "0           0.0 -0.004937       0.0    -0.489167  \n",
       "1           0.0 -0.004937       0.0    -0.074889  \n",
       "2           0.0 -0.004937       0.0    -0.255945  \n",
       "3           0.0 -0.004937       0.0     3.037853  \n",
       "4           0.0 -0.004937       0.0     0.248850  \n",
       "...         ...       ...       ...          ...  \n",
       "61546       0.0 -0.004937       0.0     3.928886  \n",
       "61547       0.0 -0.004937       0.0    -0.288466  \n",
       "61548       0.0 -0.004937       0.0    -0.397161  \n",
       "61549       0.0 -0.004937       0.0    -0.120001  \n",
       "61550       0.0 -0.004937       0.0    -0.397161  \n",
       "\n",
       "[61551 rows x 48 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_test_stand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection\n",
    "`VarianceThreshold` is a simple baseline approach to feature selection. It removes all features whose variance doesn’t meet some threshold. Defining and Fiting Threshold\n",
    "For quasi-constant features, that have the same value for a very large subset, i.e. using threshold as 0.01 would mean dropping the column where 99% of the values are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True, False,  True])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the VarianceThreshold class from sklearn support a type of feature selection\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "var_thr = VarianceThreshold(threshold = 0.25) #.25 would mean dropping the column where 75% of the values are similar.\n",
    "# fit on the trainning dataset\n",
    "var_thr.fit(df_X_train_stand)\n",
    "# Get a mask of the selected features \n",
    "var_thr.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "furg_cnt\n",
      "burg_cnt\n",
      "flow_urg\n",
      "flow_ece\n"
     ]
    }
   ],
   "source": [
    "#Show features that do not meet the threshold\n",
    "concol = [column for column in df_X_train_stand.columns \n",
    "          if column not in df_X_train_stand.columns[var_thr.get_support()]]\n",
    "\n",
    "for features in concol:\n",
    "    print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping Low Variance Columns:\n",
    "df_X_train_stand.drop(concol,axis=1,inplace=True)\n",
    "df_X_test_stand.drop(concol,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['proto', 'srcPrt', 'dstPrt', 'flowduration', 'total_fpackets',\n",
       "       'total_bpackets', 'total_fpktl', 'total_bpktl', 'min_fpktl',\n",
       "       'min_bpktl', 'max_fpktl', 'max_bpktl', 'mean_fpktl', 'mean_bpktl',\n",
       "       'std_fpktl', 'std_bpktl', 'total_fipt', 'total_bipt', 'min_fipt',\n",
       "       'min_bipt', 'max_fipt', 'max_bipt', 'mean_fipt', 'mean_bipt',\n",
       "       'std_fipt', 'std_bipt', 'fpsh_cnt', 'bpsh_cnt', 'total_fhlen',\n",
       "       'total_bhlen', 'fPktsPerSecond', 'bPktsPerSecond', 'flowPktsPerSecond',\n",
       "       'flowBytesPerSecond', 'mean_flowpktl', 'std_flowpktl', 'mean_flowipt',\n",
       "       'std_flowipt', 'flow_fin', 'flow_syn', 'flow_rst', 'flow_ack',\n",
       "       'flow_cwr', 'downUpRatio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show selected features\n",
    "df_X_train_stand.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((246203, 44), (61551, 44))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##final dataset dimensions\n",
    "df_X_train_stand.shape,df_X_test_stand.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Weighted Logistic Regression (W-LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run grid search only on training set using cross-validation\n",
    "parameters={'C':np.logspace(-3,3,7), 'penalty':[\"l1\",\"l2\"]}# l1 lasso l2 ridge\n",
    "model1=GridSearchCV(LogisticRegression(class_weight='balanced', solver='saga' ,max_iter=1000),parameters,cv=5, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "[CV 1/5] END ...............C=0.001, penalty=l1;, score=0.987 total time= 1.3min\n",
      "[CV 2/5] END ...............C=0.001, penalty=l1;, score=0.987 total time= 1.4min\n",
      "[CV 3/5] END ...............C=0.001, penalty=l1;, score=0.985 total time= 1.3min\n",
      "[CV 4/5] END ...............C=0.001, penalty=l1;, score=0.987 total time= 1.2min\n",
      "[CV 5/5] END ...............C=0.001, penalty=l1;, score=0.987 total time= 1.4min\n",
      "[CV 1/5] END ...............C=0.001, penalty=l2;, score=0.986 total time= 1.2min\n",
      "[CV 2/5] END ...............C=0.001, penalty=l2;, score=0.987 total time= 1.2min\n",
      "[CV 3/5] END ...............C=0.001, penalty=l2;, score=0.987 total time= 1.2min\n",
      "[CV 4/5] END ...............C=0.001, penalty=l2;, score=0.988 total time= 1.0min\n",
      "[CV 5/5] END ...............C=0.001, penalty=l2;, score=0.987 total time= 1.1min\n",
      "[CV 1/5] END ................C=0.01, penalty=l1;, score=0.987 total time= 2.0min\n",
      "[CV 2/5] END ................C=0.01, penalty=l1;, score=0.987 total time= 2.0min\n",
      "[CV 3/5] END ................C=0.01, penalty=l1;, score=0.987 total time= 2.0min\n",
      "[CV 4/5] END ................C=0.01, penalty=l1;, score=0.988 total time= 2.0min\n",
      "[CV 5/5] END ................C=0.01, penalty=l1;, score=0.988 total time= 2.2min\n",
      "[CV 1/5] END ................C=0.01, penalty=l2;, score=0.988 total time= 2.0min\n",
      "[CV 2/5] END ................C=0.01, penalty=l2;, score=0.988 total time= 2.1min\n",
      "[CV 3/5] END ................C=0.01, penalty=l2;, score=0.988 total time= 2.0min\n",
      "[CV 4/5] END ................C=0.01, penalty=l2;, score=0.989 total time= 2.0min\n",
      "[CV 5/5] END ................C=0.01, penalty=l2;, score=0.988 total time= 2.0min\n",
      "[CV 1/5] END .................C=0.1, penalty=l1;, score=0.988 total time= 2.3min\n",
      "[CV 2/5] END .................C=0.1, penalty=l1;, score=0.988 total time= 2.3min\n",
      "[CV 3/5] END .................C=0.1, penalty=l1;, score=0.988 total time= 2.3min\n",
      "[CV 4/5] END .................C=0.1, penalty=l1;, score=0.989 total time= 2.3min\n",
      "[CV 5/5] END .................C=0.1, penalty=l1;, score=0.989 total time= 2.3min\n",
      "[CV 1/5] END .................C=0.1, penalty=l2;, score=0.988 total time= 2.0min\n",
      "[CV 2/5] END .................C=0.1, penalty=l2;, score=0.988 total time= 2.0min\n",
      "[CV 3/5] END .................C=0.1, penalty=l2;, score=0.988 total time= 2.1min\n",
      "[CV 4/5] END .................C=0.1, penalty=l2;, score=0.989 total time= 2.0min\n",
      "[CV 5/5] END .................C=0.1, penalty=l2;, score=0.989 total time= 2.0min\n",
      "[CV 1/5] END .................C=1.0, penalty=l1;, score=0.988 total time= 2.3min\n",
      "[CV 2/5] END .................C=1.0, penalty=l1;, score=0.988 total time= 2.4min\n",
      "[CV 3/5] END .................C=1.0, penalty=l1;, score=0.988 total time= 2.4min\n",
      "[CV 4/5] END .................C=1.0, penalty=l1;, score=0.989 total time= 2.3min\n",
      "[CV 5/5] END .................C=1.0, penalty=l1;, score=0.989 total time= 2.3min\n",
      "[CV 1/5] END .................C=1.0, penalty=l2;, score=0.988 total time= 2.1min\n",
      "[CV 2/5] END .................C=1.0, penalty=l2;, score=0.988 total time= 2.1min\n",
      "[CV 3/5] END .................C=1.0, penalty=l2;, score=0.988 total time= 2.2min\n",
      "[CV 4/5] END .................C=1.0, penalty=l2;, score=0.989 total time= 2.4min\n",
      "[CV 5/5] END .................C=1.0, penalty=l2;, score=0.989 total time= 2.4min\n",
      "[CV 1/5] END ................C=10.0, penalty=l1;, score=0.988 total time= 2.7min\n",
      "[CV 2/5] END ................C=10.0, penalty=l1;, score=0.988 total time= 2.7min\n",
      "[CV 3/5] END ................C=10.0, penalty=l1;, score=0.988 total time= 2.6min\n",
      "[CV 4/5] END ................C=10.0, penalty=l1;, score=0.989 total time= 2.6min\n",
      "[CV 5/5] END ................C=10.0, penalty=l1;, score=0.989 total time= 2.7min\n",
      "[CV 1/5] END ................C=10.0, penalty=l2;, score=0.988 total time= 2.3min\n",
      "[CV 2/5] END ................C=10.0, penalty=l2;, score=0.988 total time= 2.3min\n",
      "[CV 3/5] END ................C=10.0, penalty=l2;, score=0.988 total time= 2.2min\n",
      "[CV 4/5] END ................C=10.0, penalty=l2;, score=0.989 total time= 2.3min\n",
      "[CV 5/5] END ................C=10.0, penalty=l2;, score=0.989 total time= 2.3min\n",
      "[CV 1/5] END ...............C=100.0, penalty=l1;, score=0.988 total time= 2.6min\n",
      "[CV 2/5] END ...............C=100.0, penalty=l1;, score=0.988 total time= 2.6min\n",
      "[CV 3/5] END ...............C=100.0, penalty=l1;, score=0.988 total time= 2.6min\n",
      "[CV 4/5] END ...............C=100.0, penalty=l1;, score=0.989 total time= 2.6min\n",
      "[CV 5/5] END ...............C=100.0, penalty=l1;, score=0.989 total time= 2.6min\n",
      "[CV 1/5] END ...............C=100.0, penalty=l2;, score=0.988 total time= 2.2min\n",
      "[CV 2/5] END ...............C=100.0, penalty=l2;, score=0.988 total time= 2.2min\n",
      "[CV 3/5] END ...............C=100.0, penalty=l2;, score=0.988 total time= 2.2min\n",
      "[CV 4/5] END ...............C=100.0, penalty=l2;, score=0.989 total time= 2.2min\n",
      "[CV 5/5] END ...............C=100.0, penalty=l2;, score=0.989 total time= 2.1min\n",
      "[CV 1/5] END ..............C=1000.0, penalty=l1;, score=0.988 total time= 2.5min\n",
      "[CV 2/5] END ..............C=1000.0, penalty=l1;, score=0.988 total time= 2.4min\n",
      "[CV 3/5] END ..............C=1000.0, penalty=l1;, score=0.988 total time= 2.4min\n",
      "[CV 4/5] END ..............C=1000.0, penalty=l1;, score=0.989 total time= 2.4min\n",
      "[CV 5/5] END ..............C=1000.0, penalty=l1;, score=0.989 total time= 2.4min\n",
      "[CV 1/5] END ..............C=1000.0, penalty=l2;, score=0.988 total time= 2.1min\n",
      "[CV 2/5] END ..............C=1000.0, penalty=l2;, score=0.988 total time= 2.1min\n",
      "[CV 3/5] END ..............C=1000.0, penalty=l2;, score=0.988 total time= 2.1min\n",
      "[CV 4/5] END ..............C=1000.0, penalty=l2;, score=0.989 total time= 2.1min\n",
      "[CV 5/5] END ..............C=1000.0, penalty=l2;, score=0.989 total time= 2.1min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=LogisticRegression(class_weight='balanced',\n",
       "                                          max_iter=1000, solver='saga'),\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit on the trainning dataset\n",
    "model1.fit(df_X_train_stand,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'C': 10.0, 'penalty': 'l1'}\n",
      "accuracy : 0.9882942157812622\n"
     ]
    }
   ],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",model1.best_params_)\n",
    "print(\"accuracy :\",model1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = model1.predict(df_X_test_stand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      0.98      0.99     57885\n",
      "     class 1       0.77      0.98      0.87      3666\n",
      "\n",
      "    accuracy                           0.98     61551\n",
      "   macro avg       0.89      0.98      0.93     61551\n",
      "weighted avg       0.99      0.98      0.98     61551\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#performance results\n",
    "print(classification_report(y_test, y_pred1, target_names=target_names))\n",
    "plot_confusion_matrix(model1, df_X_test_stand, y_test, display_labels=target_names,cmap=plt.cm.Blues);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Over-sampling with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origianl dataset shape: Counter({0: 231605, 1: 14598})\n",
      "Resample dataset shape: Counter({0: 231605, 1: 231605})\n"
     ]
    }
   ],
   "source": [
    "# load library\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE()\n",
    "\n",
    "# fit on the trainning dataset\n",
    "X_smote , y_smote = smote.fit_resample(df_X_train_stand, y_train)\n",
    "\n",
    "print('Origianl dataset shape:', Counter(y_train))\n",
    "print('Resample dataset shape:', Counter(y_smote))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### b) Logistic Regression with Synthetic minority over-sampling technique (LR+SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "[CV 1/5] END ...............C=0.001, penalty=l1;, score=0.989 total time= 2.6min\n",
      "[CV 2/5] END ...............C=0.001, penalty=l1;, score=0.989 total time= 2.6min\n",
      "[CV 3/5] END ...............C=0.001, penalty=l1;, score=0.989 total time= 2.6min\n",
      "[CV 4/5] END ...............C=0.001, penalty=l1;, score=0.990 total time= 2.2min\n",
      "[CV 5/5] END ...............C=0.001, penalty=l1;, score=0.990 total time= 2.6min\n",
      "[CV 1/5] END ...............C=0.001, penalty=l2;, score=0.990 total time= 2.3min\n",
      "[CV 2/5] END ...............C=0.001, penalty=l2;, score=0.990 total time= 2.3min\n",
      "[CV 3/5] END ...............C=0.001, penalty=l2;, score=0.989 total time= 2.4min\n",
      "[CV 4/5] END ...............C=0.001, penalty=l2;, score=0.990 total time= 2.0min\n",
      "[CV 5/5] END ...............C=0.001, penalty=l2;, score=0.990 total time= 2.3min\n",
      "[CV 1/5] END ................C=0.01, penalty=l1;, score=0.990 total time= 4.7min\n",
      "[CV 2/5] END ................C=0.01, penalty=l1;, score=0.991 total time= 4.7min\n",
      "[CV 3/5] END ................C=0.01, penalty=l1;, score=0.990 total time= 4.7min\n",
      "[CV 4/5] END ................C=0.01, penalty=l1;, score=0.991 total time= 4.8min\n",
      "[CV 5/5] END ................C=0.01, penalty=l1;, score=0.991 total time= 4.8min\n",
      "[CV 1/5] END ................C=0.01, penalty=l2;, score=0.991 total time= 4.3min\n",
      "[CV 2/5] END ................C=0.01, penalty=l2;, score=0.991 total time= 4.3min\n",
      "[CV 3/5] END ................C=0.01, penalty=l2;, score=0.991 total time= 4.4min\n",
      "[CV 4/5] END ................C=0.01, penalty=l2;, score=0.991 total time= 4.5min\n",
      "[CV 5/5] END ................C=0.01, penalty=l2;, score=0.991 total time= 4.2min\n",
      "[CV 1/5] END .................C=0.1, penalty=l1;, score=0.991 total time= 4.9min\n",
      "[CV 2/5] END .................C=0.1, penalty=l1;, score=0.991 total time= 4.9min\n",
      "[CV 3/5] END .................C=0.1, penalty=l1;, score=0.991 total time= 4.8min\n",
      "[CV 4/5] END .................C=0.1, penalty=l1;, score=0.991 total time= 4.8min\n",
      "[CV 5/5] END .................C=0.1, penalty=l1;, score=0.991 total time= 4.8min\n",
      "[CV 1/5] END .................C=0.1, penalty=l2;, score=0.991 total time= 4.2min\n",
      "[CV 2/5] END .................C=0.1, penalty=l2;, score=0.991 total time= 4.2min\n",
      "[CV 3/5] END .................C=0.1, penalty=l2;, score=0.991 total time= 4.3min\n",
      "[CV 4/5] END .................C=0.1, penalty=l2;, score=0.991 total time= 4.3min\n",
      "[CV 5/5] END .................C=0.1, penalty=l2;, score=0.992 total time= 4.3min\n",
      "[CV 1/5] END .................C=1.0, penalty=l1;, score=0.991 total time= 4.8min\n",
      "[CV 2/5] END .................C=1.0, penalty=l1;, score=0.991 total time= 4.8min\n",
      "[CV 3/5] END .................C=1.0, penalty=l1;, score=0.991 total time= 4.8min\n",
      "[CV 4/5] END .................C=1.0, penalty=l1;, score=0.992 total time= 4.8min\n",
      "[CV 5/5] END .................C=1.0, penalty=l1;, score=0.992 total time= 4.8min\n",
      "[CV 1/5] END .................C=1.0, penalty=l2;, score=0.991 total time= 4.2min\n",
      "[CV 2/5] END .................C=1.0, penalty=l2;, score=0.991 total time= 4.2min\n",
      "[CV 3/5] END .................C=1.0, penalty=l2;, score=0.991 total time= 4.3min\n",
      "[CV 4/5] END .................C=1.0, penalty=l2;, score=0.992 total time= 4.3min\n",
      "[CV 5/5] END .................C=1.0, penalty=l2;, score=0.992 total time= 4.2min\n",
      "[CV 1/5] END ................C=10.0, penalty=l1;, score=0.991 total time= 4.8min\n",
      "[CV 2/5] END ................C=10.0, penalty=l1;, score=0.991 total time= 4.8min\n",
      "[CV 3/5] END ................C=10.0, penalty=l1;, score=0.991 total time= 4.8min\n",
      "[CV 4/5] END ................C=10.0, penalty=l1;, score=0.992 total time= 4.8min\n",
      "[CV 5/5] END ................C=10.0, penalty=l1;, score=0.992 total time= 4.7min\n",
      "[CV 1/5] END ................C=10.0, penalty=l2;, score=0.991 total time= 3.9min\n",
      "[CV 2/5] END ................C=10.0, penalty=l2;, score=0.991 total time= 3.8min\n",
      "[CV 3/5] END ................C=10.0, penalty=l2;, score=0.991 total time= 3.8min\n",
      "[CV 4/5] END ................C=10.0, penalty=l2;, score=0.992 total time= 3.8min\n",
      "[CV 5/5] END ................C=10.0, penalty=l2;, score=0.992 total time= 3.8min\n",
      "[CV 1/5] END ...............C=100.0, penalty=l1;, score=0.991 total time= 4.4min\n",
      "[CV 2/5] END ...............C=100.0, penalty=l1;, score=0.991 total time= 4.4min\n",
      "[CV 3/5] END ...............C=100.0, penalty=l1;, score=0.991 total time= 4.4min\n",
      "[CV 4/5] END ...............C=100.0, penalty=l1;, score=0.992 total time= 4.4min\n",
      "[CV 5/5] END ...............C=100.0, penalty=l1;, score=0.992 total time= 4.5min\n",
      "[CV 1/5] END ...............C=100.0, penalty=l2;, score=0.991 total time= 4.2min\n",
      "[CV 2/5] END ...............C=100.0, penalty=l2;, score=0.991 total time= 4.1min\n",
      "[CV 3/5] END ...............C=100.0, penalty=l2;, score=0.991 total time= 4.1min\n",
      "[CV 4/5] END ...............C=100.0, penalty=l2;, score=0.992 total time= 4.1min\n",
      "[CV 5/5] END ...............C=100.0, penalty=l2;, score=0.992 total time= 4.1min\n",
      "[CV 1/5] END ..............C=1000.0, penalty=l1;, score=0.991 total time= 4.6min\n",
      "[CV 2/5] END ..............C=1000.0, penalty=l1;, score=0.991 total time= 4.4min\n",
      "[CV 3/5] END ..............C=1000.0, penalty=l1;, score=0.991 total time= 4.4min\n",
      "[CV 4/5] END ..............C=1000.0, penalty=l1;, score=0.992 total time= 4.4min\n",
      "[CV 5/5] END ..............C=1000.0, penalty=l1;, score=0.992 total time= 4.4min\n",
      "[CV 1/5] END ..............C=1000.0, penalty=l2;, score=0.991 total time= 3.9min\n",
      "[CV 2/5] END ..............C=1000.0, penalty=l2;, score=0.991 total time= 3.9min\n",
      "[CV 3/5] END ..............C=1000.0, penalty=l2;, score=0.991 total time= 3.9min\n",
      "[CV 4/5] END ..............C=1000.0, penalty=l2;, score=0.992 total time= 3.9min\n",
      "[CV 5/5] END ..............C=1000.0, penalty=l2;, score=0.992 total time= 3.9min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=1000, solver='saga'),\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run grid search only on training set using cross-validation\n",
    "parameters={'C':np.logspace(-3,3,7), 'penalty':[\"l1\",\"l2\"]}# l1 lasso l2 ridge\n",
    "model2=GridSearchCV(LogisticRegression(solver='saga' ,max_iter=1000),parameters,cv=5, verbose=3)\n",
    "model2.fit(X_smote,y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'C': 10.0, 'penalty': 'l1'}\n",
      "accuracy : 0.9912134884825458\n",
      "Best Model: LogisticRegression(C=10.0, max_iter=1000, penalty='l1', solver='saga')\n"
     ]
    }
   ],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",model2.best_params_)\n",
    "print(\"accuracy :\",model2.best_score_)\n",
    "print('Best Model:',model2.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2=model2.predict(df_X_test_stand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      0.98      0.99     57885\n",
      "     class 1       0.79      0.98      0.88      3666\n",
      "\n",
      "    accuracy                           0.98     61551\n",
      "   macro avg       0.89      0.98      0.93     61551\n",
      "weighted avg       0.99      0.98      0.98     61551\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#performance results\n",
    "print(classification_report(y_test, y_pred2, target_names=target_names))\n",
    "plot_confusion_matrix(model2, df_X_test_stand, y_test, display_labels=target_names,cmap=plt.cm.Blues); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Weighted Decision Tree (W-DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 1/5] END .......criterion=gini, max_depth=2;, score=0.966 total time=   0.7s\n",
      "[CV 2/5] END .......criterion=gini, max_depth=2;, score=0.965 total time=   0.6s\n",
      "[CV 3/5] END .......criterion=gini, max_depth=2;, score=0.966 total time=   0.7s\n",
      "[CV 4/5] END .......criterion=gini, max_depth=2;, score=0.964 total time=   0.6s\n",
      "[CV 5/5] END .......criterion=gini, max_depth=2;, score=0.964 total time=   0.6s\n",
      "[CV 1/5] END .......criterion=gini, max_depth=4;, score=0.983 total time=   1.3s\n",
      "[CV 2/5] END .......criterion=gini, max_depth=4;, score=0.983 total time=   1.3s\n",
      "[CV 3/5] END .......criterion=gini, max_depth=4;, score=0.983 total time=   1.3s\n",
      "[CV 4/5] END .......criterion=gini, max_depth=4;, score=0.982 total time=   1.3s\n",
      "[CV 5/5] END .......criterion=gini, max_depth=4;, score=0.982 total time=   1.3s\n",
      "[CV 1/5] END .......criterion=gini, max_depth=6;, score=0.986 total time=   1.6s\n",
      "[CV 2/5] END .......criterion=gini, max_depth=6;, score=0.986 total time=   1.9s\n",
      "[CV 3/5] END .......criterion=gini, max_depth=6;, score=0.986 total time=   1.9s\n",
      "[CV 4/5] END .......criterion=gini, max_depth=6;, score=0.986 total time=   1.7s\n",
      "[CV 5/5] END .......criterion=gini, max_depth=6;, score=0.986 total time=   1.9s\n",
      "[CV 1/5] END .......criterion=gini, max_depth=8;, score=0.998 total time=   1.7s\n",
      "[CV 2/5] END .......criterion=gini, max_depth=8;, score=0.998 total time=   2.0s\n",
      "[CV 3/5] END .......criterion=gini, max_depth=8;, score=0.998 total time=   2.3s\n",
      "[CV 4/5] END .......criterion=gini, max_depth=8;, score=0.998 total time=   1.7s\n",
      "[CV 5/5] END .......criterion=gini, max_depth=8;, score=0.998 total time=   2.0s\n",
      "[CV 1/5] END ......criterion=gini, max_depth=10;, score=0.999 total time=   1.7s\n",
      "[CV 2/5] END ......criterion=gini, max_depth=10;, score=0.998 total time=   2.0s\n",
      "[CV 3/5] END ......criterion=gini, max_depth=10;, score=0.999 total time=   2.3s\n",
      "[CV 4/5] END ......criterion=gini, max_depth=10;, score=0.999 total time=   1.8s\n",
      "[CV 5/5] END ......criterion=gini, max_depth=10;, score=0.999 total time=   2.3s\n",
      "[CV 1/5] END ......criterion=gini, max_depth=12;, score=0.999 total time=   1.8s\n",
      "[CV 2/5] END ......criterion=gini, max_depth=12;, score=0.999 total time=   2.1s\n",
      "[CV 3/5] END ......criterion=gini, max_depth=12;, score=0.999 total time=   2.4s\n",
      "[CV 4/5] END ......criterion=gini, max_depth=12;, score=0.999 total time=   2.1s\n",
      "[CV 5/5] END ......criterion=gini, max_depth=12;, score=1.000 total time=   2.1s\n",
      "[CV 1/5] END ....criterion=entropy, max_depth=2;, score=0.945 total time=   0.8s\n",
      "[CV 2/5] END ....criterion=entropy, max_depth=2;, score=0.945 total time=   0.8s\n",
      "[CV 3/5] END ....criterion=entropy, max_depth=2;, score=0.946 total time=   0.8s\n",
      "[CV 4/5] END ....criterion=entropy, max_depth=2;, score=0.944 total time=   0.8s\n",
      "[CV 5/5] END ....criterion=entropy, max_depth=2;, score=0.945 total time=   0.7s\n",
      "[CV 1/5] END ....criterion=entropy, max_depth=4;, score=0.998 total time=   1.2s\n",
      "[CV 2/5] END ....criterion=entropy, max_depth=4;, score=0.998 total time=   1.2s\n",
      "[CV 3/5] END ....criterion=entropy, max_depth=4;, score=0.998 total time=   1.2s\n",
      "[CV 4/5] END ....criterion=entropy, max_depth=4;, score=0.998 total time=   1.5s\n",
      "[CV 5/5] END ....criterion=entropy, max_depth=4;, score=0.998 total time=   1.3s\n",
      "[CV 1/5] END ....criterion=entropy, max_depth=6;, score=0.999 total time=   1.3s\n",
      "[CV 2/5] END ....criterion=entropy, max_depth=6;, score=0.999 total time=   1.3s\n",
      "[CV 3/5] END ....criterion=entropy, max_depth=6;, score=0.999 total time=   1.3s\n",
      "[CV 4/5] END ....criterion=entropy, max_depth=6;, score=0.999 total time=   1.9s\n",
      "[CV 5/5] END ....criterion=entropy, max_depth=6;, score=0.999 total time=   1.3s\n",
      "[CV 1/5] END ....criterion=entropy, max_depth=8;, score=0.999 total time=   1.3s\n",
      "[CV 2/5] END ....criterion=entropy, max_depth=8;, score=1.000 total time=   1.3s\n",
      "[CV 3/5] END ....criterion=entropy, max_depth=8;, score=0.999 total time=   1.3s\n",
      "[CV 4/5] END ....criterion=entropy, max_depth=8;, score=0.999 total time=   1.9s\n",
      "[CV 5/5] END ....criterion=entropy, max_depth=8;, score=0.999 total time=   1.3s\n",
      "[CV 1/5] END ...criterion=entropy, max_depth=10;, score=1.000 total time=   1.3s\n",
      "[CV 2/5] END ...criterion=entropy, max_depth=10;, score=1.000 total time=   1.3s\n",
      "[CV 3/5] END ...criterion=entropy, max_depth=10;, score=1.000 total time=   1.3s\n",
      "[CV 4/5] END ...criterion=entropy, max_depth=10;, score=1.000 total time=   1.9s\n",
      "[CV 5/5] END ...criterion=entropy, max_depth=10;, score=1.000 total time=   1.3s\n",
      "[CV 1/5] END ...criterion=entropy, max_depth=12;, score=1.000 total time=   1.3s\n",
      "[CV 2/5] END ...criterion=entropy, max_depth=12;, score=1.000 total time=   1.3s\n",
      "[CV 3/5] END ...criterion=entropy, max_depth=12;, score=1.000 total time=   1.3s\n",
      "[CV 4/5] END ...criterion=entropy, max_depth=12;, score=1.000 total time=   2.2s\n",
      "[CV 5/5] END ...criterion=entropy, max_depth=12;, score=1.000 total time=   1.3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(class_weight='balanced'),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [2, 4, 6, 8, 10, 12]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run grid search only on training set using cross-validation\n",
    "parameters = {'criterion':['gini','entropy'], 'max_depth' : [2,4,6,8,10,12]}\n",
    "model3 = GridSearchCV(DecisionTreeClassifier(class_weight='balanced'), parameters, cv=5, verbose=3)\n",
    "# fit on the trainning dataset\n",
    "model3.fit(df_X_train_stand, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'criterion': 'entropy', 'max_depth': 12}\n",
      "accuracy : 0.9998253475573998\n",
      "Best Model: DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=12)\n"
     ]
    }
   ],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",model3.best_params_)\n",
    "print(\"accuracy :\",model3.best_score_)\n",
    "print('Best Model:',model3.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = model3.predict(df_X_test_stand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      1.00      1.00     57885\n",
      "     class 1       1.00      1.00      1.00      3666\n",
      "\n",
      "    accuracy                           1.00     61551\n",
      "   macro avg       1.00      1.00      1.00     61551\n",
      "weighted avg       1.00      1.00      1.00     61551\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#performance results\n",
    "print(classification_report(y_test, y_pred3, target_names=target_names))\n",
    "plot_confusion_matrix(model3, df_X_test_stand, y_test, display_labels=target_names,cmap=plt.cm.Blues);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling using OSS\n",
    "OneSidedSelection (OSS) is an undersampling technique that combines Tomek Links and the Condensed Nearest Neighbor (CNN) Rule. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "from imblearn.under_sampling import OneSidedSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 229131, 1: 14598})\n"
     ]
    }
   ],
   "source": [
    "# define the undersampling method\n",
    "oss = OneSidedSelection(random_state=0)\n",
    "# fit on the trainning dataset\n",
    "X_oss, y_oss = oss.fit_resample(df_X_train_stand, y_train)\n",
    "# summarize the new class distribution\n",
    "counter = Counter(y_oss)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Weighted Support Vector Machine with One Sided Selection (SVM+OSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5] END ...............................C=1;, score=0.999 total time= 1.2min\n",
      "[CV 2/5] END ...............................C=1;, score=0.999 total time= 1.5min\n",
      "[CV 3/5] END ...............................C=1;, score=0.999 total time= 1.2min\n",
      "[CV 4/5] END ...............................C=1;, score=0.999 total time= 1.2min\n",
      "[CV 5/5] END ...............................C=1;, score=0.999 total time= 1.0min\n",
      "[CV 1/5] END ...............................C=5;, score=1.000 total time=  35.2s\n",
      "[CV 2/5] END ...............................C=5;, score=0.999 total time=  34.1s\n",
      "[CV 3/5] END ...............................C=5;, score=1.000 total time=  35.2s\n",
      "[CV 4/5] END ...............................C=5;, score=0.999 total time=  35.5s\n",
      "[CV 5/5] END ...............................C=5;, score=0.999 total time=  35.9s\n",
      "[CV 1/5] END ..............................C=10;, score=1.000 total time=  33.5s\n",
      "[CV 2/5] END ..............................C=10;, score=1.000 total time=  33.0s\n",
      "[CV 3/5] END ..............................C=10;, score=1.000 total time=  33.1s\n",
      "[CV 4/5] END ..............................C=10;, score=0.999 total time=  36.3s\n",
      "[CV 5/5] END ..............................C=10;, score=1.000 total time=  33.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(class_weight='balanced'),\n",
       "             param_grid={'C': [1, 5, 10]}, verbose=3)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run grid search only on training set using cross-validation\n",
    "parameters = {'C':[1, 5, 10] }\n",
    "model4 = GridSearchCV(SVC(class_weight='balanced', kernel='rbf'), parameters, cv=5, verbose=3)\n",
    "model4.fit(X_oss, y_oss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'C': 10}\n",
      "accuracy : 0.9995527820505747\n",
      "Best Model: SVC(C=10, class_weight='balanced')\n"
     ]
    }
   ],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",model4.best_params_)\n",
    "print(\"accuracy :\",model4.best_score_)\n",
    "print('Best Model:',model4.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred4 = model4.predict(df_X_test_stand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      1.00      1.00     57885\n",
      "     class 1       1.00      1.00      1.00      3666\n",
      "\n",
      "    accuracy                           1.00     61551\n",
      "   macro avg       1.00      1.00      1.00     61551\n",
      "weighted avg       1.00      1.00      1.00     61551\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAEGCAYAAAC0DiQ1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAh1UlEQVR4nO3deZhVxZ3/8fenm4AgIJs6BnAniUKiCKMkTIxLomQZNXEZ1Iw4YSQaTcYkPx2NjlEzJJqZ0Qk6mokrEh01LhGTKDqocSMgKAhuA9EoCIogIigu3Xx/f5xqvLS9XKRvn9O3Py+f8/S5darq1qEfvxR16lQpIjAzs3zU5N0AM7POzEHYzCxHDsJmZjlyEDYzy5GDsJlZjrrk3YA8qUv3UNdeeTfDNsHw3bbPuwm2CV588S+sWLFCm1NHbe8dIurWlZU31r02LSLGbM73tbfOHYS79qLbJ4/Kuxm2CR6ZeWneTbBNMHqfkZtdR9StK/v/03fm/teAzf7Cdtapg7CZdQQCVe/IqYOwmRWbgJravFtRMQ7CZlZ82qxh5UJzEDazgvNwhJlZvtwTNjPLiXBP2MwsP3JP2MwsV54dYWaWFz+YMzPLj/BwhJlZrtwTNjPLi4cjzMzyI6DWD+bMzPLjMWEzs7x4OMLMLF/uCZuZ5cg9YTOznMivLZuZ5cuvLZuZ5cUP5szM8uXhCDOznHg9YTOzPHk4wswsX34wZ2aWoyoeE67ePr6ZVQel4YhyjrKq018kzZc0V9LslNZP0r2SFqaffUvynylpkaTnJB1ckj4i1bNI0iQp+5tCUjdJN6X0mZJ2bKk9DsJmVnwNL2y0dpRv/4jYMyJGps9nANMjYggwPX1G0u7AWGAoMAa4TFLD2MjlwARgSDrGpPTxwKqI2BW4GLiwpYY4CJtZ4Ukq69gMhwKT0/lk4LCS9Bsj4t2IeAFYBOwtaTugd0TMiIgArmtUpqGuW4AD1ULjHITNrNCy3Y3KDsIDJM0uOSY0UWUA90iaU3J924hYBpB+bpPSBwKLS8ouSWkD03nj9I3KREQdsBro39z9+cGcmRWbhGrK7uWuKBliaM7oiFgqaRvgXknPtvTtTaRFC+ktlWmSe8JmVnhtORwREUvTz+XA7cDewKtpiIH0c3nKvgQYXFJ8ELA0pQ9qIn2jMpK6AFsBrzfXHgdhMyu8tgrCkraU1KvhHDgIWABMBcalbOOAO9L5VGBsmvGwE9kDuFlpyGKNpFFpvPe4RmUa6joCuC+NGzfJwxFmVnib+dCt1LbA7am+LsANEXG3pMeAmyWNB14CjgSIiKck3Qw8DdQBJ0dEfarrJOBaoDtwVzoArgKmSFpE1gMe21KDHITNrNhE06OsH0FEPA/s0UT6SuDAZspMBCY2kT4bGNZE+jukIF4OB2EzKzSx2dPPCs1B2MwKr6ameh9fOQibWeG5J2xmlpc2HBMuIgdhMys894TNzHLiB3NmZjnbhNeWOxwHYTMrNnk4wswsVw7CZmY5chA2M8uJH8yZmeWtemOwg7CZFZz82rKZWa48HGFmlqfqjcEOwkU2747zWPv2u9SvX09d3XoOGPdzrvrpPzBkh20B2Kpnd1avXce+x15Al9oaJp19LHt8ajC1tTXc9IdZXHztPfTs0Y0/XPH9DXV+fJs+3HzXY/zoolv53PBd+OkPjmDorh9n/FnXMPW+uTndaedyyvm/ZtrDCxjQtxczbjpro2uXTPlfzpn0WxbdewH9+/TMqYXF455wG5F0LrA2Iv69AnWP4INV7v8A/FNLW4p0FH974i94ffVbGz6P/9E1G85/curXeXPtOgAO++JedOvahdFH/5Tu3T7Gn24+m1umzWbxstfZ99gLNpS5/7rT+d39cwFY/MoqTj5vCqd8s8m1rK1Cjv7aKE446guc+OPrNkpf8soqHpj1LIP+qm9OLSumNtjOvtCqabT7cmAC2R5QQ4Ax+Tan8r7+xb24ddocACKCHt27UltbwxZbdOW99+tZ89Y7G+XfefDWbN2vF48+8WcAFi97nacWLWV9x/+7qkMZvdeu9O3d40PpZ118K+d+97CqDjgfVVtu9Fk0FQvCko6T9KSkeZKmNHH9BEmPpeu3SuqR0o+UtCClP5jShkqaJWluqnNIo7q2A3pHxIzU+70OOKxS99ZeIoLbLj2F+687nXFfH73Rtc8N34XlK9fw/OLXALhj+hO8ve49nr1rIvPvPJ9Lr5/OG2++vVGZww8ewW33Pt5u7bfy/eGPT7Ld1n349CcGtZ65E1KNyjo6oooMR0gaCpwFjI6IFZL6NZHttoi4IuX/V2A8cAlwDnBwRLwsqU/KeyLwi4i4XlJXoLZRXQPJtplusCSlNdW2CWQ9ZvhYscfcxvzjxbyyYjUD+vbk9ktPYeFfXtnQiz38oJHces/sDXlHDN2R+vXr2e3LZ9Gndw/+cMX3eWDWs7z48soNeb7xpREf+iew5e/td97jomumceulp+TdlMLqqL3cclSqJ3wAcEtErACIiNebyDNM0kOS5gPHAkNT+iPAtZJO4INgOwP4kaR/BnaIiHWN6mrqN9Tkv7Ej4lcRMTIiRqpL9027q3b2yorVAKxYtZbfPfAkew3dEYDa2hq+tv8e3F7Sqz1izEimP/o0dfXrWbFqLTPnPc/w3bbfcH3YkIF0qa1l3rOL2/UerHUvLHmNF5eu5PPH/IzPHHIOS5e/wRe+eSGvrngz76YVgzwc8VGIZoJgiWuBUyLi08B5wBYAEXEicDYwGJgrqX9E3AAcAqwDpkk6oFFdS4DSf8cNApZu7k3kqccWXenZo9uG8wNGfYpn/pzd0n57f5KFL77K0uVvbMi/5JXX+fxff3JD/pHDdmThX17dcP3wg0ds1HO24hi660AW3nMBT049nyenns/Ht+nDH3/9z2w7oHfeTSsEAVJ5R0dUqSA8HThKUn+AZoYjegHLJH2MrCdMyrtLRMyMiHOAFcBgSTsDz0fEJGAq8JnSiiJiGbBG0ihlfx0eB9xRiRtrL1v378VdV3yfh64/g/+dfBr3PPwU02c8A8A3Dhqx4YFcgyt/8yBbdu/KozedxfTJp3HDnX/iqUUf/D10WMlDvAbDd9+eBb/7CYceOJyLzzyaRxtNl7LKGH/WNRz0rf9g0YuvMvSrZzPljkfzblLBldcL7qg9YVVqFpekccBpQD3wREQcXzpFTdJJwOnAi8B8oFfKcxvZ7AaRBfNTgTOAbwLvA68AxzQe4pA0kg+mqN0FfLe1KWo1PbaJbp88qm1u2NrFqscuzbsJtglG7zOSOXNmb1Z03OKvPhE7jLukrLz/9/MxcyJi5OZ8X3ur2DzhiJgMTG6Udm7J+eVk08oal/tGE9X9LB0tfd9sYNhHaauZFVgHHmooh9+YM7NCE1DTQaeflcNB2MwKzz1hM7McddSHbuWopteWzawalTk9rdw4LalW0hOSfpc+95N0r6SF6WffkrxnSlok6TlJB5ekj5A0P12blGZlIambpJtS+kxJO7bWHgdhMys0IWpqaso6yvRPwDMln88ApkfEELIZWWcASNodGEv2ItkY4DJJDS+QNbdWzXhgVUTsClwMXNhaYxyEzazw2qonLGkQ8FXgypLkQ/lgJtdkPlh35lDgxoh4NyJeABYBe7eyVk1pXbcAB6qVsRQHYTMrvDZ8WeM/yd5PWF+Stm164avhxa9tUvpAoPQ9/4Y1aVpaq2ZDmYioA1YD/VtqkIOwmRXbpo0JD5A0u+SYsKEa6WvA8oiY09xXffibPyRaSG+pTLM8O8LMCi1bO6Ls2RErWnhjbjRwiKSvkK1V01vSr4FXJW0XEcvSUMPylH8J2Ro2DRrWpGlprZqGMkskdQG2AppawGwD94TNrPDaYkw4Is6MiEERsSPZA7f7IuKbZOvRjEvZxvHBujNTgbFpxsNOZA/gZrWyVk1pXUek73BP2Mw6tgq/MXcBcLOk8cBLwJEAEfGUpJuBp4E64OSIqE9lTmLjtWruSulXAVMkLSLrAY9t7csdhM2s2NT2L2tExAPAA+l8JdDkRosRMRGY2ER6k2vVRMQ7pCBeLgdhMyu0hvWEq5WDsJkVXMddK7gcDsJmVnhVHIMdhM2s4OSlLM3McrOJ84Q7HAdhMys8B2EzsxxVcQx2EDaz4nNP2MwsL97o08wsP9mi7tUbhR2Ezazwaqq4K+wgbGaFV8Ux2EHYzIpNFVjAp0gchM2s8Kp4SLj5ICzpElrYliMivleRFpmZNdJZH8zNbrdWmJk1Q2QzJKpVs0E4IiaXfpa0ZUS8VfkmmZltrIo7wq3vMSfps5KeBp5Jn/eQdFnFW2ZmBlDmdvcd9eFdORt9/idwMLASICLmAftWsE1mZhtpi40+i6qs2RERsbjR3zL1zeU1M2tLwi9rLJb0OSAkdQW+RxqaMDNrD9U8O6Kc4YgTgZOBgcDLwJ7ps5lZxZU7FNFRO8ut9oQjYgVwbDu0xcysSdU8HFHO7IidJd0p6TVJyyXdIWnn9micmRk0zBVu/eiIyhmOuAG4GdgO+DjwG+B/KtkoM7NSnX2KmiJiSkTUpePXtPA6s5lZW8pmR5R3dEQtrR3RL53eL+kM4Eay4Pt3wO/boW1mZqDOu6j7HLKg23D33y65FsBPKtUoM7NSHXWooRwtrR2xU3s2xMysKQ3DEdWqnDFhJA2TdJSk4xqOSjfMzKxBWzyYk7SFpFmS5kl6StJ5Kb2fpHslLUw/+5aUOVPSIknPSTq4JH2EpPnp2iSlL5fUTdJNKX2mpB1bu7dypqj9GLgkHfsDPwcOaa2cmVlbaaMpau8CB0TEHmQvnY2RNAo4A5geEUOA6ekzknYHxgJDgTHAZZJqU12XAxOAIekYk9LHA6siYlfgYuDC1hpVTk/4COBA4JWI+AdgD6BbGeXMzDabBLU1KutoSWTWpo8fS0cAhwINS/dOBg5L54cCN0bEuxHxArAI2FvSdkDviJgREQFc16hMQ123AAc29JKbU04QXhcR64E6Sb2B5YBf1jCzdrMJwxEDJM0uOSY0qqdW0lyyOHZvRMwEto2IZQDp5zYp+0BgcUnxJSltYDpvnL5RmYioA1YD/Vu6t3IW8JktqQ9wBdmMibXArDLKmZm1iU2YHLEiIkY2dzEi6oE9U0y7XdKwlr62qSpaSG+pTLPKWTviO+n0l5LuJuuGP9laOTOztiDU5mtHRMQbkh4gG8t9VdJ2EbEsDTUsT9mWAINLig0Clqb0QU2kl5ZZIqkLsBXwekttaXY4QtJejQ+gH9AlnZuZVV4braImaevUA0ZSd+CLwLPAVGBcyjYOuCOdTwXGphkPO5E9gJuVhizWSBqVxnuPa1Smoa4jgPvSuHGzWuoJ/0cL1wI4oKWKO4Lhu23PIzMvzbsZtgnWrHs/7ybYJqhvOf6UrY1e1tgOmJxmONQAN0fE7yTNAG6WNB54CTgSICKeknQz8DRQB5ychjMATgKuBboDd6UD4CpgiqRFZD3gsa01qqWXNfbf5Fs0M2tjAmrbIAinYdThTaSvJJsB1lSZicDEJtJnAx8aT46Id0hBvFxlbW9kZpanan5jzkHYzArPQdjMLCfZQ7fqjcLlvLYsSd+UdE76vL2kvSvfNDOzTDWvJ1zOG3OXAZ8Fjk6f1wD/VbEWmZk10qk3+gT2iYi9JD0BEBGrJHWtcLvMzIBsdkSXjhphy1BOEH4/zasLyCY8A+sr2iozsxJVHIPLCsKTgNuBbSRNJHsL5OyKtsrMLJHa/rXlIiln7YjrJc0hm8ws4LCIeKbiLTMzS6o4BrcehCVtD7wN3FmaFhEvVbJhZmYNOurMh3KUMxzxez5Yvm0LYCfgObLV5s3MKkrQ6oLtHVk5wxGfLv2cVlD7djPZzczaVgeeA1yOTX5jLiIel/TXlWiMmVlTVM4Och1UOWPCPyj5WAPsBbxWsRaZmZWo9i3vy+kJ9yo5ryMbI761Ms0xM/uwThuE00saPSPitHZqj5nZh1TzAj7NBmFJXSKizlsZmVmesi3v825F5bTUE55FNv47V9JU4DfAWw0XI+K2CrfNzAygc78xR7a550qyPeUa5gsH4CBsZhXXmR/MbZNmRizgg+DboG127zMzK0MVd4RbDMK1QE9ocoKeg7CZtRNR00nnCS+LiPPbrSVmZk0QnbcnXMW3bWYdhqBLFQ8KtxSED2y3VpiZNaPT9oQj4vX2bIiZWXM6+xQ1M7NcVXEMdhA2s2IT5W0L31E5CJtZscnDEWZmucnemKveIFzNvXwzqxIq82i1HmmwpPslPSPpKUn/lNL7SbpX0sL0s29JmTMlLZL0nKSDS9JHSJqfrk1SWupNUjdJN6X0mZJ2bKlNDsJmVnhSeUcZ6oAfRsRuwCjgZEm7A2cA0yNiCDA9fSZdG0u2p+YY4LK0xC/A5cAEYEg6xqT08cCqiNgVuBi4sKUGOQibWcEJqbyjNRGxLCIeT+drgGeAgcChwOSUbTJwWDo/FLgxIt6NiBeARcDekrYDekfEjIgI4LpGZRrqugU4UC00zkHYzAqtYXZEOQcwQNLskmNCs/VmwwTDgZnAthGxDLJADWyTsg0EFpcUW5LSBqbzxukblYmIOmA10L+5dvjBnJkV3iY8mFsRESNbyySpJ9k2badGxJstdFSbW8CspYXNNmnRM/eEzazYRJsNRwBI+hhZAL6+ZHOKV9MQA+nn8pS+BBhcUnwQsDSlD2oifaMykroAWwHNvoHsIGxmhbaJwxEt15VF6quAZyLiopJLU4Fx6XwccEdJ+tg042Ensgdws9KQxRpJo1KdxzUq01DXEcB9ady4SR6OMLPCa8ONPkcDfw/MlzQ3pf0IuAC4WdJ44CXgSICIeErSzcDTZDMrTo6I+lTuJOBaoDtwVzogC/JTJC0i6wGPbalBDsJmVnhtFYIj4uEWqmty5ciImAhMbCJ9NjCsifR3SEG8HA7CZlZoAmqr+I05B2EzK7wqjsEOwmZWdEJVvNGPg7CZFZ57wmZmOcmmqFVvFHYQNrNiK39xng7JQdjMCq+a1xN2EDazQssWdc+7FZXjIGxmhefZEWZmOari0QgH4Y7ulPN/zbSHFzCgby9m3HQWAN8682oWvvgqAKvXrmOrnt156IYz82xmp/POu+9z5Hcv5b3366irr+cr++3BD7/1ZQCuufVBJt/2MLW1NRzw2d0566RDNpR7+dVVHHjcBXz/+DF8++j9AZg6/QkunXIv9evXfyh/Z+GecBuRdC6wNiL+vQJ1TyRbyahvRPRs6/qL6uivjeKEo77AiT++bkPa1T/71obzsy++jd49u+fRtE6tW9cu3Pif32HLHt14v66ew0+exP777MY7777PPQ8vYNo1p9OtaxdWrFqzUbnzL/kt++2z24bPq1a/xU8vn8rvr/wh/fv05PsTr+fhOf/H34z4RHvfUm6qfUy4mpayvBPYO+9GtLfRe+1K3949mrwWEdz+v49z+MEj2rlVJokte3QDoK6unrq6eiQx5Y5H+M6xB9Kta9b/GdC314Yy0x6az/Yf788ndvyrDWkvLV3JToO3pn+frF/xNyM/wV1/fLId76QAJGrKPDqiigVhScdJelLSPElTmrh+gqTH0vVbJfVI6UdKWpDSH0xpQyXNkjQ31TmkcX0R8aeG7Uks8+gTf2ab/r3YZfttWs9sba6+fj1jvvVvDD/0X/ibkZ9k+O478MLi15j15PMc8u2LOfK7lzLvmZcAeHvdu1x+w3ROPf7gjerYYdAA/vzSchYve526unrueWgBS5evyuN2ctVWuy0XUUWGIyQNBc4CRkfECkn9msh2W0RckfL/K9kOpZcA5wAHR8TLkvqkvCcCv4iI6yV1BWqbqK/ctk0g2yGVwdtv/1Gr6RBuvWc2hx/U6k4vViG1tTXcffVprF6zjglnX81zzy+jrn49q9es445fnsq8Z17iOz+ezMM3nc1FV9/N+CO/sKH33KBPrx5M/MERnHzuZGpqxIihO/HSspU53VE+suGIjhpiW1epMeEDgFsiYgVARDS1tcewFHz7AD2BaSn9EeDatJByw9YjM4CzJA0iC94LP2rDIuJXwK8ARowY2exq9x1dXV09v7t/Hvdfd3reTen0turVnVF77sIDM59lu6378OV9P4Mk9tx9B1QjXl/9Fk888yJ/+OM8fvbLO3lz7TqkGrp17cLxh3+eL40expdGZ8vWXj/1UWpqqzcgNaea77hSQVi0sLFdci1wWETMk3Q8sB9ARJwoaR/gq8BcSXtGxA2SZqa0aZL+MSLuq1Dbq8IDs55jyA7bMnDbvnk3pVNa+cZautTWslWv7rzz7ns8POf/OOmYA+nRoyuPPr6Qzw7flecXL+f99+vpt9WW3Hrp9zaUvejqu9myezeOP/zzAKxYtYYBfXvxxpq3mfLbR7jsvHHNfW31quIoXKkgPB24XdLFEbFSUr8mesO9gGVp071jgZcBJO0SETOBmZL+FhgsaSvg+YiYJGln4DOAgzAw/qxreGTOQla+sZahXz2bMyZ8hb8/9HPcds8cP5DL0fKVb/KDn95Aff161kfwtf335IufG8p779dx2gU38sVxF9K1Sy0X/eiYVrfuOXfS7Ty9KNtD8tTjD2LnwZ1vjL+ahyPUwv5zm1exNA44DagHnoiI40unqEk6CTgdeBGYD/RKeW4j20xPZMH8VOAM4JvA+8ArwDGNg7qknwPHAB8n2/X0yog4t6U2jhgxMh6ZObttbtjaxZp17+fdBNsEX/rCKOY+PmezIuhunx4e193xQFl5996lz5xytrwvkorNE46IycDkRmnnlpxfDlzeRLlvNFHdz9LR0vedThbUzazaVG9H2G/MmVmxZdPPqjcKOwibWbF5PWEzs3xVcQx2EDazolOrM0g6MgdhMyu8Ko7BDsJmVmwdeV2IcjgIm1nxVXEUdhA2s8Kr5ilq1bSesJlVKam8o/V6dLWk5ZIWlKT1k3SvpIXpZ9+Sa2dKWiTpOUkHl6SPkDQ/XZuk9ORQUjdJN6X0mZJ2bK1NDsJmVmxlBuAyH95dC4xplHYGMD0ihpAtlXAGgKTdgbHA0FTmMkkNy+heTrYk7pB0NNQ5HlgVEbsCFwMXttYgB2EzKzyV+V9rIuJBoPFiYofywRILk4HDStJvjIh3I+IFYBGwt6TtgN4RMSOyxXeua1Smoa5bgAPVyvw6B2EzKzSxST3hAZJmlxwTyviKbRt25Uk/G5apGwgsLsm3JKUNTOeN0zcqExF1wGqgf0tf7gdzZlZ4m/BYbkUbrqLW1NdGC+ktlWmWe8JmVnyV3WTu1TTEQPq5PKUvAQaX5BtEtkzuknTeOH2jMpK6AFvx4eGPjTgIm1nhVXi35alAw3Yl44A7StLHphkPO5E9gJuVhizWSBqVxnuPa1Smoa4jgPuilUXbPRxhZoXXVrOEJf0P2VZqAyQtAX4MXADcLGk88BJwJEBEPJX2unwaqANOjoj6VNVJZDMtugN3pQPgKmCKpEVkPeCxrbXJQdjMiq+NonBEHN3MpQObyT8RmNhE+mxgWBPp75CCeLkchM2s0Lyou5lZnryou5lZvqo4BjsIm1nReVF3M7NcVXEMdhA2s2Lzou5mZnmr4ijsIGxmhecpamZmOfKYsJlZXgQ1DsJmZnmq3ijsIGxmhdawqHu1chA2s8Kr4hjsIGxmxeeesJlZjvzasplZjqo3BDsIm1nByUtZmpnly2/MmZnlqXpjsIOwmRVfFcdgB2EzK7rN2s6+8ByEzazQqv2NuZq8G2Bm1pm5J2xmhVfNPWEHYTMrPE9RMzPLi1/WMDPLT7U/mHMQNrPC83CEmVmO3BM2M8tRFcdgB2Ez6wCqOAo7CJtZoQmq+rVlRUTebciNpNeAF/NuRwUMAFbk3QjbJNX6O9shIrbenAok3U3251OOFRExZnO+r7116iBcrSTNjoiRebfDyuffWefltSPMzHLkIGxmliMH4er0q7wbYJvMv7NOymPCZmY5ck/YzCxHDsJmZjlyEO4gJJ0r6f9VqO4RkuZLWiRpklTFM+PbUYV/ZxMlLZa0thL1W/txEDaAy4EJwJB0dKjJ7p3UncDeeTfCNp+DcAFJOk7Sk5LmSZrSxPUTJD2Wrt8qqUdKP1LSgpT+YEobKmmWpLmpziGN6toO6B0RMyJ7SnsdcFjl77K6tOfvDCAi/hQRyyp/Z1ZpXjuiYCQNBc4CRkfECkn9msh2W0RckfL/KzAeuAQ4Bzg4Il6W1CflPRH4RURcL6krUNuoroHAkpLPS1KalSmH35lVEfeEi+cA4JaIWAEQEa83kWeYpIckzQeOBYam9EeAayWdwAf/484AfiTpn8ne41/XqK6mxn89b3HTtPfvzKqIg3DxiNaD4LXAKRHxaeA8YAuAiDgROBsYDMyV1D8ibgAOAdYB0yQd0KiuJcCgks+DgKWbexOdTHv/zqyKOAgXz3TgKEn9AZr5p20vYJmkj5H1qkh5d4mImRFxDtmKXIMl7Qw8HxGTgKnAZ0orSuOKaySNSrMijgPuqMSNVbF2/Z1ZdXEQLpiIeAqYCPxR0jzgoiay/QswE7gXeLYk/d/SVLMFwIPAPODvgAWS5gKfInvw1thJwJXAIuDPwF1tczedQx6/M0k/l7QE6CFpiaRz2/CWrB35tWUzsxy5J2xmliMHYTOzHDkIm5nlyEHYzCxHDsJmZjlyELZmSapP6xcskPSbhvUOPmJd10o6Ip1fKWn3FvLuJ+lzH+E7/iLpQ7vyNpfeKM8mrUZWyRXSrHNxELaWrIuIPSNiGPAe2ZoGG0j6SGsaRMQ/RsTTLWTZD9jkIGzWETkIW7keAnZNvdT7Jd0AzJdUK+nf0gphT0r6NoAyl0p6WtLvgW0aKpL0gKSR6XyMpMfTKmLTJe1IFuy/n3rhn5e0dVp57LF0jE5l+0u6R9ITkv6bptfB2Iik30qaI+kpSRMaXfuP1JbpkrZOabtIujuVeUjSp9rkT9Ms8Spq1ipJXYAvA3enpL2BYRHxQgpkqyPiryV1Ax6RdA8wHPgk8GlgW+Bp4OpG9W4NXAHsm+rqFxGvS/olsDYi/j3luwG4OCIelrQ9MA3YDfgx8HBEnC/pq2RrIrfmW+k7ugOPSbo1IlYCWwKPR8QPJZ2T6j6FbAPOEyNioaR9gMvIFuwxaxMOwtaS7unVWch6wleRDRPMiogXUvpBwGcaxnuBrcgWht8X+J+IqAeWSrqvifpHAQ821NXM6mMAXwR21wcbfvSW1Ct9xzdS2d9LWlXGPX1P0tfT+eDU1pXAeuCmlP5r4DZJPdP9/qbku7uV8R1mZXMQtpasi4g9SxNSMHqrNAn4bkRMa5TvK7S+slg5q49BNmz22cZLOqa2lP3evaT9yAL6ZyPibUkPkFYza0Kk732j8Z+BWVvymLBtrmnASWl1MCR9QtKWZIvRjE1jxtsB+zdRdgbwBUk7pbINq4+tIVt1rME9ZEMDpHx7ptMHSSuSSfoy0LeVtm4FrEoB+FNkPfEGNUBDb/4YsmGON4EXJB2ZvkOS9mjlO8w2iYOwba4rycZ7H08rgf032b+wbgcWAvPJ9rD7Y+OCEfEa2TjubWn1sYbhgDuBrzc8mAO+B4xMD/6e5oNZGucB+0p6nGxY5KVW2no30EXSk8BPgD+VXHsLGCppDtmY7/kp/VhgfGrfU8ChZfyZmJXNq6iZmeXIPWEzsxw5CJuZ5chB2MwsRw7CZmY5chA2M8uRg7CZWY4chM3McvT/AXGT9H8NspYuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#performance results\n",
    "print(classification_report(y_test, y_pred4, target_names=target_names))\n",
    "plot_confusion_matrix(model4, df_X_test_stand, y_test, display_labels=target_names,cmap=plt.cm.Blues);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e)  XG Boost, Extreme Gradient Boosting (XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=1.000 total time=   4.1s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=1.000 total time=   4.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=1.000 total time=   4.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=1.000 total time=   4.0s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=100;, score=1.000 total time=   4.0s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=5, n_estimators=150;, score=1.000 total time=   5.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=5, n_estimators=150;, score=1.000 total time=   5.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=5, n_estimators=150;, score=1.000 total time=   5.7s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=5, n_estimators=150;, score=1.000 total time=   5.7s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=5, n_estimators=150;, score=1.000 total time=   5.7s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=100;, score=1.000 total time=   5.5s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=100;, score=1.000 total time=   5.6s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=100;, score=1.000 total time=   5.6s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=100;, score=1.000 total time=   5.5s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=100;, score=1.000 total time=   5.7s\n",
      "[CV 1/5] END learning_rate=0.1, max_depth=10, n_estimators=150;, score=1.000 total time=   7.0s\n",
      "[CV 2/5] END learning_rate=0.1, max_depth=10, n_estimators=150;, score=1.000 total time=   7.1s\n",
      "[CV 3/5] END learning_rate=0.1, max_depth=10, n_estimators=150;, score=1.000 total time=   7.1s\n",
      "[CV 4/5] END learning_rate=0.1, max_depth=10, n_estimators=150;, score=1.000 total time=   6.9s\n",
      "[CV 5/5] END learning_rate=0.1, max_depth=10, n_estimators=150;, score=1.000 total time=   7.0s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=1.000 total time=   3.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=1.000 total time=   3.5s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=1.000 total time=   3.4s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=1.000 total time=   3.4s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=100;, score=1.000 total time=   3.4s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=5, n_estimators=150;, score=1.000 total time=   4.4s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=5, n_estimators=150;, score=1.000 total time=   4.4s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=5, n_estimators=150;, score=1.000 total time=   4.5s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=5, n_estimators=150;, score=1.000 total time=   4.3s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=5, n_estimators=150;, score=1.000 total time=   4.5s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=100;, score=1.000 total time=   3.9s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=100;, score=1.000 total time=   3.9s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=100;, score=1.000 total time=   4.0s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=100;, score=1.000 total time=   3.9s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=100;, score=1.000 total time=   4.1s\n",
      "[CV 1/5] END learning_rate=0.2, max_depth=10, n_estimators=150;, score=1.000 total time=   4.8s\n",
      "[CV 2/5] END learning_rate=0.2, max_depth=10, n_estimators=150;, score=1.000 total time=   4.9s\n",
      "[CV 3/5] END learning_rate=0.2, max_depth=10, n_estimators=150;, score=1.000 total time=   4.9s\n",
      "[CV 4/5] END learning_rate=0.2, max_depth=10, n_estimators=150;, score=1.000 total time=   4.8s\n",
      "[CV 5/5] END learning_rate=0.2, max_depth=10, n_estimators=150;, score=1.000 total time=   5.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     eval_metric='mlogloss', gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, random_state=None,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, subsample=None,\n",
       "                                     tree_method=None, use_label_encoder=False,\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             param_grid={'learning_rate': [0.1, 0.2], 'max_depth': [5, 10],\n",
       "                         'n_estimators': [100, 150]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run grid search only on training set using cross-validation\n",
    "parameters = {'max_depth': [5, 10],'n_estimators': [100, 150], 'learning_rate': [0.1, 0.2]}\n",
    "model5 = GridSearchCV(XGBClassifier(eval_metric='logloss',use_label_encoder =False), parameters, cv=5, verbose=3)\n",
    "model5.fit(df_X_train_stand, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 150}\n",
      "accuracy : 0.9999553213722571\n",
      "Best Model: XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, eval_metric='mlogloss',\n",
      "              gamma=0, gpu_id=-1, importance_type='gain',\n",
      "              interaction_constraints='', learning_rate=0.2, max_delta_step=0,\n",
      "              max_depth=5, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=150, n_jobs=32,\n",
      "              num_parallel_tree=1, random_state=0, reg_alpha=0, reg_lambda=1,\n",
      "              scale_pos_weight=1, subsample=1, tree_method='exact',\n",
      "              use_label_encoder=False, validate_parameters=1, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",model5.best_params_)\n",
    "print(\"accuracy :\",model5.best_score_)\n",
    "print('Best Model:',model5.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred5 = model5.predict(df_X_test_stand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      1.00      1.00     57885\n",
      "     class 1       1.00      0.99      1.00      3666\n",
      "\n",
      "    accuracy                           1.00     61551\n",
      "   macro avg       1.00      1.00      1.00     61551\n",
      "weighted avg       1.00      1.00      1.00     61551\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAEGCAYAAAC0DiQ1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAiaElEQVR4nO3deZhU1ZnH8e+vm7AporgHUIzihgsIKsa4oRMxi5ooDnEBEyJu0ZiYRaNJNAnjkkxM1NEkagJqjBqXqJO4DY7jEgOCiojGkXEDRRFEBAWkm3f+uKexaKu7q6Wrb3X17+Nzn646dc+pc+mH18O5575HEYGZmeWjJu8OmJl1Zg7CZmY5chA2M8uRg7CZWY4chM3MctQl7w7kSV16hLr2yrsb1gpDdtgi7y5YK7zyysssWLBAa9NG7XpbRtQtK+ncWPbWvRExcm2+r7117iDctRfdtjsq725YKzw65fK8u2CtsPeew9a6jahbVvLf0+VP/cdGa/2F7axTB2Ez6wgEqt6ZUwdhM6tsAmpq8+5F2TgIm1nl01pNK1c0B2Ezq3CejjAzy5dHwmZmOREeCZuZ5UceCZuZ5cqrI8zM8uIbc2Zm+RGejjAzy5VHwmZmefF0hJlZfgTU+sacmVl+PCdsZpYXT0eYmeXLI2Ezsxx5JGxmlhP5sWUzs3z5sWUzs7z4xpyZWb48HWFmlhPnEzYzy5OnI8zM8uUbc2ZmOariOeHqHeObWXVQmo4o5SipOb0saaakpyRNS2V9JN0v6YX0c4OC88+WNFvS85IOLigfmtqZLelSKfs/haRukm5K5VMkDWiuPw7CZlb5Gh7YaOko3QERMTgihqX3ZwGTI2IgMDm9R9KOwGhgEDASuEJSw9zIlcB4YGA6RqbyccCiiNgGuAS4qLmOOAibWcWTVNKxFg4DJqXXk4DDC8pvjIgVEfESMBvYQ9LmwHoR8VhEBHBtozoNbd0CHKhmOucgbGYVLdvdqOQgvJGkaQXH+CJNBnCfpOkFn28aEfMA0s9NUnlfYE5B3bmprG963bh8jToRUQcsBjZs6vp8Y87MKpuEakoe5S4omGJoyt4R8bqkTYD7Jf2zuW8vUhbNlDdXpyiPhM2s4rXldEREvJ5+zgduB/YA3kxTDKSf89Ppc4H+BdX7Aa+n8n5FyteoI6kL0Bt4u6n+OAibWcVrqyAsaR1JvRpeA58FngHuBMam08YCd6TXdwKj04qHrchuwE1NUxZLJA1P871jGtVpaOtI4IE0b1yUpyPMrOKt5U23QpsCt6f2ugA3RMQ9kh4HbpY0DngVGAUQEbMk3Qw8C9QBp0ZEfWrrZGAi0AO4Ox0A1wDXSZpNNgIe3VyHHITNrLKJ4rOsH0NEvAjsWqR8IXBgE3UmABOKlE8DdipSvpwUxEvhIGxmFU2s9fKziuYgbGYVr6amem9fOQibWcXzSNjMLC9tOCdciRyEzazieSRsZpYT35gzM8tZKx5b7nAchM2sssnTEWZmuXIQNjPLkYOwmVlOfGPOzCxv1RuDHYTNrMLJjy2bmeXK0xFmZnmq3hjsIFzJZtxxPkvfX0H9qlXU1a1ixNiLuebfvsrALTcFoPe6PVi8dBn7HnMhXWpruPTcY9h1+/7U1tZw09+mcsnE+wA44rND+fZXDyYimLdgMSf+cBJvL36PU44ewXGH7UV9/SoWvLOU035yPXPeWJTnJXcqy1es5PPjf8WKlXXU19Vz6IFDOPvEz+fdrYrkkXAbkXQesDQiflGGtofyYZb7vwHfbG5LkY7iiyf9mrcXv7f6/bgf/GH165+e8SXeXboMgMMP2o1uXbuw91f+jR7dPsE/bj6XW+6dxuvz3+GCM49k+FE/4+3F73H+aYdxwlH7cdFVf+Pp5+cwYszDLFuxkq8d8RnOO/3wNdq38urWtQt3XHk66/bsxsq6eg75+i856NM7svvOW+XdtYrSBtvZV7Rqmu2+EhhPtgfUQGBkvt0pvy8dtBu33jsdgIigZ4+u1NbW0L17Vz5YWc+S95an7cJhnR5dAei1Tg/eWLAYgEemv8CyFSsBeHzmy/TdZP08LqPTksS6PbsBsLKunpV19VUdbNZGW270WWnKNhKWNAb4DtlWz09HxHGNPj+BLGh2BWYDx0XE+5JGAT8G6oHFEbGvpEHAH9K5NcAREfFCQVubA+tFxGPp/bXA4Xy451OHFBHcdvk3iAgm3v4ok25/dPVnnx6yNfMXLuHFOW8BcMfkJ/ncfrvwz7sn0KN7V8655Dbeefd9AM688CYe+dMPeH/5B7z46lt85+KbPvJdxx22F/f//dn2uTBbrb5+FfsfdxEvzX2LcaP2ZdhOA/LuUkWq5twRZRkJp6B5DjAiInYFvlnktNsiYvf0+XPAuFT+I+DgVH5oKjsJ+HVEDAaGkW0pXahvo7K5qaxY38ZLmiZpWtQta/3FtaORX7+E/Y+7iFHfvIKvH7kPnx6y9erPjvjsMG69b9rq90MHDaB+1Sp2OOQcBh/2Y049ZgRb9t2QLrU1fO3Ifdjv2IvY4ZBzmDX7Nb51/GfX+J6jDtmdwTtswWXXTW63a7NMbW0ND99wNrP++jOemPUKz85+veVKnVA1j4TLNR0xArglIhYARMTbRc7ZSdLDkmYCxwCDUvmjwMQ0Uq5NZY8BP5D0fWDLiGgcPYv96RedD46I30XEsIgYpi49WndV7axh2mDBoqX854NPs9ugAUD2F/cLB+zK7fc/sfrcI0cOY/Lfn6WufhULFi1lyowXGbLDFuy8XT8AXn5tAQB/+a8n2HOXT62ut98e2/Htrx7M0Wf+lg9W1rXTlVljvXv15DNDBzL5Mf9r5CPkIPxxiCaCYIGJwDciYmfgfKA7QEScBJwL9AeekrRhRNxANipeBtwraUSjtuYC/Qre9wM69JCiZ/euq+cLe3bvyojh2/Pc/2WXtP8e2/HCK2/y+vx3Vp8/94232Wf37VafP2ynAbzw8pvMm7+Y7bbajA3XXzeru+f2PP/yGwDsvG0/Ljl7NEef+VsWLFrajldnAAsWLWHxkmzKaNnyD3hw6vMMHLBpzr2qPA33NUo5OqJyzQlPBm6XdElELJTUp8houBcwT9InyEbCrwFI2joipgBTJH0R6C+pN/BiRFwq6VPALsADDQ1FxDxJSyQNB6YAY4DLynRt7WLjDXtx/cUnAFDbpZZb75nG5MeeA+DLnx26+oZcg6v//BCX/+hY/n7TOQi44a5/MCv90/biq+7mr787g7q6eua88TannH89AD/55uGs06MbEy/MZoLmvrGIo8/8bTtdob2x4F1OOe866letYtWq4EsH7cbIfXbOu1sVqOOOckuhcq3ikjQW+C7ZDbYnI+L4wiVqkk4Gvge8AswEeqVzbiNb3SCyYH4GcBZwLLASeAM4unFQlzSMD5eo3Q2c1tIStZqem0S37Y5qmwu2drHo8cvz7oK1wt57DmP69GlrFUG7b7ZtbDm2tDHV/148cnpEDFub72tvZVsdERGTgEmNys4reH0l2bKyxvW+XKS5C9LR3PdNA3b6OH01swrWgacaSuEn5sysogmoqeIlag7CZlbxPBI2M8tRNd+Yq6bHls2sGpW4PK3UOC2pVtKTkv4zve8j6X5JL6SfGxSce7ak2ZKel3RwQflQSTPTZ5cq/V9CUjdJN6XyKZIGtNQfB2Ezq2hC1NTUlHSU6JtkT+k2OAuYHBEDyVZknQUgaUdgNNmDZCOBKyQ1PEDWVK6accCiiNgGuAS4qKXOOAibWcVrq5GwpH7A54GrC4oP48OVXJPI8s40lN8YESsi4iWyHDd7FOaqSctgr21Up6GtW4AD1cJcioOwmVW8Nnxs+VdkzyesKijbNCLmQfbgF7BJKu8LzCk4ryEnTXO5albXiYg6YDGwYXMdchA2s8rWujnhjRoSdKVj/OpmpC8A8yNielNf9dFv/ohopry5Ok3y6ggzq2hZ7oiSV0csaOaJub2BQyV9jixXzXqSrgfelLR5Sn+wOTA/nT+XLIdNg4acNM3lqmmoM1dSF6A3UCyB2WoeCZtZxWuLOeGIODsi+kXEALIbbg9ExLHAncDYdNpY4I70+k5gdFrxsBXZDbipacpiiaThab53TKM6DW0dmb7DI2Ez69jK/MTchcDNksYBrwKjACJilqSbgWeBOuDUiKhPdU5mzVw1DRtIXANcJ2k22Qh4dEtf7iBsZpVNbf+wRkQ8CDyYXi8EDmzivAnAhCLlRXPVRMRyUhAvlYOwmVW0hnzC1cpB2MwqXHXnE3YQNrOKV8Ux2EHYzCqcnMrSzCw3rVwn3OE4CJtZxXMQNjPLURXHYAdhM6t8HgmbmeXFG32ameUnS+pevVHYQdjMKl5NFQ+FHYTNrOJVcQx2EDazyqYyJPCpJA7CZlbxqnhKuOkgLOkymtmWIyJOL0uPzMwa6aw35qa1Wy/MzJogshUS1arJIBwRkwrfS1onIt4rf5fMzNZUxQPhlveYk7SXpGeB59L7XSVdUfaemZkBlLjdfUe9eVfKRp+/Ag4GFgJExAxg3zL2ycxsDW2x0WelKml1RETMafR/mfqmzjUza0vCD2vMkfRpICR1BU4nTU2YmbWHal4dUcp0xEnAqUBf4DVgcHpvZlZ2pU5FdNTBcosj4YhYABzTDn0xMyuqmqcjSlkd8SlJd0l6S9J8SXdI+lR7dM7MDBrWCrd8dESlTEfcANwMbA58Evgz8KdydsrMrFBnX6KmiLguIurScT3NPM5sZtaWstURpR0dUXO5I/qkl/8t6SzgRrLg+6/AX9uhb2ZmoM6b1H06WdBtuPoTCz4L4Kfl6pSZWaGOOtVQiuZyR2zVnh0xMyumYTqiWpUyJ4yknSQdJWlMw1HujpmZNWiLG3OSukuaKmmGpFmSzk/lfSTdL+mF9HODgjpnS5ot6XlJBxeUD5U0M312qdKXS+om6aZUPkXSgJaurZQlaj8GLkvHAcDFwKEt1TMzaytttERtBTAiInYle+hspKThwFnA5IgYCExO75G0IzAaGASMBK6QVJvauhIYDwxMx8hUPg5YFBHbAJcAF7XUqVJGwkcCBwJvRMRXgV2BbiXUMzNbaxLU1qikozmRWZrefiIdARwGNKTunQQcnl4fBtwYESsi4iVgNrCHpM2B9SLisYgI4NpGdRraugU4sGGU3JRSgvCyiFgF1ElaD5gP+GENM2s3rZiO2EjStIJjfKN2aiU9RRbH7o+IKcCmETEPIP3cJJ3eF5hTUH1uKuubXjcuX6NORNQBi4ENm7u2UhL4TJO0PnAV2YqJpcDUEuqZmbWJViyOWBARw5r6MCLqgcEppt0uaafmvrZYE82UN1enSaXkjjglvfyNpHvIhuFPt1TPzKwtCLV57oiIeEfSg2RzuW9K2jwi5qWphvnptLlA/4Jq/YDXU3m/IuWFdeZK6gL0Bt5uri9NTkdI2q3xAfQBuqTXZmbl10ZZ1CRtnEbASOoBHAT8E7gTGJtOGwvckV7fCYxOKx62IrsBNzVNWSyRNDzN945pVKehrSOBB9K8cZOaGwn/ezOfBTCiuYY7giE7bMGjUy7PuxvWCkuWrcy7C9YK9c3Hn5K10cMamwOT0gqHGuDmiPhPSY8BN0saB7wKjAKIiFmSbgaeBeqAU9N0BsDJwESgB3B3OgCuAa6TNJtsBDy6pU4197DGAa2+RDOzNiagtg2CcJpGHVKkfCHZCrBidSYAE4qUTwM+Mp8cEctJQbxUJW1vZGaWp2p+Ys5B2MwqnoOwmVlOsptu1RuFS3lsWZKOlfSj9H4LSXuUv2tmZplqzidcyhNzVwB7AV9J75cA/1G2HpmZNdKpN/oE9oyI3SQ9CRARiyR1LXO/zMyAbHVEl44aYUtQShBemdbVBWQLnoFVZe2VmVmBKo7BJQXhS4HbgU0kTSB7CuTcsvbKzCyR2v6x5UpSSu6IP0qaTraYWcDhEfFc2XtmZpZUcQxuOQhL2gJ4H7irsCwiXi1nx8zMGnTUlQ+lKGU64q98mL6tO7AV8DxZtnkzs7IStJiwvSMrZTpi58L3KYPaiU2cbmbWtjrwGuBStPqJuYh4QtLu5eiMmVkxKmUHuQ6qlDnhbxe8rQF2A94qW4/MzApU+5b3pYyEexW8riObI761PN0xM/uoThuE00Ma60bEd9upP2ZmH1HNCXyaDMKSukREnbcyMrM8ZVve592L8mluJDyVbP73KUl3An8G3mv4MCJuK3PfzMwAOvcTc2Sbey4k21OuYb1wAA7CZlZ2nfnG3CZpZcQzfBh8G7TN7n1mZiWo4oFws0G4FlgXii7QcxA2s3YiajrpOuF5EfGTduuJmVkRovOOhKv4ss2swxB0qeJJ4eaC8IHt1gszsyZ02pFwRLzdnh0xM2tKZ1+iZmaWqyqOwQ7CZlbZRGnbwndUDsJmVtnk6Qgzs9xkT8xVbxCu5lG+mVUJlXi02I7UX9J/S3pO0ixJ30zlfSTdL+mF9HODgjpnS5ot6XlJBxeUD5U0M312qVKqN0ndJN2UyqdIGtBcnxyEzaziSaUdJagDzoyIHYDhwKmSdgTOAiZHxEBgcnpP+mw02Z6aI4ErUopfgCuB8cDAdIxM5eOARRGxDXAJcFFzHXIQNrMKJ6TSjpZExLyIeCK9XgI8B/QFDgMmpdMmAYen14cBN0bEioh4CZgN7CFpc2C9iHgsIgK4tlGdhrZuAQ5UM51zEDazitawOqKUA9hI0rSCY3yT7WbTBEOAKcCmETEPskANbJJO6wvMKag2N5X1Ta8bl69RJyLqgMXAhk31wzfmzKziteLG3IKIGNbSSZLWJdum7YyIeLeZgWpTCcyaS2zWqqRnHgmbWWUTbTYdASDpE2QB+I8Fm1O8maYYSD/np/K5QP+C6v2A11N5vyLla9SR1AXoDTT5BLKDsJlVtFZORzTfVhaprwGei4hfFnx0JzA2vR4L3FFQPjqteNiK7Abc1DRlsUTS8NTmmEZ1Gto6EnggzRsX5ekIM6t4bbjR597AccBMSU+lsh8AFwI3SxoHvAqMAoiIWZJuBp4lW1lxakTUp3onAxOBHsDd6YAsyF8naTbZCHh0cx1yEDazitdWITgiHmmmuaKZIyNiAjChSPk0YKci5ctJQbwUDsJmVtEE1FbxE3MOwmZW8ao4BjsIm1mlE6rijX4chM2s4nkkbGaWk2yJWvVGYQdhM6tspSfn6ZAchM2s4lVzPmEHYTOraFlS97x7UT4OwmZW8bw6wswsR1U8G+Eg3JHNfWMRJ593LfMXvkuNxNgv7c1JXzmAv/zXE1z0u7/x/MtvMnnidxiy45Z5d7XTWb5iJaNOu5wPVtZRV1/P5/bflTO/dggAf7j1ISbd9gi1tTWM2GtHzjn50NX1XntzEQeOuZBvHT+SE79yAABHnX458xe+S/dunwDg+n8/iY026NX+F5Ujj4TbiKTzgKUR8YsytD2BLJPRBhGxblu3X4m6dKnhZ2d8mV2378+S95ZzwJiL2H/P7dlh609y7cUn8K0L/pR3Fzutbl27cOOvTmGdnt1YWVfPEadeygF77sDyFSu575FnuPcP36Nb1y4sWLRkjXo/uewv7L/nDh9p79c/PJZdt9+ivbpfUTwn3HHcBVwOvJB3R9rLZhv1ZrONegPQa53ubDtgM+a99Q4HFPlLbO1LEuv07AZAXV09dXX1SOK6Ox7llGMOpFvX7K9e4Yj23odnssUnN6RH96659LliSVW9OqJs+YQljZH0tKQZkq4r8vkJkh5Pn98qqWcqHyXpmVT+UCobJGmqpKdSmwMbtxcR/2jYnqQzevX1hTz9/FyGDhqQd1csqa9fxciv/Zwhh/2QzwzbjiE7bslLc95i6tMvcuiJlzDqtMuZ8dyrALy/bAVX3jCZM44/uGhb37ngRkZ+7ef8etJ9NJOatmq11W7LlagsI2FJg4BzgL0jYoGkPkVOuy0irkrn/4xsh9LLgB8BB0fEa5LWT+eeBPw6Iv4oqStQW6S9Uvs2nmyHVPpvUR3/vFv6/grGfP9qLvj2Eay3bo+8u2NJbW0N9/z+uyxesozx5/6e51+cR139KhYvWcYdvzmDGc+9yik/nsQjN53LL39/D+NG7bd69Fzo0h8ey2Ybr8/S95dz4rl/4NZ7N+DIkbvncEX5yKYjOmqIbVm5piNGALdExAKAiCi2tcdOKfiuD6wL3JvKHwUmpkTKDVuPPAacI6kfWfD+2FMOEfE74HcAQ4cO6/BDipV19Yz9/lWMGjmML44YnHd3rIjevXowfPDWPDjln2y+8focsu8uSGLwjluiGvH24vd48rlX+Nv/zOCC39zFu0uXIdXQrWsXjj9iHzbbeH0A1u3ZncP/ZSgznnu1UwVh6Lij3FKUKwiLZja2SyYCh0fEDEnHA/sDRMRJkvYEPg88JWlwRNwgaUoqu1fS1yPigTL1vcOICE776R/ZdsBmnHpM0XzUlpOF7yylS20tvXv1YPmKD3hk+v9y8tEH0rNnV/7+xAvsNWQbXpwzn5Ur6+nTex1uvfz01XV/+ft7WKdHN44/Yh/q6up5d+ky+qy/Livr6vmvv8/iM8O2zfHKclLFUbhcQXgycLukSyJioaQ+RUbDvYB5adO9Y4DXACRtHRFTgCmSvgj0l9QbeDEiLpX0KWAXoNMH4X/MeJGb/jaVHbf5JPscfQEAPzz1UD74oI7v/+LPLFi0lH/91m/Yedu+3HrZN3Lubecyf+G7fPvfbqC+fhWrIvjCAYM56NOD+GBlHd+98EYOGnsRXbvU8ssfHN3s1j0frKzj2O/8lrq6eupXreIzQ7fl6C/s1Y5XUhmqeTpC5ZrklzQW+C5QDzwZEccXLlGTdDLwPeAVYCbQK51zG9lmeiIL5mcAZwHHAiuBN4CjGwd1SRcDRwOfJNv19OqIOK+5Pg4dOiwenTKtbS7Y2sWSZSvz7oK1wr/sN5ynnpi+VhF0h52HxLV3PFjSuXtsvf70Ura8ryRlW6IWEZOASY3Kzit4fSVwZZF6Xy7S3AXpaO77vkcW1M2s2lTvQLiq1gmbWRXKlp9VbxR2EDazyuZ8wmZm+ariGOwgbGaVTs2uIOnoHITNrOJVcQx2EDazytaR80KUwkHYzCpfFUdhB2Ezq3jVvEStbKkszczailTa0XI7+r2k+ZKeKSjrI+l+SS+knxsUfHa2pNmSnpd0cEH5UEkz02eXKt05lNRN0k2pfIqkAS31yUHYzCpbiQG4xJt3E4GRjcrOAiZHxECyVAlnAUjaERgNDEp1rpDUkEb3SrKUuAPT0dDmOGBRRGwDXAJc1FKHHITNrOKpxP9aEhEPAY2TiR3GhykWJgGHF5TfGBErIuIlYDawh6TNgfUi4rHIku9c26hOQ1u3AAeqhfV1DsJmVtFEq0bCG0maVnCML+ErNm3YlSf93CSV9wXmFJw3N5X1Ta8bl69RJyLqgMXAhs19uW/MmVnFa8VtuQVtmEWt2NdGM+XN1WmSR8JmVvnKu8ncm2mKgfRzfiqfC/QvOK8fWZrcuel14/I16kjqAvTmo9Mfa3AQNrOKV5N2XG7p+JjuBMam12OBOwrKR6cVD1uR3YCbmqYslkganuZ7xzSq09DWkcAD0ULSdk9HmFnFa6tVwpL+RLaV2kaS5gI/Bi4EbpY0DngVGAUQEbPSXpfPAnXAqRFRn5o6mWylRQ/g7nQAXANcJ2k22Qh4dEt9chA2s8rXRlE4Ir7SxEdFN2mMiAnAhCLl04CdipQvJwXxUjkIm1lFc1J3M7M8Oam7mVm+qjgGOwibWaVzUnczs1xVcQx2EDazyuak7mZmeaviKOwgbGYVz0vUzMxy5DlhM7O8CGochM3M8lS9UdhB2MwqWkNS92rlIGxmFa+KY7CDsJlVPo+Ezcxy5MeWzcxyVL0h2EHYzCqcnMrSzCxffmLOzCxP1RuDHYTNrPJVcQx2EDazSrdW29lXPAdhM6to1f7EXE3eHTAz68w8EjazilfNI2EHYTOreF6iZmaWFz+sYWaWn2q/MecgbGYVz9MRZmY58kjYzCxHVRyDHYTNrAOo4ijsIGxmFU1Q1Y8tKyLy7kNuJL0FvJJ3P8pgI2BB3p2wVqnW39mWEbHx2jQg6R6yP59SLIiIkWvzfe2tUwfhaiVpWkQMy7sfVjr/zjov544wM8uRg7CZWY4chKvT7/LugLWaf2edlOeEzcxy5JGwmVmOHITNzHLkINxBSDpP0nfK1PZQSTMlzZZ0qVTFK+PbUZl/ZxMkzZG0tBztW/txEDaAK4HxwMB0dKjF7p3UXcAeeXfC1p6DcAWSNEbS05JmSLquyOcnSHo8fX6rpJ6pfJSkZ1L5Q6lskKSpkp5KbQ5s1NbmwHoR8Vhkd2mvBQ4v/1VWl/b8nQFExD8iYl75r8zKzbkjKoykQcA5wN4RsUBSnyKn3RYRV6XzfwaMAy4DfgQcHBGvSVo/nXsS8OuI+KOkrkBto7b6AnML3s9NZVaiHH5nVkU8Eq48I4BbImIBQES8XeScnSQ9LGkmcAwwKJU/CkyUdAIf/sV9DPiBpO+TPce/rFFbxeZ/vW6xddr7d2ZVxEG48oiWg+BE4BsRsTNwPtAdICJOAs4F+gNPSdowIm4ADgWWAfdKGtGorblAv4L3/YDX1/YiOpn2/p1ZFXEQrjyTgaMkbQjQxD9tewHzJH2CbFRFOnfriJgSET8iy8jVX9KngBcj4lLgTmCXwobSvOISScPTqogxwB3luLAq1q6/M6suDsIVJiJmAROA/5E0A/hlkdN+CEwB7gf+WVD+87TU7BngIWAG8K/AM5KeArYnu/HW2MnA1cBs4P+Au9vmajqHPH5nki6WNBfoKWmupPPa8JKsHfmxZTOzHHkkbGaWIwdhM7McOQibmeXIQdjMLEcOwmZmOXIQtiZJqk/5C56R9OeGfAcfs62Jko5Mr6+WtGMz5+4v6dMf4ztelvSRXXmbKm90TquykZUzQ5p1Lg7C1pxlETE4InYCPiDLabCapI+V0yAivh4RzzZzyv5Aq4OwWUfkIGylehjYJo1S/1vSDcBMSbWSfp4yhD0t6UQAZS6X9KykvwKbNDQk6UFJw9LrkZKeSFnEJksaQBbsv5VG4ftI2jhlHns8HXunuhtKuk/Sk5J+S/E8GGuQ9BdJ0yXNkjS+0Wf/nvoyWdLGqWxrSfekOg9L2r5N/jTNEmdRsxZJ6gIcAtyTivYAdoqIl1IgWxwRu0vqBjwq6T5gCLAdsDOwKfAs8PtG7W4MXAXsm9rqExFvS/oNsDQifpHOuwG4JCIekbQFcC+wA/Bj4JGI+Imkz5PlRG7J19J39AAel3RrRCwE1gGeiIgzJf0otf0Nsg04T4qIFyTtCVxBlrDHrE04CFtzeqRHZyEbCV9DNk0wNSJeSuWfBXZpmO8FepMlht8X+FNE1AOvS3qgSPvDgYca2moi+xjAQcCO+nDDj/Uk9Urf8eVU96+SFpVwTadL+lJ63T/1dSGwCrgplV8P3CZp3XS9fy747m4lfIdZyRyErTnLImJwYUEKRu8VFgGnRcS9jc77HC1nFisl+xhk02Z7NU7pmPpS8nP3kvYnC+h7RcT7kh4kZTMrItL3vtP4z8CsLXlO2NbWvcDJKTsYkraVtA5ZMprRac54c+CAInUfA/aTtFWq25B9bAlZ1rEG95FNDZDOG5xePkTKSCbpEGCDFvraG1iUAvD2ZCPxBjVAw2j+aLJpjneBlySNSt8hSbu28B1mreIgbGvrarL53idSJrDfkv0L63bgBWAm2R52/9O4YkS8RTaPe1vKPtYwHXAX8KWGG3PA6cCwdOPvWT5cpXE+sK+kJ8imRV5toa/3AF0kPQ38FPhHwWfvAYMkTSeb8/1JKj8GGJf6Nws4rIQ/E7OSOYuamVmOPBI2M8uRg7CZWY4chM3McuQgbGaWIwdhM7McOQibmeXIQdjMLEf/D01JRnHCVDr5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#performance results\n",
    "print(classification_report(y_test, y_pred5, target_names=target_names))\n",
    "plot_confusion_matrix(model5, df_X_test_stand, y_test, display_labels=target_names,cmap=plt.cm.Blues);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save notebook session\n",
    "import dill\n",
    "dill.dump_session('session_esc-01.db')\n",
    "#to restore a notebook session\n",
    "#dill.load_session('session_esc-01.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
